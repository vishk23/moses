{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80603b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to sys.path to import src modules from notebooks/\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path(os.getcwd()).parent\n",
    "os.chdir(project_root)\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"Python path includes: {project_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22f0694",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Core business logic for Accubranch account data processing.\n",
    "\n",
    "This module handles:\n",
    "1. Account data generation for current period\n",
    "2. 5-year historical analysis\n",
    "3. Data transformation and output generation\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import src.config as config\n",
    "import src.accubranch.data_cleaning_main\n",
    "import src.accubranch.annual_deposit_history\n",
    "import cdutils.acct_file_creation.core\n",
    "import cdutils.pkey_sqlite\n",
    "import cdutils.hhnbr\n",
    "import cdutils.loans.calculations\n",
    "import cdutils.inactive_date\n",
    "import cdutils.input_cleansing\n",
    "\n",
    "\n",
    "def create_primary_key(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create Primary Key (Tax Owner of Account).\n",
    "    Checks for required columns before creating the key.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with tax reporting columns\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with added 'Primary Key' column\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    if 'taxrptfororgnbr' in df.columns and 'taxrptforpersnbr' in df.columns:\n",
    "        df['Primary Key'] = np.where(\n",
    "            df['taxrptfororgnbr'].isnull(), \n",
    "            'P' + df['taxrptforpersnbr'].astype(str), \n",
    "            'O' + df['taxrptfororgnbr'].astype(str)\n",
    "        )\n",
    "        print(\"Created Primary Key column\")\n",
    "    else:\n",
    "        print(\"Warning: Required columns for Primary Key not found\")\n",
    "        print(f\"Available columns: {list(df.columns)}\")\n",
    "        df['Primary Key'] = 'UNKNOWN'\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_address_field(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create consolidated address field from available address columns.\n",
    "    Checks for multiple possible column name patterns.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with address columns\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with added 'Address' column\n",
    "    \"\"\"\n",
    "    def concat_address(text1, text2, text3):\n",
    "        parts = [str(p).strip() for p in [text1, text2, text3] if p and str(p).strip() and str(p) != 'nan']\n",
    "        return ' '.join(parts) if parts else pd.NA\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Check for different possible address column patterns\n",
    "    address_patterns = [\n",
    "        ('text1', 'text2', 'text3'),  # Original pattern\n",
    "        ('addr1', 'addr2', 'addr3'),  # Alternative pattern\n",
    "        ('address1', 'address2', 'address3'),  # Another alternative\n",
    "        ('street1', 'street2', 'street3'),  # Yet another alternative\n",
    "    ]\n",
    "    \n",
    "    address_cols = None\n",
    "    for pattern in address_patterns:\n",
    "        if all(col in df.columns for col in pattern):\n",
    "            address_cols = pattern\n",
    "            print(f\"Using address columns: {address_cols}\")\n",
    "            break\n",
    "    \n",
    "    if address_cols:\n",
    "        df['Address'] = df.apply(\n",
    "            lambda row: concat_address(row.get(address_cols[0]), row.get(address_cols[1]), row.get(address_cols[2])),\n",
    "            axis=1\n",
    "        )\n",
    "    else:\n",
    "        print(\"Warning: No address columns found, setting Address to empty\")\n",
    "        print(f\"Available columns: {list(df.columns)}\")\n",
    "        df['Address'] = pd.NA\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def map_account_type(acct_code: str) -> str:\n",
    "    \"\"\"\n",
    "    Map mjaccttypcd to friendly Account Type.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    acct_code : str\n",
    "        Major account type code\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Friendly account type name\n",
    "    \"\"\"\n",
    "    return config.ACCOUNT_TYPE_MAPPING.get(str(acct_code).upper(), 'Other')\n",
    "\n",
    "\n",
    "def apply_account_type_mapping(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply account type mapping and handle small business loans.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with mjaccttypcd and loanofficer columns\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with added 'Account Type' column\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['Account Type'] = df['mjaccttypcd'].apply(map_account_type)\n",
    "    \n",
    "    # Handle small business loans\n",
    "    df['Account Type'] = np.where(\n",
    "        (df['Account Type'] == 'Commercial Loan') & \n",
    "        (df['loanofficer'].isin(config.SMALL_BUSINESS_OFFICERS)),\n",
    "        'Small Business Loan',\n",
    "        df['Account Type']\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_loan_amount_logic(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply original loan amount logic for loan accounts only.\n",
    "    Checks for multiple possible column names for original loan amount.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with loan amount columns\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with updated loan amount column\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Check for different possible loan amount column names\n",
    "    loan_amount_cols = ['orig_ttl_loan_amt']\n",
    "    loan_col = None\n",
    "    \n",
    "    for col in loan_amount_cols:\n",
    "        if col in df.columns:\n",
    "            loan_col = col\n",
    "            print(f\"Using loan amount column: {loan_col}\")\n",
    "            break\n",
    "    \n",
    "    if loan_col and 'mjaccttypcd' in df.columns:\n",
    "        df['Original Balance (Loans)'] = np.where(\n",
    "            df['mjaccttypcd'].isin(config.LOAN_ACCOUNT_TYPES),\n",
    "            df[loan_col],\n",
    "            pd.NA\n",
    "        )\n",
    "        print(f\"Applied loan amount logic using {loan_col}\")\n",
    "    else:\n",
    "        print(\"Warning: Required columns for loan amount logic not found\")\n",
    "        df['Original Balance (Loans)'] = pd.NA\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_business_individual_flag(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create Business/Individual flag based on organization number.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with taxrptfororgnbr column\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with added 'Business/Individual' column\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['Business/Individual'] = np.where(\n",
    "        df['taxrptfororgnbr'].isnull(),\n",
    "        'Individual',\n",
    "        'Business'\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_column_renaming(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply standard column renaming for output.\n",
    "    Only renames columns that actually exist in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with renamed columns\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Define potential column mappings\n",
    "    column_mappings = {\n",
    "        'cityname': 'City',\n",
    "        'statecd': 'State', \n",
    "        'zipcd': 'Zip',\n",
    "        'branchname': 'Branch Associated',\n",
    "        'contractdate': 'Date Account Opened',\n",
    "        'Net Balance': 'Current Balance',\n",
    "        'datebirth': 'Date of Birth',\n",
    "        # Add potential alternative column names from cdutils\n",
    "        'city': 'City',\n",
    "        'state': 'State',\n",
    "        'zip': 'Zip',\n",
    "        'branch': 'Branch Associated',\n",
    "        'opendate': 'Date Account Opened',\n",
    "        'dob': 'Date of Birth'\n",
    "    }\n",
    "    \n",
    "    # Only apply mappings for columns that actually exist\n",
    "    existing_mappings = {old_col: new_col for old_col, new_col in column_mappings.items() \n",
    "                        if old_col in df.columns}\n",
    "    \n",
    "    if existing_mappings:\n",
    "        print(f\"Renaming columns: {existing_mappings}\")\n",
    "        df = df.rename(columns=existing_mappings)\n",
    "    else:\n",
    "        print(\"No matching columns found for renaming\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def select_final_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Select final columns for output.\n",
    "    Only selects columns that actually exist in the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with selected columns\n",
    "    \"\"\"\n",
    "    desired_columns = [\n",
    "        'Primary Key',\n",
    "        'Address',\n",
    "        'City',\n",
    "        'State',\n",
    "        'Zip',\n",
    "        'Branch Associated',\n",
    "        'Account Type',\n",
    "        'Date Account Opened',\n",
    "        'Current Balance',\n",
    "        'Original Balance (Loans)',\n",
    "        'Date of Birth'\n",
    "    ]\n",
    "    \n",
    "    # Only select columns that actually exist\n",
    "    available_columns = [col for col in desired_columns if col in df.columns]\n",
    "    missing_columns = [col for col in desired_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"Warning: Missing columns in output: {missing_columns}\")\n",
    "        print(f\"Available columns: {list(df.columns)}\")\n",
    "    \n",
    "    print(f\"Selecting {len(available_columns)} columns for output: {available_columns}\")\n",
    "    \n",
    "    return df[available_columns].copy()\n",
    "\n",
    "\n",
    "def process_current_account_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process current account data with all transformations.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Processed account data ready for output\n",
    "    \"\"\"\n",
    "    print(\"Fetching current account data...\")\n",
    "    \n",
    "    # Determine the date to use\n",
    "    current_date = config.CURRENT_DATA_DATE or None \n",
    "    print(f\"Using date: {current_date}\")\n",
    "    \n",
    "    # Use the data cleaning pipeline to get complete account data with addresses and person info\n",
    "    data_current = src.accubranch.data_cleaning_main.run_data_cleaning_pipeline(\n",
    "        as_of_date=current_date,\n",
    "        data_source=\"production\",\n",
    "        exclude_org_types=config.EXCLUDE_ORG_TYPES\n",
    "    )\n",
    "    \n",
    "    print(f\"Retrieved {len(data_current)} records\")\n",
    "    print(f\"Available columns: {list(data_current.columns)}\")\n",
    "    \n",
    "    print(\"Applying data transformations...\")\n",
    "    \n",
    "    # Apply all transformations in sequence\n",
    "    data_current = create_primary_key(data_current)\n",
    "    data_current = create_address_field(data_current)\n",
    "    \n",
    "    # Filter to target account types (if column exists)\n",
    "    # Note: data_cleaning_main may have already done some filtering\n",
    "    if 'mjaccttypcd' in data_current.columns:\n",
    "        initial_count = len(data_current)\n",
    "        data_current = data_current[\n",
    "            data_current['mjaccttypcd'].isin(config.ALL_TARGET_ACCOUNT_TYPES)\n",
    "        ].copy()\n",
    "        print(f\"Filtered to target account types: {len(data_current)} of {initial_count} records\")\n",
    "    else:\n",
    "        print(\"Warning: mjaccttypcd column not found, skipping account type filtering\")\n",
    "    \n",
    "    # Exclude ACH Manager products (if column exists)\n",
    "    if 'currmiaccttypcd' in data_current.columns:\n",
    "        initial_count = len(data_current)\n",
    "        data_current = data_current[\n",
    "            ~data_current['currmiaccttypcd'].isin(config.EXCLUDE_ACCOUNT_TYPES)\n",
    "        ].copy()\n",
    "        print(f\"Excluded ACH Manager products: {len(data_current)} of {initial_count} records\")\n",
    "    else:\n",
    "        print(\"Warning: currmiaccttypcd column not found, skipping ACH Manager exclusion\")\n",
    "    \n",
    "    # Apply business logic transformations\n",
    "    data_current = apply_account_type_mapping(data_current)\n",
    "    data_current = apply_loan_amount_logic(data_current)\n",
    "    data_current = create_business_individual_flag(data_current)\n",
    "    data_current = apply_column_renaming(data_current)\n",
    "    data_current = select_final_columns(data_current)\n",
    "    \n",
    "    return data_current\n",
    "\n",
    "\n",
    "def process_historical_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process 5-year historical data for branch analysis.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Historical analysis data\n",
    "    \"\"\"\n",
    "    print(\"Processing 5-year historical data...\")\n",
    "    \n",
    "    dataframes = []\n",
    "    dates = []\n",
    "    \n",
    "    for year_config in config.HISTORICAL_YEARS:\n",
    "        print(f\"Processing year {year_config['year']}...\")\n",
    "        year_date = datetime.strptime(year_config['date'], '%Y-%m-%d')\n",
    "        \n",
    "        # Use the data cleaning pipeline for historical data too\n",
    "        year_data = src.accubranch.data_cleaning_main.run_data_cleaning_pipeline(\n",
    "            as_of_date=year_date,\n",
    "            data_source=\"production\", \n",
    "            exclude_org_types=config.EXCLUDE_ORG_TYPES\n",
    "        )\n",
    "        \n",
    "        dataframes.append(year_data)\n",
    "        dates.append(year_config['date'])\n",
    "    \n",
    "    print(\"Creating time series analysis...\")\n",
    "    five_yr_history = src.accubranch.annual_deposit_history.create_time_series_analysis(\n",
    "        dataframes, dates\n",
    "    )\n",
    "    \n",
    "    return five_yr_history\n",
    "\n",
    "\n",
    "def process_account_data():\n",
    "    \"\"\"\n",
    "    Main function to process all account data and generate outputs.\n",
    "    \"\"\"\n",
    "    # Process current account data\n",
    "    current_data = process_current_account_data()\n",
    "    \n",
    "    # Save current account data\n",
    "    print(f\"Saving account data to {config.ACCOUNT_OUTPUT_FILE}\")\n",
    "    current_data.to_csv(config.ACCOUNT_OUTPUT_FILE, index=False)\n",
    "    print(f\"✓ Account data saved: {len(current_data)} records\")\n",
    "    \n",
    "    # Process historical data\n",
    "    historical_data = process_historical_data()\n",
    "    \n",
    "    # Save historical data\n",
    "    print(f\"Saving historical data to {config.FIVE_YR_HISTORY_FILE}\")\n",
    "    historical_data.to_csv(config.FIVE_YR_HISTORY_FILE, index=False)\n",
    "    print(f\"✓ Historical data saved: {len(historical_data)} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fetching current account data...\")\n",
    "\n",
    "# Determine the date to use\n",
    "current_date = config.CURRENT_DATA_DATE or None \n",
    "print(f\"Using date: {current_date}\")\n",
    "\n",
    "# Use the data cleaning pipeline to get complete account data with addresses and person info\n",
    "data_current = src.accubranch.data_cleaning_main.run_data_cleaning_pipeline(\n",
    "    as_of_date=current_date,\n",
    "    data_source=\"production\",\n",
    "    exclude_org_types=config.EXCLUDE_ORG_TYPES\n",
    ")\n",
    "\n",
    "print(f\"Retrieved {len(data_current)} records\")\n",
    "print(f\"Available columns: {list(data_current.columns)}\")\n",
    "\n",
    "print(\"Applying data transformations...\")\n",
    "\n",
    "# Apply all transformations in sequence\n",
    "data_current = create_primary_key(data_current)\n",
    "data_current = create_address_field(data_current)\n",
    "\n",
    "# Filter to target account types (if column exists)\n",
    "# Note: data_cleaning_main may have already done some filtering\n",
    "if 'mjaccttypcd' in data_current.columns:\n",
    "    initial_count = len(data_current)\n",
    "    data_current = data_current[\n",
    "        data_current['mjaccttypcd'].isin(config.ALL_TARGET_ACCOUNT_TYPES)\n",
    "    ].copy()\n",
    "    print(f\"Filtered to target account types: {len(data_current)} of {initial_count} records\")\n",
    "else:\n",
    "    print(\"Warning: mjaccttypcd column not found, skipping account type filtering\")\n",
    "\n",
    "# Exclude ACH Manager products (if column exists)\n",
    "if 'currmiaccttypcd' in data_current.columns:\n",
    "    initial_count = len(data_current)\n",
    "    data_current = data_current[\n",
    "        ~data_current['currmiaccttypcd'].isin(config.EXCLUDE_ACCOUNT_TYPES)\n",
    "    ].copy()\n",
    "    print(f\"Excluded ACH Manager products: {len(data_current)} of {initial_count} records\")\n",
    "else:\n",
    "    print(\"Warning: currmiaccttypcd column not found, skipping ACH Manager exclusion\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aef0066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply business logic transformations\n",
    "data_current = apply_account_type_mapping(data_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efad181",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_current = create_business_individual_flag(data_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be54a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_current = apply_column_renaming(data_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ceb1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_current = select_final_columns(data_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22acbce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_current.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8cabd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f81a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = Path(r\"C:\\Users\\w322800\\Documents\\gh\\bcsb-prod\\Reports\\Retail\\Accubranch\\output\\five_yr_history.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d22e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b35af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e274a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcsb-prod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
