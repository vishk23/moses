{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a724e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Navigate to project root (equivalent to cd ..)\n",
    "project_dir = Path(__file__).parent.parent if '__file__' in globals() else Path.cwd().parent\n",
    "os.chdir(project_dir)\n",
    "\n",
    "# Add src directory to Python path for imports\n",
    "src_dir = project_dir / \"src\"\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# Set environment for dev testing\n",
    "os.environ['REPORT_ENV'] = 'dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ad2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import src.config\n",
    "from deltalake import DeltaTable\n",
    "import cdutils.customer_dim # type: ignore\n",
    "import src.raynham_report.fetch_data\n",
    "import cdutils.input_cleansing # type: ignore\n",
    "\n",
    "def filter_distinct_customers_assigned_to_n_raynham(df):\n",
    "    \"\"\"\n",
    "    Unique customers that are assigned to branch in question\n",
    "    \"\"\"\n",
    "    filtered_df = df[df['branchname'] == 'BCSB - NORTH RAYNHAM BRANCH'].copy()\n",
    "    distinct_customers = filtered_df[['customer_id']].drop_duplicates()\n",
    "    distinct_customers['eligibility'] = 'Assigned to N Raynham'\n",
    "    return distinct_customers\n",
    "\n",
    "def filter_distinct_customers_transacted_at_n_raynham(accts):\n",
    "    \"\"\"\n",
    "    Unique accounts that have transacted at branch in question\n",
    "    \"\"\"\n",
    "    data = src.raynham_report.fetch_data.fetch_rtxn_data()\n",
    "    transacted = data['transacted'].copy()\n",
    "    transacted_schema = {\n",
    "        'acctnbr':'str'\n",
    "    }\n",
    "    transacted = cdutils.input_cleansing.cast_columns(transacted, transacted_schema)\n",
    "    transacted = transacted.merge(accts, how='inner', on='acctnbr')\n",
    "    distinct_customers = transacted[['customer_id']].drop_duplicates()\n",
    "    distinct_customers['eligibility'] = 'Transacted at N Raynham within 90 days'\n",
    "\n",
    "    return distinct_customers \n",
    "\n",
    "def filter_distinct_customer_near_branches(accts):\n",
    "    \"\"\"\n",
    "    Unique Customers located near raynham or taunton\n",
    "\n",
    "    Requested was within 5 mi of branch, but for simplicity, we match on primary zip codes\n",
    "    \"\"\"\n",
    "    zip_codes = [\"02767\"]\n",
    "    filtered_df = accts[accts['primaryownerzipcd'].isin(zip_codes)]\n",
    "    distinct_customers = filtered_df[['customer_id']].drop_duplicates()\n",
    "    distinct_customers['eligibility'] = 'Zip Code in Raynham (02767)'\n",
    "    return distinct_customers\n",
    "    \n",
    "\n",
    "# def generate_raynham_report():\n",
    "\"\"\"\n",
    "Objective:\n",
    "\n",
    "To create a person mailing list to North raynham Branch Construction customers\n",
    "\n",
    "Params:\n",
    "\n",
    "Assigned to N Raynham\n",
    "Transacted at N Raynham within 90 days\n",
    "Address within a 5 mile radius of N. Raynham, Raynham Center, Main Office\n",
    "Owns Safe Deposit Box @ N. Raynham\n",
    "Exclusions (do we have standard exclusions for all mailings? Including common ones below)\n",
    "Customers under 18 years of age\n",
    "Deceased customers\n",
    "Charged off accounts\n",
    "\n",
    "\n",
    "Data fields:\n",
    "\n",
    "First name\n",
    "Last name\n",
    "Address\n",
    "City\n",
    "State\n",
    "Zip\n",
    "\"\"\"\n",
    "\n",
    "# Pull in Base Customer Layer\n",
    "base_customer_dim = DeltaTable(src.config.SILVER / \"base_customer_dim\").to_pandas()\n",
    "\n",
    "# Pull in Active Accounts (create a clean customer_id for joining)\n",
    "accts = DeltaTable(src.config.SILVER / \"account\").to_pandas()\n",
    "\n",
    "# Assigned to Branch from Accts\n",
    "assigned = filter_distinct_customers_assigned_to_n_raynham(accts)\n",
    "\n",
    "# Transacted at Branch in last 90 days\n",
    "transacted = filter_distinct_customers_transacted_at_n_raynham(accts)\n",
    "\n",
    "# Address near Branch (zip codes)\n",
    "nearby = filter_distinct_customer_near_branches(accts)\n",
    "\n",
    "# Union/concat eligible criteria on cust_id\n",
    "concat_df = pd.concat([assigned, transacted, nearby], ignore_index=True)\n",
    "concat_df = concat_df.drop_duplicates(subset=['customer_id'], keep='first')\n",
    "\n",
    "# Inner join with base customer dim\n",
    "base_customer_dim = base_customer_dim[[\n",
    "    'customer_id',\n",
    "    'customer_type',\n",
    "    'customer_name',\n",
    "    'Active Account Owner',\n",
    "    'loan_net_balance',\n",
    "    'deposit_balance'\n",
    "]].copy()\n",
    "base_customer_dim = base_customer_dim[base_customer_dim['Active Account Owner'] == \"Y\"].copy()\n",
    "customer_df = base_customer_dim.merge(concat_df, how='inner', on='customer_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09d9ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290aa859",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Append primary address\n",
    "customer_address_link = DeltaTable(src.config.SILVER / \"customer_address_link\").to_pandas()\n",
    "customer_address_link = customer_address_link[customer_address_link['addrusecd'] == 'PRI'].copy()\n",
    "customer_address_link = customer_address_link[[\n",
    "    'customer_id',\n",
    "    'addrnbr'\n",
    "]].copy()\n",
    "customer_address_link_schema = {\n",
    "    'addrnbr':'str'\n",
    "}\n",
    "customer_address_link = cdutils.input_cleansing.cast_columns(customer_address_link, customer_address_link_schema)\n",
    "\n",
    "address = DeltaTable(src.config.SILVER / \"address\").to_pandas()\n",
    "address_schema = {\n",
    "    'addrnbr':'str'\n",
    "}\n",
    "address = cdutils.input_cleansing.cast_columns(address, address_schema)\n",
    "address = address.drop(columns='load_timestamp_utc').copy()\n",
    "address = customer_address_link.merge(address, how='inner', on='addrnbr')\n",
    "\n",
    "customer_df = customer_df.merge(address, on='customer_id', how='left')\n",
    "\n",
    "# Need to do exclusions\n",
    "pers_dim = DeltaTable(src.config.SILVER / \"pers_dim\").to_pandas()\n",
    "pers_dim = pers_dim[[\n",
    "    'customer_id',\n",
    "    'age',\n",
    "    'firstname',\n",
    "    'lastname'\n",
    "]].copy()\n",
    "customer_df = customer_df.merge(pers_dim, on='customer_id', how='left')\n",
    "\n",
    "# Filter out records where age < 18 and customer type = 'Person'\n",
    "customer_df = customer_df[~((customer_df['customer_type'] == 'Person') & (customer_df['age'] < 18) & (customer_df['age'] > 90))].copy()\n",
    "\n",
    "# # Append pkey\n",
    "# pkey_slice = accts[['customer_id','portfolio_key']].copy()\n",
    "# # Assert a customer id is not associated with multiple portfolio keys\n",
    "# # There is a Many:1 relationship between customers and portfolio key.\n",
    "\n",
    "# customer_df = customer_df.merge(pkey_slice, on='customer_id', how='left')\n",
    "\n",
    "\n",
    "# # Append pkey\n",
    "# pkey_slice = accts[['customer_id', 'portfolio_key']].copy()\n",
    "\n",
    "# # Assert no customers are associated with multiple portfolio keys\n",
    "# portfolio_key_uniques = pkey_slice.groupby('customer_id')['portfolio_key'].nunique()\n",
    "# assert (portfolio_key_uniques == 1).all(), \"Assertion failed: One or more customers are associated with multiple portfolio keys\"\n",
    "\n",
    "# # Deduplicate pkey_slice to handle potential multiplicity (assuming Many:1 relationship)\n",
    "# pkey_slice = pkey_slice.drop_duplicates(subset='customer_id')\n",
    "# customer_df = customer_df.merge(pkey_slice, on='customer_id', how='left')\n",
    "\n",
    "# # Sort in descending order of deposit balance then loan balance, and drop duplicates on portfolio_key\n",
    "# customer_df_portfolio = customer_df.sort_values(['deposit_balance', 'loan_net_balance'], ascending=[False, False]).drop_duplicates(subset=['portfolio_key'])\n",
    "\n",
    "# Just inspect output\n",
    "# Set column order\n",
    "# Write out\n",
    "# Done\n",
    "customer_df = customer_df[[\n",
    "    'customer_id',\n",
    "    'customer_type',\n",
    "    'customer_name',\n",
    "    'Full_Street_Address',\n",
    "    'cityname',\n",
    "    'statecd',\n",
    "    'zipcd',\n",
    "    'firstname',\n",
    "    'lastname',\n",
    "    'eligibility'\n",
    "]].copy()\n",
    "\n",
    "customer_df = customer_df.rename(columns={\n",
    "    'customer_name':'Customer Name',\n",
    "    'Full_Street_Address':'Address',\n",
    "    'cityname': 'City',\n",
    "    'statecd':'State',\n",
    "    'zipcd':'Zip',\n",
    "    'firstname':'First Name',\n",
    "    'lastname':'Last Name'\n",
    "}).copy()\n",
    "\n",
    "return customer_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import src.config\n",
    "from deltalake import DeltaTable\n",
    "import cdutils.customer_dim # type: ignore\n",
    "import src.raynham_report.fetch_data\n",
    "import cdutils.input_cleansing # type: ignore\n",
    "\n",
    "def filter_distinct_customers_assigned_to_n_raynham(df):\n",
    "    \"\"\"\n",
    "    Unique customers that are assigned to branch in question\n",
    "    \"\"\"\n",
    "    filtered_df = df[df['branchname'] == 'BCSB - NORTH RAYNHAM BRANCH'].copy()\n",
    "    distinct_customers = filtered_df[['customer_id']].drop_duplicates()\n",
    "    distinct_customers['eligibility'] = 'Assigned to N Raynham'\n",
    "    return distinct_customers\n",
    "\n",
    "def filter_distinct_customers_transacted_at_n_raynham(accts):\n",
    "    \"\"\"\n",
    "    Unique accounts that have transacted at branch in question\n",
    "    \"\"\"\n",
    "    data = src.raynham_report.fetch_data.fetch_rtxn_data()\n",
    "    transacted = data['transacted'].copy()\n",
    "    transacted_schema = {\n",
    "        'acctnbr':'str'\n",
    "    }\n",
    "    transacted = cdutils.input_cleansing.cast_columns(transacted, transacted_schema)\n",
    "    transacted = transacted.merge(accts, how='inner', on='acctnbr')\n",
    "    distinct_customers = transacted[['customer_id']].drop_duplicates()\n",
    "    distinct_customers['eligibility'] = 'Transacted at N Raynham within 90 days'\n",
    "\n",
    "    return distinct_customers \n",
    "\n",
    "def filter_distinct_customer_near_branches(accts):\n",
    "    \"\"\"\n",
    "    Unique Customers located near raynham or taunton\n",
    "\n",
    "    Requested was within 5 mi of branch, but for simplicity, we match on primary zip codes\n",
    "    \"\"\"\n",
    "    zip_codes = [\"02767\",\"02780\"]\n",
    "    filtered_df = accts[accts['primaryownerzipcd'].isin(zip_codes)]\n",
    "    distinct_customers = filtered_df[['customer_id']].drop_duplicates()\n",
    "    distinct_customers['eligibility'] = 'Zip Code in Raynham (02767) or Taunton (02780)'\n",
    "    return distinct_customers\n",
    "    \n",
    "\n",
    "# def generate_raynham_report():\n",
    "\"\"\"\n",
    "Objective:\n",
    "\n",
    "To create a person mailing list to North raynham Branch Construction customers\n",
    "\n",
    "Params:\n",
    "\n",
    "Assigned to N Raynham\n",
    "Transacted at N Raynham within 90 days\n",
    "Address within a 5 mile radius of N. Raynham, Raynham Center, Main Office\n",
    "Owns Safe Deposit Box @ N. Raynham\n",
    "Exclusions (do we have standard exclusions for all mailings? Including common ones below)\n",
    "Customers under 18 years of age\n",
    "Deceased customers\n",
    "Charged off accounts\n",
    "\n",
    "\n",
    "Data fields:\n",
    "\n",
    "First name\n",
    "Last name\n",
    "Address\n",
    "City\n",
    "State\n",
    "Zip\n",
    "\"\"\"\n",
    "\n",
    "# Pull in Base Customer Layer\n",
    "base_customer_dim = DeltaTable(src.config.SILVER / \"base_customer_dim\").to_pandas()\n",
    "\n",
    "# Pull in Active Accounts (create a clean customer_id for joining)\n",
    "accts = DeltaTable(src.config.SILVER / \"account\").to_pandas()\n",
    "\n",
    "# Assigned to Branch from Accts\n",
    "assigned = filter_distinct_customers_assigned_to_n_raynham(accts)\n",
    "\n",
    "# Transacted at Branch in last 90 days\n",
    "transacted = filter_distinct_customers_transacted_at_n_raynham(accts)\n",
    "\n",
    "# Address near Branch (zip codes)\n",
    "nearby = filter_distinct_customer_near_branches(accts)\n",
    "\n",
    "# Union/concat eligible criteria on cust_id\n",
    "concat_df = pd.concat([assigned, transacted, nearby], ignore_index=True)\n",
    "concat_df = concat_df.drop_duplicates(subset=['customer_id'], keep='first')\n",
    "\n",
    "# Inner join with base customer dim\n",
    "base_customer_dim = base_customer_dim[[\n",
    "    'customer_id',\n",
    "    'customer_type',\n",
    "    'customer_name',\n",
    "    'Active Account Owner',\n",
    "    'loan_net_balance',\n",
    "    'deposit_balance'\n",
    "]].copy()\n",
    "base_customer_dim = base_customer_dim[base_customer_dim['Active Account Owner'] == \"Y\"].copy()\n",
    "customer_df = base_customer_dim.merge(concat_df, how='inner', on='customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacce9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105a9f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Append primary address\n",
    "customer_address_link = DeltaTable(src.config.SILVER / \"customer_address_link\").to_pandas()\n",
    "customer_address_link = customer_address_link[customer_address_link['addrusecd'] == 'PRI'].copy()\n",
    "customer_address_link = customer_address_link[[\n",
    "    'customer_id',\n",
    "    'addrnbr'\n",
    "]].copy()\n",
    "customer_address_link_schema = {\n",
    "    'addrnbr':'str'\n",
    "}\n",
    "customer_address_link = cdutils.input_cleansing.cast_columns(customer_address_link, customer_address_link_schema)\n",
    "\n",
    "address = DeltaTable(src.config.SILVER / \"address\").to_pandas()\n",
    "address_schema = {\n",
    "    'addrnbr':'str'\n",
    "}\n",
    "address = cdutils.input_cleansing.cast_columns(address, address_schema)\n",
    "address = address.drop(columns='load_timestamp_utc').copy()\n",
    "address = customer_address_link.merge(address, how='inner', on='addrnbr')\n",
    "\n",
    "customer_df = customer_df.merge(address, on='customer_id', how='left')\n",
    "\n",
    "# Need to do exclusions\n",
    "pers_dim = DeltaTable(src.config.SILVER / \"pers_dim\").to_pandas()\n",
    "pers_dim = pers_dim[[\n",
    "    'customer_id',\n",
    "    'age',\n",
    "    'firstname',\n",
    "    'lastname'\n",
    "]].copy()\n",
    "customer_df = customer_df.merge(pers_dim, on='customer_id', how='left')\n",
    "\n",
    "# Filter out records where age < 18 and customer type = 'Person'\n",
    "customer_df = customer_df[~((customer_df['customer_type'] == 'Person') & (customer_df['age'] < 18) & (customer_df['age'] > 90))].copy()\n",
    "\n",
    "# # Append pkey\n",
    "# pkey_slice = accts[['customer_id','portfolio_key']].copy()\n",
    "# # Assert a customer id is not associated with multiple portfolio keys\n",
    "# # There is a Many:1 relationship between customers and portfolio key.\n",
    "\n",
    "# customer_df = customer_df.merge(pkey_slice, on='customer_id', how='left')\n",
    "\n",
    "\n",
    "# # Append pkey\n",
    "# pkey_slice = accts[['customer_id', 'portfolio_key']].copy()\n",
    "\n",
    "# # Assert no customers are associated with multiple portfolio keys\n",
    "# portfolio_key_uniques = pkey_slice.groupby('customer_id')['portfolio_key'].nunique()\n",
    "# assert (portfolio_key_uniques == 1).all(), \"Assertion failed: One or more customers are associated with multiple portfolio keys\"\n",
    "\n",
    "# # Deduplicate pkey_slice to handle potential multiplicity (assuming Many:1 relationship)\n",
    "# pkey_slice = pkey_slice.drop_duplicates(subset='customer_id')\n",
    "# customer_df = customer_df.merge(pkey_slice, on='customer_id', how='left')\n",
    "\n",
    "# # Sort in descending order of deposit balance then loan balance, and drop duplicates on portfolio_key\n",
    "# customer_df_portfolio = customer_df.sort_values(['deposit_balance', 'loan_net_balance'], ascending=[False, False]).drop_duplicates(subset=['portfolio_key'])\n",
    "\n",
    "# Just inspect output\n",
    "# Set column order\n",
    "# Write out\n",
    "# Done\n",
    "customer_df = customer_df[[\n",
    "    'customer_id',\n",
    "    'customer_type',\n",
    "    'customer_name',\n",
    "    'Full_Street_Address',\n",
    "    'cityname',\n",
    "    'statecd',\n",
    "    'zipcd',\n",
    "    'firstname',\n",
    "    'lastname',\n",
    "    'eligibility'\n",
    "]].copy()\n",
    "\n",
    "customer_df = customer_df.rename(columns={\n",
    "    'customer_name':'Customer Name',\n",
    "    'Full_Street_Address':'Address',\n",
    "    'cityname': 'City',\n",
    "    'statecd':'State',\n",
    "    'zipcd':'Zip',\n",
    "    'firstname':'First Name',\n",
    "    'lastname':'Last Name'\n",
    "}).copy()\n",
    "\n",
    "# return customer_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdecf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import src.config\n",
    "from deltalake import DeltaTable\n",
    "import cdutils.customer_dim # type: ignore\n",
    "import src.raynham_report.fetch_data\n",
    "import cdutils.input_cleansing # type: ignore\n",
    "\n",
    "def filter_distinct_customers_assigned_to_n_raynham(df):\n",
    "    \"\"\"\n",
    "    Unique customers that are assigned to branch in question\n",
    "    \"\"\"\n",
    "    filtered_df = df[df['branchname'] == 'BCSB - NORTH RAYNHAM BRANCH'].copy()\n",
    "    distinct_customers = filtered_df[['customer_id']].drop_duplicates()\n",
    "    distinct_customers['eligibility'] = 'Assigned to N Raynham'\n",
    "    return distinct_customers\n",
    "\n",
    "def filter_distinct_customers_transacted_at_n_raynham(accts):\n",
    "    \"\"\"\n",
    "    Unique accounts that have transacted at branch in question\n",
    "    \"\"\"\n",
    "    data = src.raynham_report.fetch_data.fetch_rtxn_data()\n",
    "    transacted = data['transacted'].copy()\n",
    "    transacted_schema = {\n",
    "        'acctnbr':'str'\n",
    "    }\n",
    "    transacted = cdutils.input_cleansing.cast_columns(transacted, transacted_schema)\n",
    "    transacted = transacted.merge(accts, how='inner', on='acctnbr')\n",
    "    distinct_customers = transacted[['customer_id']].drop_duplicates()\n",
    "    distinct_customers['eligibility'] = 'Transacted at N Raynham within 90 days'\n",
    "\n",
    "    return distinct_customers \n",
    "\n",
    "def filter_distinct_customer_near_branches(accts):\n",
    "    \"\"\"\n",
    "    Unique Customers located near raynham or taunton\n",
    "\n",
    "    Requested was within 5 mi of branch, but for simplicity, we match on primary zip codes\n",
    "    \"\"\"\n",
    "    zip_codes = [\"02767\",\"02780\"]\n",
    "    filtered_df = accts[accts['primaryownerzipcd'].isin(zip_codes)]\n",
    "    distinct_customers = filtered_df[['customer_id']].drop_duplicates()\n",
    "    distinct_customers['eligibility'] = 'Zip Code in Raynham (02767) or Taunton (02780)'\n",
    "    return distinct_customers\n",
    "    \n",
    "\n",
    "# def generate_raynham_report():\n",
    "    \"\"\"\n",
    "    Objective:\n",
    "\n",
    "    To create a person mailing list to North raynham Branch Construction customers\n",
    "\n",
    "    Params:\n",
    "\n",
    "    Assigned to N Raynham\n",
    "    Transacted at N Raynham within 90 days\n",
    "    Address within a 5 mile radius of N. Raynham, Raynham Center, Main Office\n",
    "    Owns Safe Deposit Box @ N. Raynham\n",
    "    Exclusions (do we have standard exclusions for all mailings? Including common ones below)\n",
    "    Customers under 18 years of age\n",
    "    Deceased customers\n",
    "    Charged off accounts\n",
    "\n",
    "\n",
    "    Data fields:\n",
    "\n",
    "    First name\n",
    "    Last name\n",
    "    Address\n",
    "    City\n",
    "    State\n",
    "    Zip\n",
    "    \"\"\"\n",
    "\n",
    "# Pull in Base Customer Layer\n",
    "base_customer_dim = DeltaTable(src.config.SILVER / \"base_customer_dim\").to_pandas()\n",
    "\n",
    "# Pull in Active Accounts (create a clean customer_id for joining)\n",
    "accts = DeltaTable(src.config.SILVER / \"account\").to_pandas()\n",
    "\n",
    "# Assigned to Branch from Accts\n",
    "assigned = filter_distinct_customers_assigned_to_n_raynham(accts)\n",
    "\n",
    "# Transacted at Branch in last 90 days\n",
    "transacted = filter_distinct_customers_transacted_at_n_raynham(accts)\n",
    "\n",
    "# Address near Branch (zip codes)\n",
    "nearby = filter_distinct_customer_near_branches(accts)\n",
    "\n",
    "# Union/concat eligible criteria on cust_id\n",
    "concat_df = pd.concat([assigned, transacted, nearby], ignore_index=True)\n",
    "concat_df = concat_df.drop_duplicates(subset=['customer_id'], keep='first')\n",
    "\n",
    "# Inner join with base customer dim\n",
    "base_customer_dim = base_customer_dim[[\n",
    "    'customer_id',\n",
    "    'customer_type',\n",
    "    'customer_name',\n",
    "    'Active Account Owner',\n",
    "    'loan_net_balance',\n",
    "    'deposit_balance'\n",
    "]].copy()\n",
    "base_customer_dim = base_customer_dim[base_customer_dim['Active Account Owner'] == \"Y\"].copy()\n",
    "customer_df = base_customer_dim.merge(concat_df, how='inner', on='customer_id')\n",
    "\n",
    "# Append primary address\n",
    "customer_address_link = DeltaTable(src.config.SILVER / \"customer_address_link\").to_pandas()\n",
    "customer_address_link = customer_address_link[customer_address_link['addrusecd'] == 'PRI'].copy()\n",
    "customer_address_link = customer_address_link[[\n",
    "    'customer_id',\n",
    "    'addrnbr'\n",
    "]].copy()\n",
    "customer_address_link_schema = {\n",
    "    'addrnbr':'str'\n",
    "}\n",
    "customer_address_link = cdutils.input_cleansing.cast_columns(customer_address_link, customer_address_link_schema)\n",
    "\n",
    "address = DeltaTable(src.config.SILVER / \"address\").to_pandas()\n",
    "address_schema = {\n",
    "    'addrnbr':'str'\n",
    "}\n",
    "address = cdutils.input_cleansing.cast_columns(address, address_schema)\n",
    "address = address.drop(columns='load_timestamp_utc').copy()\n",
    "address = customer_address_link.merge(address, how='inner', on='addrnbr')\n",
    "\n",
    "customer_df = customer_df.merge(address, on='customer_id', how='left')\n",
    "\n",
    "# Need to do exclusions\n",
    "pers_dim = DeltaTable(src.config.SILVER / \"pers_dim\").to_pandas()\n",
    "pers_dim = pers_dim[[\n",
    "    'customer_id',\n",
    "    'age',\n",
    "    'firstname',\n",
    "    'lastname'\n",
    "]].copy()\n",
    "customer_df = customer_df.merge(pers_dim, on='customer_id', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1da66a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82232d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e760455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out records where age < 18 and customer type = 'Person'\n",
    "customer_df = customer_df[~((customer_df['customer_type'] == 'Person') & (customer_df['age'] < 18) | (customer_df['age'] > 90))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3da299",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3793ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # Append pkey\n",
    "# pkey_slice = accts[['customer_id','portfolio_key']].copy()\n",
    "# # Assert a customer id is not associated with multiple portfolio keys\n",
    "# # There is a Many:1 relationship between customers and portfolio key.\n",
    "\n",
    "# customer_df = customer_df.merge(pkey_slice, on='customer_id', how='left')\n",
    "\n",
    "\n",
    "# # Append pkey\n",
    "# pkey_slice = accts[['customer_id', 'portfolio_key']].copy()\n",
    "\n",
    "# # Assert no customers are associated with multiple portfolio keys\n",
    "# portfolio_key_uniques = pkey_slice.groupby('customer_id')['portfolio_key'].nunique()\n",
    "# assert (portfolio_key_uniques == 1).all(), \"Assertion failed: One or more customers are associated with multiple portfolio keys\"\n",
    "\n",
    "# # Deduplicate pkey_slice to handle potential multiplicity (assuming Many:1 relationship)\n",
    "# pkey_slice = pkey_slice.drop_duplicates(subset='customer_id')\n",
    "# customer_df = customer_df.merge(pkey_slice, on='customer_id', how='left')\n",
    "\n",
    "# # Sort in descending order of deposit balance then loan balance, and drop duplicates on portfolio_key\n",
    "# customer_df_portfolio = customer_df.sort_values(['deposit_balance', 'loan_net_balance'], ascending=[False, False]).drop_duplicates(subset=['portfolio_key'])\n",
    "\n",
    "# Just inspect output\n",
    "# Set column order\n",
    "# Write out\n",
    "# Done\n",
    "customer_df = customer_df[[\n",
    "    'customer_id',\n",
    "    'customer_type',\n",
    "    'customer_name',\n",
    "    'Full_Street_Address',\n",
    "    'cityname',\n",
    "    'statecd',\n",
    "    'zipcd',\n",
    "    'firstname',\n",
    "    'lastname',\n",
    "    'eligibility'\n",
    "]].copy()\n",
    "\n",
    "customer_df = customer_df.rename(columns={\n",
    "    'customer_name':'Customer Name',\n",
    "    'Full_Street_Address':'Address',\n",
    "    'cityname': 'City',\n",
    "    'statecd':'State',\n",
    "    'zipcd':'Zip',\n",
    "    'firstname':'First Name',\n",
    "    'lastname':'Last Name'\n",
    "}).copy()\n",
    "\n",
    "return customer_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('./output/raynham_report.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3a95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d25f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import src.config\n",
    "from deltalake import DeltaTable\n",
    "import cdutils.customer_dim # type: ignore\n",
    "import src.raynham_report.fetch_data\n",
    "import cdutils.input_cleansing # type: ignore\n",
    "\n",
    "def filter_distinct_customers_assigned_to_n_raynham(df):\n",
    "    \"\"\"\n",
    "    Unique customers that are assigned to branch in question\n",
    "    \"\"\"\n",
    "    filtered_df = df[df['branchname'] == 'BCSB - NORTH RAYNHAM BRANCH'].copy()\n",
    "    distinct_customers = filtered_df[['customer_id']].drop_duplicates()\n",
    "    distinct_customers['eligibility'] = 'Assigned to N Raynham'\n",
    "    return distinct_customers\n",
    "\n",
    "def filter_distinct_customers_transacted_at_n_raynham(accts):\n",
    "    \"\"\"\n",
    "    Unique accounts that have transacted at branch in question\n",
    "    \"\"\"\n",
    "    data = src.raynham_report.fetch_data.fetch_rtxn_data()\n",
    "    transacted = data['transacted'].copy()\n",
    "    transacted_schema = {\n",
    "        'acctnbr':'str'\n",
    "    }\n",
    "    transacted = cdutils.input_cleansing.cast_columns(transacted, transacted_schema)\n",
    "    transacted = transacted.merge(accts, how='inner', on='acctnbr')\n",
    "    distinct_customers = transacted[['customer_id']].drop_duplicates()\n",
    "    distinct_customers['eligibility'] = 'Transacted at N Raynham within 90 days'\n",
    "\n",
    "    return distinct_customers \n",
    "\n",
    "def filter_distinct_customer_near_branches(accts):\n",
    "    \"\"\"\n",
    "    Unique Customers located near raynham or taunton\n",
    "\n",
    "    Requested was within 5 mi of branch, but for simplicity, we match on primary zip codes\n",
    "    \"\"\"\n",
    "    zip_codes = [\"02767\",\"02780\"]\n",
    "    filtered_df = accts[accts['primaryownerzipcd'].isin(zip_codes)]\n",
    "    distinct_customers = filtered_df[['customer_id']].drop_duplicates()\n",
    "    distinct_customers['eligibility'] = 'Zip Code in Raynham (02767) or Taunton (02780)'\n",
    "    return distinct_customers\n",
    "    \n",
    "\n",
    "# def generate_raynham_report():\n",
    "\"\"\"\n",
    "Objective:\n",
    "\n",
    "To create a person mailing list to North raynham Branch Construction customers\n",
    "\n",
    "Params:\n",
    "\n",
    "Assigned to N Raynham\n",
    "Transacted at N Raynham within 90 days\n",
    "Address within a 5 mile radius of N. Raynham, Raynham Center, Main Office\n",
    "Owns Safe Deposit Box @ N. Raynham\n",
    "Exclusions (do we have standard exclusions for all mailings? Including common ones below)\n",
    "Customers under 18 years of age\n",
    "Deceased customers\n",
    "Charged off accounts\n",
    "\n",
    "\n",
    "Data fields:\n",
    "\n",
    "First name\n",
    "Last name\n",
    "Address\n",
    "City\n",
    "State\n",
    "Zip\n",
    "\"\"\"\n",
    "\n",
    "# Pull in Base Customer Layer\n",
    "base_customer_dim = DeltaTable(src.config.SILVER / \"base_customer_dim\").to_pandas()\n",
    "\n",
    "# Pull in Active Accounts (create a clean customer_id for joining)\n",
    "accts = DeltaTable(src.config.SILVER / \"account\").to_pandas()\n",
    "\n",
    "# Assigned to Branch from Accts\n",
    "assigned = filter_distinct_customers_assigned_to_n_raynham(accts)\n",
    "\n",
    "# Transacted at Branch in last 90 days\n",
    "transacted = filter_distinct_customers_transacted_at_n_raynham(accts)\n",
    "\n",
    "# Address near Branch (zip codes)\n",
    "nearby = filter_distinct_customer_near_branches(accts)\n",
    "\n",
    "# Union/concat eligible criteria on cust_id\n",
    "concat_df = pd.concat([assigned, transacted, nearby], ignore_index=True)\n",
    "concat_df = concat_df.drop_duplicates(subset=['customer_id'], keep='first')\n",
    "\n",
    "# Inner join with base customer dim\n",
    "base_customer_dim = base_customer_dim[[\n",
    "    'customer_id',\n",
    "    'customer_type',\n",
    "    'customer_name',\n",
    "    'Active Account Owner',\n",
    "    'loan_net_balance',\n",
    "    'deposit_balance'\n",
    "]].copy()\n",
    "base_customer_dim = base_customer_dim[base_customer_dim['Active Account Owner'] == \"Y\"].copy()\n",
    "customer_df = base_customer_dim.merge(concat_df, how='inner', on='customer_id')\n",
    "\n",
    "# Append primary address\n",
    "customer_address_link = DeltaTable(src.config.SILVER / \"customer_address_link\").to_pandas()\n",
    "customer_address_link = customer_address_link[customer_address_link['addrusecd'] == 'PRI'].copy()\n",
    "customer_address_link = customer_address_link[[\n",
    "    'customer_id',\n",
    "    'addrnbr'\n",
    "]].copy()\n",
    "customer_address_link_schema = {\n",
    "    'addrnbr':'str'\n",
    "}\n",
    "customer_address_link = cdutils.input_cleansing.cast_columns(customer_address_link, customer_address_link_schema)\n",
    "\n",
    "address = DeltaTable(src.config.SILVER / \"address\").to_pandas()\n",
    "address_schema = {\n",
    "    'addrnbr':'str'\n",
    "}\n",
    "address = cdutils.input_cleansing.cast_columns(address, address_schema)\n",
    "address = address.drop(columns='load_timestamp_utc').copy()\n",
    "address = customer_address_link.merge(address, how='inner', on='addrnbr')\n",
    "\n",
    "customer_df = customer_df.merge(address, on='customer_id', how='left')\n",
    "\n",
    "# Need to do exclusions\n",
    "pers_dim = DeltaTable(src.config.SILVER / \"pers_dim\").to_pandas()\n",
    "pers_dim = pers_dim[[\n",
    "    'customer_id',\n",
    "    'age'\n",
    "]].copy()\n",
    "customer_df = customer_df.merge(pers_dim, on='customer_id', how='left')\n",
    "\n",
    "# Filter out records where age < 18 and customer type = 'Person'\n",
    "customer_df = customer_df[~((customer_df['customer_type'] == 'Person') & (customer_df['age'] < 18))]\n",
    "\n",
    "# Append pkey\n",
    "pkey_slice = accts[['customer_id','portfolio_key']].copy()\n",
    "# Assert a customer id is not associated with multiple portfolio keys\n",
    "# There is a Many:1 relationship between customers and portfolio key.\n",
    "\n",
    "# Append pkey\n",
    "pkey_slice = accts[['customer_id', 'portfolio_key']].copy()\n",
    "\n",
    "# Assert no customers are associated with multiple portfolio keys\n",
    "portfolio_key_uniques = pkey_slice.groupby('customer_id')['portfolio_key'].nunique().reset_index()\n",
    "\n",
    "# IOLTA orgs will be tied to mulitple customers - edge case identified, but not an issue.\n",
    "# assert (portfolio_key_uniques == 1).all(), \"Assertion failed: One or more customers are associated with multiple portfolio keys\"\n",
    "\n",
    "# Deduplicate pkey_slice to handle potential multiplicity (assuming Many:1 relationship)\n",
    "pkey_slice = pkey_slice.drop_duplicates(subset='customer_id')\n",
    "customer_df = customer_df.merge(pkey_slice, on='customer_id', how='left')\n",
    "\n",
    "# Sort in descending order of deposit balance then loan balance, and drop duplicates on portfolio_key\n",
    "customer_df_portfolio = customer_df.sort_values(['deposit_balance', 'loan_net_balance'], ascending=[False, False]).drop_duplicates(subset=['portfolio_key'])\n",
    "\n",
    "# Just inspect output\n",
    "# Set column order\n",
    "# Write out\n",
    "# Done\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1714c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c61a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_key_uniques.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815d097b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcsb-prod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
