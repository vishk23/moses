{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd # type: ignore\n",
    "\n",
    "import src.balance_tracker_pipeline_v2\n",
    "import src.cdutils.database.sliding_window\n",
    "import src.excel_output\n",
    "import src.monthly_delta\n",
    "from src._version import __version__\n",
    "\n",
    "# Fetch Data from COCC\n",
    "data_prior, data_current = src.cdutils.database.sliding_window.fetch_data()\n",
    "\n",
    "_, data_prior_summary = src.balance_tracker_pipeline_v2.main_pipeline_bt(data_prior)\n",
    "full_data_current, data_current_summary = src.balance_tracker_pipeline_v2.main_pipeline_bt(data_current)\n",
    "\n",
    "# OUTPUT_PATH = Path('./output/data_prior_summary.xlsx')\n",
    "# data_prior_summary.to_excel(OUTPUT_PATH, engine='openpyxl', index=False)\n",
    "\n",
    "# OUTPUT_PATH = Path('./output/data_current_summary.xlsx')\n",
    "# data_current_summary.to_excel(OUTPUT_PATH, engine='openpyxl', index=False)\n",
    "\n",
    "monthly_delta = src.monthly_delta.creating_monthly_delta(data_prior_summary, data_current_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg_rate(df: pd.DataFrame, title: str='Weighted Avg Rate') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create weighted average rate\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['WeightedRate'] = df['Net Balance'] * df['noteintrate']\n",
    "    grouped_df = df.groupby('Category').apply(\n",
    "        lambda x: x['WeightedRate'].sum() / x['Net Balance'].sum(), include_groups=False\n",
    "    ).reset_index(name=title).copy()\n",
    "    return grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_and_unadvanced_creation(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Takes the full data current (from the main pipeline) and creates a total loan yield, new loan yield, and unadvanced funds for every category\n",
    "\n",
    "    Args:\n",
    "        df (pd.Dataframe): This is the full_data_current from the current output of the pipeline function\n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): Simple table that will be added to the right most columns of the balance tracker in a separate excel update function\n",
    "    \"\"\"\n",
    "    # Manual Rate Adjustments for Heat Loans (CNS) WSJ + 100 bp\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['noteintrate'] = np.where(\n",
    "        (df['currmiaccttypcd'] == 'IL33') & (df['contractdate'] >= pd.Timestamp(2025,1,1)), .07,\n",
    "        np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2024,12,19)), .085,\n",
    "        np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2024,12,19)), .085,\n",
    "        np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2024,11,8)), .0875,\n",
    "        np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2024,9,19)), .09,\n",
    "        np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2023,7,27)), .095,\n",
    "        np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2023,5,4)), .0925,\n",
    "        np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2023,3,23)), .09,\n",
    "        np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2023,2,2)), .0875,\n",
    "        np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,12,16)), .085,\n",
    "        np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,11,3)), .08,\n",
    "        np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,9,22)), .0725,\n",
    "        np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,7,28)), .065,\n",
    "        np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,6,16)), .0575,\n",
    "        np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])), .05,\n",
    "        df['noteintrate']))))))))))))))\n",
    "    )\n",
    "\n",
    "    # Create total yield\n",
    "    total_yield = weighted_avg_rate(df, title='Total Loan Yield')\n",
    "\n",
    "    # Create new loan yield\n",
    "    datetime_cols = ['effdate','origdate']\n",
    "    for col in datetime_cols:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "    new_loan_df = df[\n",
    "        (df['origdate'].dt.month == df['effdate'].dt.month) & (df['origdate'].dt.year == df['effdate'].dt.year)\n",
    "    ].copy()\n",
    "\n",
    "    new_yield = weighted_avg_rate(new_loan_df, title='New Loan Yield')\n",
    "\n",
    "    df['Unadvanced'] = df['Total Exposure'] - df['Net Balance']\n",
    "\n",
    "    # Unadvanced\n",
    "    unadvanced = df.groupby('Category')['Unadvanced'].sum().reset_index()\n",
    "    unadvanced = unadvanced.rename(columns={'Unadvanced':'Unadvanced Funds'})\n",
    "\n",
    "    # Merge\n",
    "    merged_df = pd.merge(new_yield, total_yield, how='inner', on='Category')\n",
    "    merged_df = pd.merge(merged_df, unadvanced, how='inner', on='Category')\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = yield_and_unadvanced_creation(full_data_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cdutils.deduplication # type: ignore\n",
    "import cdutils.database.connect # type: ignore\n",
    "import cdutils.input_cleansing # type: ignore\n",
    "from sqlalchemy import text # type: ignore\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_from_acctuserfield():\n",
    "    \"\"\"\n",
    "    Gets data from COCC\n",
    "    \"\"\"\n",
    "    wh_acctuserfields = text(f\"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM \n",
    "        OSIBANK.WH_ACCTUSERFIELDS a\n",
    "    \"\"\")\n",
    "\n",
    "    queries = [\n",
    "        {'key':'wh_acctuserfields', 'sql':wh_acctuserfields, 'engine':1},\n",
    "    ]\n",
    "\n",
    "    data = cdutils.database.connect.retrieve_data(queries)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acctuser = fetch_from_acctuserfield()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acctuser = acctuser['wh_acctuserfields'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acctuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splt = acctuser[acctuser['acctuserfieldcd'] == 'SPLT'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert splt['acctnbr'].is_unique, \"Failure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using the lookup query to inspect the DB tables\n",
    "\"\"\"\n",
    "\n",
    "import cdutils.database.connect # type: ignore\n",
    "from sqlalchemy import text # type: ignore\n",
    "\n",
    "def fetch_data():\n",
    "    \"\"\"\n",
    "    Main data query\n",
    "    \"\"\"\n",
    "    # Engine 1\n",
    "    lookup_df = text(\"\"\"\n",
    "    SELECT \n",
    "        *\n",
    "    FROM \n",
    "        sys.all_tab_columns col\n",
    "    \"\"\")\n",
    "\n",
    "    queries = [\n",
    "        # {'key':'acctcommon', 'sql':acctcommon, 'engine':2},\n",
    "        {'key':'lookup_df', 'sql':lookup_df, 'engine':2},\n",
    "    ]\n",
    "\n",
    "\n",
    "    data = cdutils.database.connect.retrieve_data(queries)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = lookup['lookup_df'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cdutils.deduplication # type: ignore\n",
    "import cdutils.database.connect # type: ignore\n",
    "import cdutils.input_cleansing # type: ignore\n",
    "from sqlalchemy import text # type: ignore\n",
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "# ------------------------------------------------------------------\n",
    "# --- 1.  Runtime inputs -------------------------------------------\n",
    "# ------------------------------------------------------------------\n",
    "begin_dt: datetime = datetime(2024, 3, 1)   # ← change as you like\n",
    "end_dt:   datetime = datetime(2024, 3, 31)\n",
    "resi_minors       = [\"MG48\", \"MG50\", \"MG52\", \"MG55\", \"MG60\"]\n",
    "secondary_codes   = [\"DDSB\", \"OPA\"]\n",
    "cml_minors        = [\"CM06\", \"CM30\", \"CM52\"]\n",
    "disb_codes_cml    = [\"PDSB\", \"SWPI\"]\n",
    "receipt_codes_cml = [\"PRCT\", \"SWPR\"]\n",
    "# ------------------------------------------------------------------\n",
    "# --- 2.  Helpers ---------------------------------------------------\n",
    "# ------------------------------------------------------------------\n",
    "def sql_list(py_list):\n",
    "    \"\"\"Turn ['A','B'] →  'A','B'  for SQL IN (...)\"\"\"\n",
    "    return \", \".join(f\"'{x}'\" for x in py_list)\n",
    "def to_date_literal(dt: datetime) -> str:\n",
    "    \"\"\"\n",
    "    Return an Oracle-friendly TO_DATE literal.\n",
    "      2024-03-15  →  TO_DATE('2024-03-15','YYYY-MM-DD')\n",
    "    If the value has a time component, include it:\n",
    "      2024-03-15 14:07:00  →  TO_DATE('2024-03-15 14:07:00','YYYY-MM-DD HH24:MI:SS')\n",
    "    \"\"\"\n",
    "    fmt_date = \"%Y-%m-%d %H:%M:%S\" if isinstance(dt, datetime) and dt.time() != datetime.min.time() else \"%Y-%m-%d\"\n",
    "    date_str = dt.strftime(fmt_date)\n",
    "    mask     = \"YYYY-MM-DD HH24:MI:SS\" if \" \" in date_str else \"YYYY-MM-DD\"\n",
    "    return f\"TO_DATE('{date_str}','{mask}')\"\n",
    "# Pre-formatted pieces\n",
    "resi_minors_sql        = sql_list(resi_minors)\n",
    "secondary_codes_sql    = sql_list(secondary_codes)\n",
    "cml_minors_sql         = sql_list(cml_minors)\n",
    "disb_codes_cml_sql     = sql_list(disb_codes_cml)\n",
    "receipt_codes_cml_sql  = sql_list(receipt_codes_cml)\n",
    "start_date = \"2025-03-01 00:00:00\"\n",
    "end_date = \"2025-03-31 00:00:00\"\n",
    "# ------------------------------------------------------------------\n",
    "# --- 3.  Compose the SQL ------------------------------------------\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def fetch_from_database():\n",
    "    \"\"\"\n",
    "    Gets data from COCC\n",
    "    \"\"\"\n",
    "    rtxn = text(f\"\"\"\n",
    "    SELECT\n",
    "        a.RTXNNBR,\n",
    "        a.RTXNTYPCD,\n",
    "        a.ACCTNBR,\n",
    "        a.TRANAMT\n",
    "    FROM\n",
    "        COCCDM.WH_RTXN a\n",
    "    WHERE\n",
    "        a.RUNDATE BETWEEN TO_DATE('{start_date}','yyyy-mm-dd hh24:mi:ss') AND TO_DATE('{end_date}','yyyy-mm-dd hh24:mi:ss')\n",
    "    \"\"\")\n",
    "\n",
    "    queries = [\n",
    "        {'key':'rtxn', 'sql':rtxn, 'engine':2},\n",
    "    ]\n",
    "\n",
    "    data = cdutils.database.connect.retrieve_data(queries)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_from_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtxn = data['rtxn'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_from_database():\n",
    "    \"\"\"\n",
    "    Gets data from COCC\n",
    "    \"\"\"\n",
    "    acctcommon = text(f\"\"\"\n",
    "    SELECT\n",
    "        a.ACCTNBR,\n",
    "        a.CURRMIACCTTYPCD\n",
    "    FROM\n",
    "        OSIBANK.WH_ACCTCOMMON a\n",
    "    \"\"\")\n",
    "\n",
    "    queries = [\n",
    "        {'key':'acctcommon', 'sql':acctcommon, 'engine':1},\n",
    "    ]\n",
    "\n",
    "    data = cdutils.database.connect.retrieve_data(queries)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_from_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = data['acctcommon'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdutils.input_cleansing # type: ignore\n",
    "\n",
    "rtxn_schema = {\n",
    "    'acctnbr': str\n",
    "}\n",
    "\n",
    "rtxn = cdutils.input_cleansing.enforce_schema(rtxn, rtxn_schema)\n",
    "\n",
    "ac_schema = {\n",
    "    'acctnbr': str\n",
    "}\n",
    "ac = cdutils.input_cleansing.enforce_schema(ac, ac_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtxn = pd.merge(rtxn, ac, how='left', on='acctnbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resi_minors       = [\"MG48\", \"MG50\", \"MG52\", \"MG55\", \"MG60\"]\n",
    "resi_codes        = [\"PDSB\",\"CWTH\",\"CKUS\",\"XDSB\"]\n",
    "secondary_codes   = [\"PDSB\", \"OPA\"]\n",
    "cml_minors        = [\"CM06\", \"CM30\", \"CM52\"]\n",
    "disb_codes_cml    = [\"PDSB\", \"SWPI\"]\n",
    "receipt_codes_cml = [\"PRCT\", \"SWPR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtxn['adv_calc'] = abs(np.where((rtxn['currmiaccttypcd'].isin(resi_minors)) and (rtxn['tranamt'] < 0) and (rtxn['trantypcd'].isin(resi_codes)), rtxn['tranamt'],\n",
    "                            (np.where(rtxn['trantypcd'].isin(secondary_codes) and (~(rtxn['currmiaccttypcd']).isin(cml_minors))), rtxn['tranamt'],\n",
    "                            0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Balance Tracker - revised\n",
    "Developed by CD\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd # type: ignore\n",
    "\n",
    "import src.addition_fields\n",
    "import src.balance_tracker_pipeline_v2\n",
    "import src.cdutils.database.sliding_window\n",
    "import src.excel_output\n",
    "import src.monthly_delta\n",
    "from src._version import __version__\n",
    "import cdutils.distribution # type: ignore\n",
    "\n",
    "# def main():\n",
    "# Fetch Data from COCC\n",
    "data_prior, data_current = src.cdutils.database.sliding_window.fetch_data()\n",
    "\n",
    "_, data_prior_summary = src.balance_tracker_pipeline_v2.main_pipeline_bt(data_prior)\n",
    "full_data_current, data_current_summary = src.balance_tracker_pipeline_v2.main_pipeline_bt(data_current)\n",
    "\n",
    "# OUTPUT_PATH = Path('./output/data_prior_summary.xlsx')\n",
    "# data_prior_summary.to_excel(OUTPUT_PATH, engine='openpyxl', index=False)\n",
    "\n",
    "# OUTPUT_PATH = Path('./output/data_current_summary.xlsx')\n",
    "# data_current_summary.to_excel(OUTPUT_PATH, engine='openpyxl', index=False)\n",
    "\n",
    "monthly_delta = src.monthly_delta.creating_monthly_delta(data_prior_summary, data_current_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_data_current.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def yield_and_unadvanced_creation(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\"\"\"\n",
    "Takes the full data current (from the main pipeline) and creates a total loan yield, new loan yield, and unadvanced funds for every category\n",
    "\n",
    "Args:\n",
    "    df (pd.Dataframe): This is the full_data_current from the current output of the pipeline function\n",
    "\n",
    "Returns:\n",
    "    df (pd.DataFrame): Simple table that will be added to the right most columns of the balance tracker in a separate excel update function\n",
    "\"\"\"\n",
    "# Manual Rate Adjustments for Heat Loans (CNS) WSJ + 100 bp\n",
    "df = df.copy()\n",
    "\n",
    "# Adjustment for the Consumer loans: WSJ Prime + 1\n",
    "df['modified_noteintrate'] = np.where(\n",
    "    (df['currmiaccttypcd'] == 'IL33') & (df['contractdate'] >= pd.Timestamp(2025,1,1)), .07,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2024,12,19)), .085,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2024,12,19)), .085,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2024,11,8)), .0875,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2024,9,19)), .09,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2023,7,27)), .095,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2023,5,4)), .0925,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2023,3,23)), .09,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2023,2,2)), .0875,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,12,16)), .085,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,11,3)), .08,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,9,22)), .0725,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,7,28)), .065,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,6,16)), .0575,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])), .05,\n",
    "    df['noteintrate']))))))))))))))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Attach dealer split rate and subtract this from noteint rate\n",
    "df = cdutils.dealer_split.append_dealersplit(df)\n",
    "print(df.info())\n",
    "df['modified_noteintrate'] = np.where(df['Category'] == 'Indirect', df['modified_noteintrate'] - df['SPLT'], df['modified_noteintrate'])\n",
    "\n",
    "\n",
    "\n",
    "# Create total yield\n",
    "total_yield = weighted_avg_rate(df, title='Total Loan Yield')\n",
    "\n",
    "# Create new loan yield\n",
    "datetime_cols = ['effdate','origdate']\n",
    "for col in datetime_cols:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "new_loan_df = df[\n",
    "    (df['origdate'].dt.month == df['effdate'].dt.month) & (df['origdate'].dt.year == df['effdate'].dt.year)\n",
    "].copy()\n",
    "\n",
    "# # Attach transaction amt\n",
    "\n",
    "# # Create advances column\n",
    "# resi_minor_\n",
    "# new_loan_df['Advances'] = np.where(\n",
    "#     ()\n",
    "# )\n",
    "\n",
    "new_yield = weighted_avg_rate(new_loan_df, title='New Loan Yield')\n",
    "\n",
    "df['Unadvanced'] = (df['availbalamt']) / 1000\n",
    "\n",
    "# Unadvanced\n",
    "unadvanced = df.groupby('Category')['Unadvanced'].sum().reset_index()\n",
    "unadvanced = unadvanced.rename(columns={'Unadvanced':'Unadvanced Funds'})\n",
    "\n",
    "# Merge\n",
    "merged_df = pd.merge(new_yield, total_yield, how='inner', on='Category')\n",
    "merged_df = pd.merge(merged_df, unadvanced, how='inner', on='Category')\n",
    "\n",
    "return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_fields = src.addition_fields.yield_and_unadvanced_creation(full_data_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "TEMPLATE_PATH = Path('./output/Portfolio_Balance_Tracker_2025YTD.xlsx')\n",
    "OUTPUT_PATH = Path('./output/Portfolio_Balance_Tracker_2025YTD.xlsx')\n",
    "# OUTPUT_PATH = Path('./output/Portfolio_Balance_Tracker_2025YTD_test.xlsx')\n",
    "\n",
    "src.excel_output.update_excel_template(TEMPLATE_PATH, monthly_delta, additional_fields, OUTPUT_PATH)\n",
    "\n",
    "# Distribution \n",
    "recipients = [\n",
    "    \"chad.doorley@bcsbmail.com\"\n",
    "    # \"Timothy.Chaves@bcsbmail.com\",\n",
    "    # \"John.Silva@bcsbmail.com\",\n",
    "    # \"Dawn.Young@bcsbmail.com\",\n",
    "    # \"Christopher.Alves@bcsbmail.com\",\n",
    "    # \"donna.oliveira@bcsbmail.com\",\n",
    "    # \"nancy.pimentel@bcsbmail.com\",\n",
    "    # \"Hasan.Ali@bcsbmail.com\",\n",
    "    # \"Michael.Patacao@bcsbmail.com\",\n",
    "    # \"Jeffrey.Pagliuca@bcsbmail.com\",\n",
    "    # \"Erin.Riendeau@bcsbmail.com\",\n",
    "    # \"donna.pavao@bcsbmail.com\"\n",
    "]\n",
    "bcc_recipients = [\n",
    "    \"chad.doorley@bcsbmail.com\",\n",
    "    \"businessintelligence@bcsbmail.com\"\n",
    "]\n",
    "subject = f\"Balance Tracker YTD - Through April 2025\" \n",
    "body = \"Hi all, \\n\\nAttached is the Balance Tracker through the most recent month end. If you have any questions, please reach out to BusinessIntelligence@bcsbmail.com\\n\"\n",
    "attachment_paths = [OUTPUT_PATH]\n",
    "\n",
    "cdutils.distribution.email_out(\n",
    "    recipients = recipients, \n",
    "    bcc_recipients = bcc_recipients, \n",
    "    subject = subject, \n",
    "    body = body, \n",
    "    attachment_paths = attachment_paths\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "print(f\"Starting {__version__}\")\n",
    "main()\n",
    "print(\"Complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdutils.deduplication # type: ignore\n",
    "import cdutils.database.connect # type: ignore\n",
    "import cdutils.input_cleansing # type: ignore\n",
    "from sqlalchemy import text # type: ignore\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_from_acctuserfield():\n",
    "        \"\"\"\n",
    "        Gets data from COCC\n",
    "        \"\"\"\n",
    "        wh_acctuserfields = text(f\"\"\"\n",
    "        SELECT\n",
    "            *\n",
    "        FROM \n",
    "            OSIBANK.WH_ACCTUSERFIELDS a\n",
    "        \"\"\")\n",
    "\n",
    "        queries = [\n",
    "            {'key':'wh_acctuserfields', 'sql':wh_acctuserfields, 'engine':1},\n",
    "        ]\n",
    "\n",
    "        data = cdutils.database.connect.retrieve_data(queries)\n",
    "        return data\n",
    "\n",
    "\n",
    "# def append_dealersplit(df: pd.DataFrame):\n",
    "\"\"\"\n",
    "Attach secondary lending officer to any dataframe\n",
    "\"\"\"\n",
    "\n",
    "data = fetch_from_acctuserfield()\n",
    "\n",
    "wh_acctuserfields = data['wh_acctuserfields'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_acctuserfields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splt = wh_acctuserfields[wh_acctuserfields['acctuserfieldcd'] == 'SPLT'].copy()\n",
    "\n",
    "splt = splt.sort_values(by='datelastmaint', ascending=False).copy()\n",
    "splt = cdutils.deduplication.dedupe([{'df':splt, 'field':'acctnbr'}])\n",
    "\n",
    "\n",
    "# Asserts\n",
    "assert splt['acctnbr'].is_unique, \"splt not unique on acctnbr\"\n",
    "\n",
    "\n",
    "splt = splt[['acctnbr','acctuserfieldvalue']].copy()\n",
    "\n",
    "splt = splt.rename(columns={'acctuserfieldvalue':'SPLT'}).copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splt['SPLT'] = pd.to_numeric(splt['SPLT'], errors=\"coerce\").fillna(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "schema_df = {\n",
    "            'acctnbr': str,\n",
    "        }\n",
    "\n",
    "df = cdutils.input_cleansing.enforce_schema(df, schema_df)\n",
    "\n",
    "schema_splt = {\n",
    "            'acctnbr': str,\n",
    "            'SPLT': float\n",
    "        }\n",
    "\n",
    "splt = cdutils.input_cleansing.enforce_schema(splt, schema_splt)\n",
    "\n",
    "assert df['acctnbr'].is_unique, \"acctnbr not unique in df\"\n",
    "\n",
    "final_df = pd.merge(df, splt, on='acctnbr', how='left')\n",
    "\n",
    "# return final_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['SPLT'] = pd.to_numeric(final_df['SPLT'], errors=\"coerce\").fillna(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[final_df['Category'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2025-05-09\n",
    "\"\"\"\n",
    "Balance Tracker - revised\n",
    "Developed by CD\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd # type: ignore\n",
    "\n",
    "import src.addition_fields\n",
    "import src.balance_tracker_pipeline_v3\n",
    "import src.excel_output\n",
    "import src.fetch_data\n",
    "import src.monthly_delta\n",
    "from src._version import __version__\n",
    "import cdutils.distribution # type: ignore\n",
    "\n",
    "# def main():\n",
    "# Fetch Data from COCC\n",
    "data_prior, data_current = src.fetch_data.fetch_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, data_prior_summary = src.balance_tracker_pipeline_v3.main_pipeline_bt(data_prior)\n",
    "full_data_current, data_current_summary = src.balance_tracker_pipeline_v3.main_pipeline_bt(data_current)\n",
    "\n",
    "# OUTPUT_PATH = Path('./output/data_prior_summary.xlsx')\n",
    "# data_prior_summary.to_excel(OUTPUT_PATH, engine='openpyxl', index=False)\n",
    "\n",
    "# OUTPUT_PATH = Path('./output/data_current_summary.xlsx')\n",
    "# data_current_summary.to_excel(OUTPUT_PATH, engine='openpyxl', index=False)\n",
    "\n",
    "monthly_delta = src.monthly_delta.creating_monthly_delta(data_prior_summary, data_current_summary)\n",
    "additional_fields = src.addition_fields.yield_and_unadvanced_creation(full_data_current)\n",
    "\n",
    "\n",
    "#     TEMPLATE_PATH = Path('./output/Portfolio_Balance_Tracker_2025YTD.xlsx')\n",
    "#     OUTPUT_PATH = Path('./output/Portfolio_Balance_Tracker_2025YTD.xlsx')\n",
    "#     # OUTPUT_PATH = Path('./output/Portfolio_Balance_Tracker_2025YTD_test.xlsx')\n",
    "\n",
    "#     src.excel_output.update_excel_template(TEMPLATE_PATH, monthly_delta, additional_fields, OUTPUT_PATH)\n",
    "\n",
    "#     # Distribution \n",
    "#     recipients = [\n",
    "#         # \"chad.doorley@bcsbmail.com\"\n",
    "#         \"Timothy.Chaves@bcsbmail.com\",\n",
    "#         \"John.Silva@bcsbmail.com\",\n",
    "#         \"Dawn.Young@bcsbmail.com\",\n",
    "#         \"Christopher.Alves@bcsbmail.com\",\n",
    "#         \"donna.oliveira@bcsbmail.com\",\n",
    "#         \"nancy.pimentel@bcsbmail.com\",\n",
    "#         \"Hasan.Ali@bcsbmail.com\",\n",
    "#         \"Michael.Patacao@bcsbmail.com\",\n",
    "#         \"Jeffrey.Pagliuca@bcsbmail.com\",\n",
    "#         \"Erin.Riendeau@bcsbmail.com\",\n",
    "#         \"donna.pavao@bcsbmail.com\"\n",
    "#     ]\n",
    "#     bcc_recipients = [\n",
    "#         \"chad.doorley@bcsbmail.com\",\n",
    "#         \"businessintelligence@bcsbmail.com\"\n",
    "#     ]\n",
    "#     subject = f\"Balance Tracker YTD - Through April 2025\" \n",
    "#     body = \"Hi all, \\n\\nAttached is the Balance Tracker through the most recent month end. If you have any questions, please reach out to BusinessIntelligence@bcsbmail.com\\n\\n\"\n",
    "#     attachment_paths = [OUTPUT_PATH]\n",
    "\n",
    "#     cdutils.distribution.email_out(\n",
    "#         recipients = recipients, \n",
    "#         bcc_recipients = bcc_recipients, \n",
    "#         subject = subject, \n",
    "#         body = body, \n",
    "#         attachment_paths = attachment_paths\n",
    "#         )\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     print(f\"Starting {__version__}\")\n",
    "#     main()\n",
    "#     print(\"Complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_data_current.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Weighted Average Rate & Unadvanced Funds\n",
    "\"\"\"\n",
    "import cdutils.dealer_split # type: ignore\n",
    "\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "\n",
    "\n",
    "def weighted_avg_rate(df: pd.DataFrame, title: str='Weighted Avg Rate', weight_col: str = 'Net Balance', value_col: str = 'modified_noteintrate') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create weighted average rate\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['WeightedRate'] = df[weight_col] * df[value_col]\n",
    "    grouped_df = df.groupby('Category').apply(\n",
    "        lambda x: x['WeightedRate'].sum() / x[weight_col].sum(), include_groups=False\n",
    "    ).reset_index(name=title).copy()\n",
    "    return grouped_df\n",
    "\n",
    "# def yield_and_unadvanced_creation(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Takes the full data current (from the main pipeline) and creates a total loan yield, new loan yield, and unadvanced funds for every category\n",
    "\n",
    "#     Args:\n",
    "#         df (pd.Dataframe): This is the full_data_current from the current output of the pipeline function\n",
    "\n",
    "#     Returns:\n",
    "#         df (pd.DataFrame): Simple table that will be added to the right most columns of the balance tracker in a separate excel update function\n",
    "#     \"\"\"\n",
    "# Manual Rate Adjustments for Heat Loans (CNS) WSJ + 100 bp\n",
    "df = df.copy()\n",
    "\n",
    "# Adjustment for the Consumer loans: WSJ Prime + 1\n",
    "df['modified_noteintrate'] = np.where(\n",
    "    (df['currmiaccttypcd'] == 'IL33') & (df['contractdate'] >= pd.Timestamp(2025,1,1)), .07,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2024,12,19)), .085,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2024,11,8)), .0875,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2024,9,19)), .09,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2023,7,27)), .095,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2023,5,4)), .0925,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2023,3,23)), .09,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2023,2,2)), .0875,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,12,16)), .085,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,11,3)), .08,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,9,22)), .0725,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,7,28)), .065,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,6,16)), .0575,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])), .05,\n",
    "    df['noteintrate'])))))))))))))\n",
    ")\n",
    "\n",
    "# Attach dealer split rate and subtract this from noteint rate\n",
    "df = cdutils.dealer_split.append_dealersplit(df)\n",
    "df['modified_noteintrate'] = np.where(df['Category'] == 'Indirect', df['modified_noteintrate'] - df['SPLT'], df['modified_noteintrate'])\n",
    "\n",
    "\n",
    "\n",
    "# Create total yield\n",
    "total_yield = weighted_avg_rate(df, title='Total Loan Yield')\n",
    "\n",
    "# Create new loan yield\n",
    "datetime_cols = ['effdate','origdate']\n",
    "for col in datetime_cols:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "new_loan_df = df[\n",
    "    (df['origdate'].dt.month == df['effdate'].dt.month) & (df['origdate'].dt.year == df['effdate'].dt.year)\n",
    "].copy()\n",
    "\n",
    "# # Attach transaction amt\n",
    "\n",
    "# # Create advances column\n",
    "# resi_minor_\n",
    "# new_loan_df['Advances'] = np.where(\n",
    "#     ()\n",
    "# )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_loan_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = new_loan_df[new_loan_df['currmiaccttypcd'] == \"CM06\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we need to create a new column that would be the new balance + advances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = new_loan_df['effdate'].iloc[0].strftime('%Y-%m-01 00:00:00')\n",
    "end_date = new_loan_df['effdate'].iloc[0].strftime('%Y-%m-%d 00:00:00')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_rtxn():\n",
    "    \"\"\"\n",
    "    Gets data from COCC\n",
    "    \"\"\"\n",
    "    rtxn = text(f\"\"\"\n",
    "    SELECT\n",
    "        a.RTXNNBR,\n",
    "        a.RTXNTYPCD,\n",
    "        a.ACCTNBR,\n",
    "        a.TRANAMT\n",
    "    FROM\n",
    "        COCCDM.WH_RTXN a\n",
    "    WHERE\n",
    "        a.RUNDATE BETWEEN TO_DATE('{start_date}','yyyy-mm-dd hh24:mi:ss') AND TO_DATE('{end_date}','yyyy-mm-dd hh24:mi:ss')\n",
    "    \"\"\")\n",
    "\n",
    "    acctcommon = text(f\"\"\"\n",
    "    SELECT\n",
    "        a.ACCTNBR,\n",
    "        a.CURRMIACCTTYPCD\n",
    "    FROM\n",
    "        OSIBANK.WH_ACCTCOMMON a\n",
    "    \"\"\")\n",
    "\n",
    "    queries = [\n",
    "        {'key':'rtxn', 'sql':rtxn, 'engine':2},\n",
    "        {'key':'acctcommon', 'sql':acctcommon, 'engine':1},\n",
    "    ]\n",
    "\n",
    "    data = cdutils.database.connect.retrieve_data(queries)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtxn_data_pack = fetch_rtxn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acctcommon = rtxn_data_pack['acctcommon'].copy()\n",
    "rtxn = rtxn_data_pack['rtxn'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtxn_schema = {'tranamt': 'float', 'acctnbr':'str'}\n",
    "rtxn = cdutils.input_cleansing.enforce_schema(rtxn, rtxn_schema)\n",
    "\n",
    "acctcommon_schema = {'acctnbr':'str'}\n",
    "acctcommon = cdutils.input_cleansing.enforce_schema(acctcommon, acctcommon_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtxn = pd.merge(rtxn, acctcommon, how='left', on='acctnbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "resi_minors       = [\"MG48\", \"MG50\", \"MG52\", \"MG55\", \"MG60\"]\n",
    "resi_codes        = [\"PDSB\",\"CWTH\",\"CKUS\",\"XDSB\"]\n",
    "secondary_codes   = [\"PDSB\", \"OPA\"]\n",
    "cml_minors        = [\"CM06\", \"CM30\", \"CM52\"]\n",
    "disb_codes_cml    = [\"PDSB\", \"SWPI\"]\n",
    "receipt_codes_cml = [\"PRCT\", \"SWPR\"]\n",
    "\"\"\"\n",
    "resi_minors = (\"MG48\", \"MG50\", \"MG52\", \"MG55\", \"MG60\")\n",
    "resi_codes = (\"PDSB\",\"CWTH\",\"CKUS\",\"XDSB\")\n",
    "secondary_codes = (\"PDSB\", \"OPA\")\n",
    "cml_minors = (\"CM06\", \"CM30\", \"CM52\")\n",
    "disb_codes_cml = (\"PDSB\", \"SWPI\")\n",
    "receipt_codes_cml = (\"PRCT\", \"SWPR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_net_advances(row):\n",
    "    if (row['currmiaccttypcd'] in resi_minors) and (row['tranamt'] < 0) and (row['rtxntypcd'] in resi_codes):\n",
    "        return row['tranamt']\n",
    "    elif (row['rtxntypcd'] in secondary_codes) and (row['currmiaccttypcd'] not in cml_minors):\n",
    "        return row['tranamt']\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtxn['net advances'] = rtxn.apply(calculate_net_advances, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rtxn['net advances'] = abs(rtxn['net advances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtxn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minor_df = rtxn.groupby('currmiaccttypcd')['net advances'].sum().reset_index()\n",
    "minor_df['net advances'] = abs(minor_df['net advances'])\n",
    "minor_df = minor_df.sort_values(by='net advances', ascending=False)\n",
    "minor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdsb = rtxn[rtxn['rtxntypcd'] == 'PDSB'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdsb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdsb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_yield = weighted_avg_rate(new_loan_df, title='New Loan Yield')\n",
    "\n",
    "df['Unadvanced'] = (df['availbalamt']) / 1000\n",
    "\n",
    "# Unadvanced\n",
    "unadvanced = df.groupby('Category')['Unadvanced'].sum().reset_index()\n",
    "unadvanced = unadvanced.rename(columns={'Unadvanced':'Unadvanced Funds'})\n",
    "\n",
    "# Merge\n",
    "merged_df = pd.merge(new_yield, total_yield, how='inner', on='Category')\n",
    "merged_df = pd.merge(merged_df, unadvanced, how='inner', on='Category')\n",
    "\n",
    "    # return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Balance Tracker - revised\n",
    "Developed by CD\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd # type: ignore\n",
    "\n",
    "import src.addition_fields\n",
    "import src.balance_tracker_pipeline_v3\n",
    "import src.excel_output\n",
    "import src.fetch_data\n",
    "import src.monthly_delta\n",
    "from src._version import __version__\n",
    "import cdutils.distribution # type: ignore\n",
    "\n",
    "# def main():\n",
    "# Fetch Data from COCC\n",
    "data_prior, data_current = src.fetch_data.fetch_data()\n",
    "\n",
    "_, data_prior_summary = src.balance_tracker_pipeline_v3.main_pipeline_bt(data_prior)\n",
    "full_data_current, data_current_summary = src.balance_tracker_pipeline_v3.main_pipeline_bt(data_current)\n",
    "\n",
    "# OUTPUT_PATH = Path('./output/data_prior_summary.xlsx')\n",
    "# data_prior_summary.to_excel(OUTPUT_PATH, engine='openpyxl', index=False)\n",
    "\n",
    "# OUTPUT_PATH = Path('./output/data_current_summary.xlsx')\n",
    "# data_current_summary.to_excel(OUTPUT_PATH, engine='openpyxl', index=False)\n",
    "\n",
    "monthly_delta = src.monthly_delta.creating_monthly_delta(data_prior_summary, data_current_summary)\n",
    "# additional_fields = src.addition_fields.yield_and_unadvanced_creation(full_data_current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Weighted Average Rate & Unadvanced Funds\n",
    "\"\"\"\n",
    "import cdutils.dealer_split # type: ignore\n",
    "import src.fetch_data\n",
    "\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "\n",
    "\n",
    "def weighted_avg_rate(df: pd.DataFrame, title: str='Weighted Avg Rate', weight_col: str = 'Net Balance', value_col: str = 'modified_noteintrate') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create weighted average rate\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['WeightedRate'] = df[weight_col] * df[value_col]\n",
    "    grouped_df = df.groupby('Category').apply(\n",
    "        lambda x: x['WeightedRate'].sum() / x[weight_col].sum(), include_groups=False\n",
    "    ).reset_index(name=title).copy()\n",
    "    return grouped_df\n",
    "\n",
    "# def yield_and_unadvanced_creation(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\"\"\"\n",
    "Takes the full data current (from the main pipeline) and creates a total loan yield, new loan yield, and unadvanced funds for every category\n",
    "\n",
    "Args:\n",
    "    df (pd.Dataframe): This is the full_data_current from the current output of the pipeline function\n",
    "\n",
    "Returns:\n",
    "    df (pd.DataFrame): Simple table that will be added to the right most columns of the balance tracker in a separate excel update function\n",
    "\"\"\"\n",
    "# Manual Rate Adjustments for Heat Loans (CNS) WSJ + 100 bp\n",
    "df = full_data_current.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting to make this 1 query. Takes more work than expected\n",
    "# import datetime\n",
    "# from typing import Dict\n",
    "\n",
    "# from sqlalchemy import text # type: ignore\n",
    "\n",
    "# import cdutils.database.connect # Type: ignore\n",
    "\n",
    "# def fetch_rtxn(start_date, end_date):\n",
    "#     \"\"\"\n",
    "#     Gets data from COCC\n",
    "#     \"\"\"\n",
    "#     rtxn = text(f\"\"\"\n",
    "#     SELECT\n",
    "#         t.RTXNNBR,\n",
    "#         t.RTXNTYPCD,\n",
    "#         t.ACCTNBR,\n",
    "#         t.TRANAMT,\n",
    "#         a.CURRMIACCTTYPCD\n",
    "#     FROM\n",
    "#         COCCDM.WH_RTXN t\n",
    "#     JOIN\n",
    "#         COCCDM.WH_ACCTCOMMON a\n",
    "#         ON t.ACCTNBR = a.ACCTNBR\n",
    "#         AND t.RUNDATE = a.EFFDATE\n",
    "#     WHERE\n",
    "#         (a.RUNDATE BETWEEN TO_DATE('{start_date}','yyyy-mm-dd hh24:mi:ss') AND TO_DATE('{end_date}','yyyy-mm-dd hh24:mi:ss')) AND\n",
    "#         (a.CURRRTXNSTATCD = 'C')\n",
    "#     \"\"\")\n",
    "\n",
    "#     acctcommon = text(f\"\"\"\n",
    "#     SELECT\n",
    "#         a.ACCTNBR,\n",
    "#         a.CURRMIACCTTYPCD\n",
    "#     FROM\n",
    "#         COCCDM.WH_ACCTCOMMON_ME a\n",
    "#     \"\"\")\n",
    "\n",
    "#     queries = [\n",
    "#         {'key':'rtxn', 'sql':rtxn, 'engine':2},\n",
    "#         {'key':'acctcommon', 'sql':acctcommon, 'engine':2},\n",
    "#     ]\n",
    "\n",
    "#     data = cdutils.database.connect.retrieve_data(queries)\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "from typing import Dict\n",
    "\n",
    "from sqlalchemy import text # type: ignore\n",
    "\n",
    "import cdutils.database.connect # Type: ignore\n",
    "\n",
    "def fetch_rtxn(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Gets data from COCC\n",
    "    \"\"\"\n",
    "    rtxn = text(f\"\"\"\n",
    "    SELECT\n",
    "        a.RTXNNBR,\n",
    "        a.RTXNTYPCD,\n",
    "        a.ACCTNBR,\n",
    "        a.TRANAMT\n",
    "    FROM\n",
    "        COCCDM.WH_RTXN a\n",
    "    WHERE\n",
    "        (a.RUNDATE BETWEEN TO_DATE('{start_date}','yyyy-mm-dd hh24:mi:ss') AND TO_DATE('{end_date}','yyyy-mm-dd hh24:mi:ss')) AND\n",
    "        (a.CURRRTXNSTATCD = 'C')\n",
    "    \"\"\")\n",
    "\n",
    "    acctcommon = text(f\"\"\"\n",
    "    SELECT\n",
    "        a.ACCTNBR,\n",
    "        a.CURRMIACCTTYPCD\n",
    "    FROM\n",
    "        COCCDM.WH_ACCTCOMMON_ME a\n",
    "    \"\"\")\n",
    "\n",
    "    queries = [\n",
    "        {'key':'rtxn', 'sql':rtxn, 'engine':2},\n",
    "        {'key':'acctcommon', 'sql':acctcommon, 'engine':2},\n",
    "    ]\n",
    "\n",
    "    data = cdutils.database.connect.retrieve_data(queries)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Adjustment for the Consumer loans: WSJ Prime + 1\n",
    "df['modified_noteintrate'] = np.where(\n",
    "    (df['currmiaccttypcd'] == 'IL33') & (df['contractdate'] >= pd.Timestamp(2025,1,1)), .07,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2024,12,19)), .085,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2024,11,8)), .0875,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2024,9,19)), .09,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2023,7,27)), .095,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2023,5,4)), .0925,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2023,3,23)), .09,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2023,2,2)), .0875,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,12,16)), .085,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,11,3)), .08,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,9,22)), .0725,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,7,28)), .065,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])) & (df['contractdate'] >= pd.Timestamp(2022,6,16)), .0575,\n",
    "    np.where((df['currmiaccttypcd'].isin(['IL21','IL31','IL33'])), .05,\n",
    "    df['noteintrate'])))))))))))))\n",
    ")\n",
    "\n",
    "# Attach dealer split rate and subtract this from noteint rate\n",
    "df = cdutils.dealer_split.append_dealersplit(df)\n",
    "df['modified_noteintrate'] = np.where(df['Category'] == 'Indirect', df['modified_noteintrate'] - df['SPLT'], df['modified_noteintrate'])\n",
    "\n",
    "\n",
    "\n",
    "# Create total yield\n",
    "total_yield = weighted_avg_rate(df, title='Total Loan Yield')\n",
    "\n",
    "# Create new loan yield\n",
    "datetime_cols = ['effdate','origdate']\n",
    "for col in datetime_cols:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "new_loan_df = df[\n",
    "    (df['origdate'].dt.month == df['effdate'].dt.month) & (df['origdate'].dt.year == df['effdate'].dt.year)\n",
    "].copy()\n",
    "\n",
    "# Using the Transaction table\n",
    "start_date = new_loan_df['effdate'].iloc[0].strftime('%Y-%m-01 00:00:00')\n",
    "end_date = new_loan_df['effdate'].iloc[0].strftime('%Y-%m-%d 00:00:00')\n",
    "\n",
    "# rtxn_data_pack = fetch_rtxn(start_date, end_date)\n",
    "\n",
    "acctcommon = rtxn_data_pack['acctcommon'].copy()\n",
    "rtxn = rtxn_data_pack['rtxn'].copy() \n",
    "rtxn_schema = {'tranamt': 'float', 'acctnbr':'str'}\n",
    "rtxn = cdutils.input_cleansing.enforce_schema(rtxn, rtxn_schema)\n",
    "\n",
    "acctcommon_schema = {'acctnbr':'str'}\n",
    "acctcommon = cdutils.input_cleansing.enforce_schema(acctcommon, acctcommon_schema)\n",
    "rtxn = pd.merge(rtxn, acctcommon, how='left', on='acctnbr')\n",
    "\n",
    "# Calculting net advances\n",
    "resi_minors = (\"MG48\", \"MG50\", \"MG52\", \"MG55\", \"MG60\")\n",
    "resi_codes = (\"PDSB\",\"CWTH\",\"CKUS\",\"XDSB\")\n",
    "secondary_codes = (\"PDSB\", \"OPA\")\n",
    "cml_minors = (\"CM06\", \"CM30\", \"CM52\")\n",
    "disb_codes_cml = (\"PDSB\", \"SWPI\")\n",
    "receipt_codes_cml = (\"PRCT\", \"SWPR\")\n",
    "\n",
    "def calculate_advances(row):\n",
    "    if (row['currmiaccttypcd'] in resi_minors) and (row['tranamt'] < 0) and (row['rtxntypcd'] in resi_codes):\n",
    "        return row['tranamt']\n",
    "    elif (row['rtxntypcd'] in secondary_codes) and (row['currmiaccttypcd'] not in cml_minors):\n",
    "        return row['tranamt']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "rtxn['advances'] = rtxn.apply(calculate_advances, axis=1)\n",
    "\n",
    "# Here we'll group by acctnbr and sum net advances\n",
    "# Apply abs value to net advances\n",
    "\n",
    "# Create a separate formula on transaction table for the 3 commercial minors that we need to net disb - reciepts\n",
    "# or embed this into the second line of that formula above (couldn't get this correct based on the formula/codes Tom gave me)\n",
    "\n",
    "# Then we merge it into new_load_df as an extra field and this is used in the weighted_avg_rate as the weight_col instead of Net Balance\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need trancd formula built out: NDSB\n",
    "# This will be a separate column that we add to advances\n",
    "rtxn['new loan disb'] = np.where(rtxn['rtxntypcd'] == 'NDSB', rtxn['tranamt'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CML\n",
    "cml_minors = (\"CM06\", \"CM30\", \"CM52\")\n",
    "# Group by acctnbr\n",
    "disb_codes_cml = (\"PDSB\", \"SWPI\") # Increasing the loan\n",
    "receipt_codes_cml = (\"PRCT\", \"SWPR\") # Paying down loan\n",
    "# If positive, disb - receipt\n",
    "# Else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtxn['cml_disb'] = np.where((rtxn['rtxntypcd'].isin(disb_codes_cml)) & (rtxn['currmiaccttypcd'].isin(cml_minors)), rtxn['tranamt'], 0)\n",
    "rtxn['cml_receipt'] = np.where((rtxn['rtxntypcd'].isin(receipt_codes_cml)) & (rtxn['currmiaccttypcd'].isin(cml_minors)), rtxn['tranamt'], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acct_grouping = rtxn.groupby('acctnbr').agg({\n",
    "    'advances':'sum',\n",
    "    'new loan disb':'sum',\n",
    "    'cml_disb':'sum',\n",
    "    'cml_receipt':'sum'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acct_grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acct_grouping['advances'] = abs(acct_grouping['advances'])\n",
    "acct_grouping['net cml advance'] = (acct_grouping['cml_disb'] + acct_grouping['cml_receipt']) * -1\n",
    "acct_grouping['net cml advance'] = acct_grouping['net cml advance'].replace(-0.0,0.0)\n",
    "acct_grouping['net cml advance'] = np.where(acct_grouping['net cml advance'] < 0, 0, acct_grouping['net cml advance'])\n",
    "acct_grouping['advances'] = np.where(acct_grouping['net cml advance'] > 0, acct_grouping['net cml advance'], acct_grouping['advances'])\n",
    "acct_grouping_final = acct_grouping[['acctnbr','advances','new loan disb']].copy()\n",
    "\n",
    "# Merging\n",
    "new_loan_df = pd.merge(df, acct_grouping_final, on='acctnbr', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_loan_df['advances'] = new_loan_df['advances'].fillna(0)\n",
    "new_loan_df['new loan disb'] = new_loan_df['new loan disb'].fillna(0)\n",
    "new_loan_df['new_and_advanced'] = new_loan_df['advances'] + (new_loan_df['new loan disb'] * -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_loan_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytd_table_recon = new_loan_df.groupby('currmiaccttypcd')['new_and_advanced'].sum().sort_values(ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytd_table_recon6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minor_df = rtxn.groupby('currmiaccttypcd')['net advances'].sum().reset_index()\n",
    "# minor_df['net advances'] = abs(minor_df['net advances'])\n",
    "# minor_df = minor_df.sort_values(by='net advances', ascending=False)\n",
    "# minor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_yield = weighted_avg_rate(new_loan_df, title='New Loan Yield', weight_col='new_and_advanced')\n",
    "\n",
    "df['Unadvanced'] = (df['availbalamt']) / 1000\n",
    "\n",
    "# Unadvanced\n",
    "unadvanced = df.groupby('Category')['Unadvanced'].sum().reset_index()\n",
    "unadvanced = unadvanced.rename(columns={'Unadvanced':'Unadvanced Funds'})\n",
    "\n",
    "# Merge\n",
    "merged_df = pd.merge(new_yield, total_yield, how='inner', on='Category')\n",
    "merged_df = pd.merge(merged_df, unadvanced, how='inner', on='Category')\n",
    "\n",
    "# return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
