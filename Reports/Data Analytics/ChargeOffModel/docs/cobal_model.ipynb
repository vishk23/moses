{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea067bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad018e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec91e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6a1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb972b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733648fc",
   "metadata": {},
   "source": [
    "### Balancing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3622c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = data[data['cobal'] > 0]\n",
    "non_positive = data[data['cobal'] <= 0]\n",
    "\n",
    "non_positive_sampled = non_positive.sample(n=len(positive), random_state=42)\n",
    "balanced_data = pd.concat([positive, non_positive_sampled], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee30c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = balanced_data[[\n",
    "    'noteopenamt',\n",
    "    'ratetypcd', \n",
    "    'noteintrate', \n",
    "    'bookbalance', \n",
    "    'notebal', \n",
    "    #'contractdate', \n",
    "    #'datemat',\n",
    "    'origintrate', \n",
    "    'riskratingcd',\n",
    "    'availbalamt',\n",
    "    'Net Balance',\n",
    "    'Net Available',\n",
    "    'Net Collateral Reserve',\n",
    "    'Total Exposure',\n",
    "    'orig_ttl_loan_amt'\n",
    "    ]].copy()\n",
    "X['riskratingcd'] = X['riskratingcd'].str.replace(r'\\D', '', regex=True)\n",
    "X.replace('', np.nan, inplace=True)\n",
    "X.fillna(0, inplace=True)\n",
    "y = balanced_data['cobal'].copy()\n",
    "# converting cobal to binomial distribution\n",
    "y = (y > 0).astype(int)\n",
    "\n",
    "# append most recent delinquency file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd1ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04379536",
   "metadata": {},
   "source": [
    "### One hot encoding ratetypecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037e49ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = pd.get_dummies(X, columns=['ratetypcd'], prefix='ratetypcd')\n",
    "X_encoded['ratetypcd_FIX'], X_encoded['ratetypcd_VAR'] = X_encoded['ratetypcd_FIX'].astype(int), X_encoded['ratetypcd_VAR'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1858d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8cfd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features_to_be_scaled = ['noteopenamt', 'noteintrate', 'bookbalance', \n",
    "                         'notebal', 'origintrate','riskratingcd', \n",
    "                         'availbalamt', 'Net Balance', 'Net Available', \n",
    "                         'Net Collateral Reserve', 'Total Exposure', 'orig_ttl_loan_amt']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size = 0.2)\n",
    "X_train[features_to_be_scaled] = scaler.fit_transform(X_train[features_to_be_scaled])\n",
    "X_test[features_to_be_scaled] = scaler.transform(X_test[features_to_be_scaled])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e24183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_when_y_is_1 = ((y_test == y_pred) & (y_test == 1)).sum()\n",
    "# correct_when_y_is_1\n",
    "ones_in_y = y_test[y_test == 1]\n",
    "ones_in_y\n",
    "#y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9191aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    solver='saga',\n",
    "    C=1.0,\n",
    "    max_iter=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d53e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1798bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "y_pred = model.predict(X_test)\n",
    "# classification_report(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf9e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ac23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_when_y_is_1 = (str(((y_test == y_pred) & (y_test == 1)).sum() / len(y_test[y_test == 1]) * 100) + \"%\")\n",
    "accuracy_when_y_is_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1866c78b",
   "metadata": {},
   "source": [
    "### Testing model on entire unbalanced dataset (it has already been trained on about 600 of those rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb5754",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = data[[\n",
    "    'noteopenamt',\n",
    "    'ratetypcd', \n",
    "    'noteintrate', \n",
    "    'bookbalance', \n",
    "    'notebal', \n",
    "    #'contractdate', \n",
    "    #'datemat',\n",
    "    'origintrate', \n",
    "    'riskratingcd',\n",
    "    'availbalamt',\n",
    "    'Net Balance',\n",
    "    'Net Available',\n",
    "    'Net Collateral Reserve',\n",
    "    'Total Exposure',\n",
    "    'orig_ttl_loan_amt'\n",
    "    ]].copy()\n",
    "\n",
    "X_total['riskratingcd'] = X_total['riskratingcd'].str.replace(r'\\D', '', regex=True)\n",
    "X_total.replace('', np.nan, inplace=True)\n",
    "X_total.fillna(0, inplace=True)\n",
    "y_total = data['cobal'].copy()\n",
    "# converting cobal to binomial distribution\n",
    "y_total = (y_total > 0).astype(int)\n",
    "\n",
    "# append most recent delinquency file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b55622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding ratetypecd\n",
    "X_encoded = pd.get_dummies(X_total, columns=['ratetypcd'], prefix='ratetypcd')\n",
    "X_encoded['ratetypcd_FIX'], X_encoded['ratetypcd_VAR'] = X_encoded['ratetypcd_FIX'].astype(int), X_encoded['ratetypcd_VAR'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2274e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_be_scaled = ['noteopenamt', 'noteintrate', 'bookbalance', \n",
    "                         'notebal', 'origintrate','riskratingcd', \n",
    "                         'availbalamt', 'Net Balance', 'Net Available', \n",
    "                         'Net Collateral Reserve', 'Total Exposure', 'orig_ttl_loan_amt']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_encoded[features_to_be_scaled] = scaler.fit_transform(X_encoded[features_to_be_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0878820",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_total = model.predict(X_encoded)\n",
    "accuracy_score(y_total, y_pred_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f683ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_when_y_is_1 = ((y_total == y_pred_total) & (y_total == 1)).sum().item()\n",
    "# correct_when_y_is_1\n",
    "\n",
    "accuracy_when_y_is_1 = (str(((y_total == y_pred_total) & (y_total == 1)).sum() / len(y_total[y_total == 1]) * 100) + \"%\")\n",
    "accuracy_when_y_is_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e12189",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['y'] = y_total\n",
    "data['y_pred'] = y_pred_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "danger_zone = data[(data['y'] == 0)  & (data['y_pred'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef621d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "danger_zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe5141",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = model.coef_[0]\n",
    "feature_names = X_encoded.columns\n",
    "for name, coef in zip(feature_names, coefficients):\n",
    "    print(f\"{name} {coef:.12f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333c0a97",
   "metadata": {},
   "source": [
    "Net Balance and Total Exposure have a large impact on negative results (no cobal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544effe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c7eb599",
   "metadata": {},
   "source": [
    "### Trying without bookbal, net bal, note bal, net available, net collat, total exposure, and orig_ttl_loan_amt columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d930e85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "data = data.dropna(subset=['Category'])\n",
    "\n",
    "positive = data[data['cobal'] > 0]\n",
    "non_positive = data[data['cobal'] <= 0]\n",
    "\n",
    "non_positive_sampled = non_positive.sample(n=len(positive), random_state=42)\n",
    "balanced_data = pd.concat([positive, non_positive_sampled], ignore_index=True)\n",
    "\n",
    "X = balanced_data[[\n",
    "    'noteopenamt',\n",
    "    'ratetypcd', \n",
    "    'noteintrate', \n",
    "    #'contractdate', \n",
    "    #'datemat',\n",
    "    'origintrate', \n",
    "    'riskratingcd',\n",
    "    'availbalamt',\n",
    "    ]].copy()\n",
    "\n",
    "X['riskratingcd'] = X['riskratingcd'].str.replace(r'\\D', '', regex=True)\n",
    "X.replace('', np.nan, inplace=True)\n",
    "X.fillna(0, inplace=True)\n",
    "y = balanced_data['cobal'].copy()\n",
    "# converting cobal to binomial distribution\n",
    "y = (y > 0).astype(int)\n",
    "\n",
    "# append most recent delinquency file\n",
    "\n",
    "X_encoded = pd.get_dummies(X, columns=['ratetypcd'], prefix='ratetypcd')\n",
    "X_encoded['ratetypcd_FIX'], X_encoded['ratetypcd_VAR'] = X_encoded['ratetypcd_FIX'].astype(int), X_encoded['ratetypcd_VAR'].astype(int)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features_to_be_scaled = ['noteopenamt', 'noteintrate', 'origintrate',\n",
    "                         'riskratingcd', 'availbalamt']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size = 0.2)\n",
    "X_train[features_to_be_scaled] = scaler.fit_transform(X_train[features_to_be_scaled])\n",
    "X_test[features_to_be_scaled] = scaler.transform(X_test[features_to_be_scaled])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4976ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    solver='saga',\n",
    "    C=1.0,\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e8ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da611467",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_when_y_is_1 = (str(((y_test == y_pred) & (y_test == 1)).sum() / len(y_test[y_test == 1]) * 100) + \"%\")\n",
    "accuracy_when_y_is_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32bd037",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = model2.coef_[0]\n",
    "feature_names = X_encoded.columns\n",
    "for name, coef in zip(feature_names, coefficients):\n",
    "    print(f\"{name} {coef:.12f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa6f400",
   "metadata": {},
   "source": [
    "### Adding delinquency feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbed4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "delinquency = pd.read_excel(\"Delinquency_013125.xlsx\")\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "data = data.dropna(subset=['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b058cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "delinquency.columns = delinquency.iloc[3]\n",
    "delinquency = delinquency.rename(columns={'Account Number': 'acctnbr'})\n",
    "delinquency = delinquency.dropna(subset=['Customer Name'])\n",
    "delinquency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4ccf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_delinquency = pd.merge(data, delinquency, on='acctnbr', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11365ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_delinquency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_delinquency.replace('', np.nan, inplace=True)\n",
    "data_with_delinquency.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f008f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_delinquency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da94551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = data_with_delinquency[data_with_delinquency['cobal'] > 0]\n",
    "non_positive = data_with_delinquency[data_with_delinquency['cobal'] <= 0]\n",
    "\n",
    "non_positive_sampled = non_positive.sample(n=len(positive), random_state=42)\n",
    "balanced_data = pd.concat([positive, non_positive_sampled], ignore_index=True)\n",
    "\n",
    "X = balanced_data[[\n",
    "    'noteopenamt',\n",
    "    'ratetypcd', \n",
    "    'noteintrate', \n",
    "    #'contractdate', \n",
    "    #'datemat',\n",
    "    'origintrate', \n",
    "    'riskratingcd',\n",
    "    #'availbalamt',\n",
    "    'NDPD'\n",
    "    ]].copy()\n",
    "\n",
    "X['riskratingcd'] = X['riskratingcd'].str.replace(r'\\D', '', regex=True)\n",
    "X.replace('', np.nan, inplace=True)\n",
    "X.fillna(0, inplace=True)\n",
    "y = balanced_data['cobal'].copy()\n",
    "# converting cobal to binomial distribution\n",
    "y = (y > 0).astype(int)\n",
    "\n",
    "# append most recent delinquency file\n",
    "\n",
    "X_encoded = pd.get_dummies(X, columns=['ratetypcd'], prefix='ratetypcd')\n",
    "X_encoded['ratetypcd_FIX'], X_encoded['ratetypcd_VAR'] = X_encoded['ratetypcd_FIX'].astype(int), X_encoded['ratetypcd_VAR'].astype(int)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features_to_be_scaled = ['noteopenamt', 'noteintrate', 'origintrate',\n",
    "                         'riskratingcd', 'NDPD']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size = 0.2)\n",
    "X_train[features_to_be_scaled] = scaler.fit_transform(X_train[features_to_be_scaled])\n",
    "X_test[features_to_be_scaled] = scaler.transform(X_test[features_to_be_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c055ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    solver='saga',\n",
    "    C=1.0,\n",
    "    max_iter=100000\n",
    ")\n",
    "\n",
    "model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad29ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model3.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f6f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_when_y_is_1 = (str(((y_test == y_pred) & (y_test == 1)).sum() / len(y_test[y_test == 1]) * 100) + \"%\")\n",
    "accuracy_when_y_is_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = model3.coef_[0]\n",
    "feature_names = X_encoded.columns\n",
    "for name, coef in zip(feature_names, coefficients):\n",
    "    print(f\"{name} {coef:.12f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a4400f",
   "metadata": {},
   "source": [
    "### Adding contract_to_maturity_days feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8dbc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "delinquency = pd.read_excel(\"Delinquency_013125.xlsx\")\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "data = data.dropna(subset=['Category'])\n",
    "\n",
    "data['contractdate'] = pd.to_datetime(data['contractdate'])\n",
    "data['datemat'] = pd.to_datetime(data['datemat'])\n",
    "\n",
    "data['contract_to_maturity_days'] = (data['datemat'] - data['contractdate']).dt.days\n",
    "\n",
    "delinquency.columns = delinquency.iloc[3]\n",
    "delinquency = delinquency.rename(columns={'Account Number': 'acctnbr'})\n",
    "delinquency = delinquency.dropna(subset=['Customer Name'])\n",
    "\n",
    "data_with_delinquency = pd.merge(data, delinquency, on='acctnbr', how='left')\n",
    "data_with_delinquency.replace('', np.nan, inplace=True)\n",
    "data_with_delinquency.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c708353",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = data_with_delinquency[data_with_delinquency['cobal'] > 0]\n",
    "non_positive = data_with_delinquency[data_with_delinquency['cobal'] <= 0]\n",
    "\n",
    "non_positive_sampled = non_positive.sample(n=len(positive), random_state=42)\n",
    "balanced_data = pd.concat([positive, non_positive_sampled], ignore_index=True)\n",
    "\n",
    "X = balanced_data[[\n",
    "    'noteopenamt',\n",
    "    'ratetypcd', \n",
    "    'noteintrate', \n",
    "    #'contractdate', \n",
    "    #'datemat',\n",
    "    'contract_to_maturity_days',\n",
    "    'origintrate', \n",
    "    'riskratingcd',\n",
    "    #'availbalamt',\n",
    "    'NDPD'\n",
    "    ]].copy()\n",
    "\n",
    "X['riskratingcd'] = X['riskratingcd'].str.replace(r'\\D', '', regex=True)\n",
    "X.replace('', np.nan, inplace=True)\n",
    "X.fillna(0, inplace=True)\n",
    "y = balanced_data['cobal'].copy()\n",
    "# converting cobal to binomial distribution\n",
    "y = (y > 0).astype(int)\n",
    "\n",
    "# append most recent delinquency file\n",
    "\n",
    "X_encoded = pd.get_dummies(X, columns=['ratetypcd'], prefix='ratetypcd')\n",
    "X_encoded['ratetypcd_FIX'], X_encoded['ratetypcd_VAR'] = X_encoded['ratetypcd_FIX'].astype(int), X_encoded['ratetypcd_VAR'].astype(int)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features_to_be_scaled = ['noteopenamt', 'noteintrate', 'origintrate',\n",
    "                         'riskratingcd', 'contract_to_maturity_days', 'NDPD']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size = 0.2)\n",
    "X_train[features_to_be_scaled] = scaler.fit_transform(X_train[features_to_be_scaled])\n",
    "X_test[features_to_be_scaled] = scaler.transform(X_test[features_to_be_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bb83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    solver='saga',\n",
    "    C=1.0,\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "model4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc98a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model4.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6734ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_when_y_is_1 = (str(((y_test == y_pred) & (y_test == 1)).sum() / len(y_test[y_test == 1]) * 100) + \"%\")\n",
    "accuracy_when_y_is_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d4d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = model4.coef_[0]\n",
    "feature_names = X_encoded.columns\n",
    "for name, coef in zip(feature_names, coefficients):\n",
    "    print(f\"{name} {coef:.12f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff17d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = data_with_delinquency[[\n",
    "    'noteopenamt',\n",
    "    'ratetypcd', \n",
    "    'noteintrate', \n",
    "    #'contractdate', \n",
    "    #'datemat',\n",
    "    'contract_to_maturity_days',\n",
    "    'origintrate', \n",
    "    'riskratingcd',\n",
    "    #'availbalamt',\n",
    "    'NDPD'\n",
    "    ]].copy()\n",
    "\n",
    "X_total['riskratingcd'] = X_total['riskratingcd'].str.replace(r'\\D', '', regex=True)\n",
    "X_total.replace('', np.nan, inplace=True)\n",
    "X_total.fillna(0, inplace=True)\n",
    "y_total = data_with_delinquency['cobal'].copy()\n",
    "# converting cobal to binomial distribution\n",
    "y_total = (y_total > 0).astype(int)\n",
    "\n",
    "# append most recent delinquency file\n",
    "\n",
    "X_encoded = pd.get_dummies(X_total, columns=['ratetypcd'], prefix='ratetypcd')\n",
    "X_encoded['ratetypcd_FIX'], X_encoded['ratetypcd_VAR'] = X_encoded['ratetypcd_FIX'].astype(int), X_encoded['ratetypcd_VAR'].astype(int)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features_to_be_scaled = ['noteopenamt', 'noteintrate', 'origintrate',\n",
    "                         'riskratingcd', 'contract_to_maturity_days', 'NDPD']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_encoded[features_to_be_scaled] = scaler.fit_transform(X_encoded[features_to_be_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45279416",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_total = model4.predict(X_encoded)\n",
    "accuracy_score(y_total, y_pred_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cafe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model4.predict_proba(X_encoded)[:, 1]\n",
    "\n",
    "threshold = np.percentile(probabilities, 99)\n",
    "pred_top_1_percent = (probabilities >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa3b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_total, pred_top_1_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c3937",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_when_y_is_1 = (str(((y_total == pred_top_1_percent) & (y_total == 1)).sum() / len(y_total[y_total == 1]) * 100) + \"%\")\n",
    "accuracy_when_y_is_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5402a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_train)\n",
    "\n",
    "model4.fit(X_poly, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e065b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b259fbf5",
   "metadata": {},
   "source": [
    "#### Manual implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual\n",
    "from tqdm import tqdm\n",
    "\n",
    "def q(x=None, X = None, w = None):\n",
    "    if X is None:\n",
    "        return 1 / (1 + np.exp(-x.T.dot(w)))\n",
    "    else:\n",
    "        return 1 / (1 + np.exp(-X.dot(w)))\n",
    "    \n",
    "def dL(Φ, y, w):\n",
    "    return Φ.T.dot(q(None, Φ, w) - y) / len(y)\n",
    "\n",
    "def gradient_descent(Φ, y, w, η):\n",
    "    for i in tqdm(range(5)):\n",
    "        w = w - η * dL(Φ, y, w)\n",
    "    return w\n",
    "\n",
    "w = np.ones((X_train.shape[1], 1))\n",
    "w = gradient_descent(X_train, y_train, w, 0.1)\n",
    "\n",
    "def logistic_predict(X, w):\n",
    "    return (q(None, X, w) >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4dcae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a9237",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62138503",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_pred = logistic_predict(X_train, w)\n",
    "lr_train_accuracy = np.mean(lr_train_pred[0] == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9597e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = w\n",
    "feature_names = X_encoded.columns\n",
    "for name, coef in zip(feature_names, coefficients):\n",
    "    print(f\"{name} {coef:.12f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922e08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6dc904",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_pred = lr_train_pred[lr_train_pred[0] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_pred[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
