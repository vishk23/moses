{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e683a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Navigate to project root (equivalent to cd ..)\n",
    "project_dir = Path(__file__).parent.parent if '__file__' in globals() else Path.cwd().parent\n",
    "os.chdir(project_dir)\n",
    "\n",
    "# Add src directory to Python path for imports\n",
    "src_dir = project_dir / \"src\"\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# Set environment for dev testing\n",
    "os.environ['REPORT_ENV'] = 'dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba08556",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main Entry Point\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from openpyxl import load_workbook\n",
    "from deltalake import DeltaTable\n",
    "\n",
    "import src.config\n",
    "import os\n",
    "import shutil\n",
    "import cdutils.distribution # type: ignore\n",
    "from src._version import __version__\n",
    "from src.config import BASE_PATH, INPUT_DIR, OUTPUT_DIR, EMAIL_TO, EMAIL_CC, EMAIL_BCC, EXCEPTION_EMAIL_TO, EXCEPTION_EMAIL_CC, EXCEPTION_EMAIL_BCC\n",
    "from src.daily_mismatch_txns.api_call import (\n",
    "    fetch_latest_to_input,\n",
    ")\n",
    "\n",
    "\n",
    "# def main():\n",
    "ASSETS_PATH = BASE_PATH / Path('./assets')\n",
    "ASSETS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "# Fetch latest .prn/.txt into INPUT_DIR so downstream reads it\n",
    "try:\n",
    "    dest = fetch_latest_to_input(\"CO_VSUS\", storage_type_id=1, filename_template=\"CO_VSUS_{pkid}.txt\")\n",
    "    if dest:\n",
    "        print(f\"Downloaded and saved latest CO_VSUS file to INPUT_DIR: {dest}\")\n",
    "    else:\n",
    "        print(\"No CO_VSUS documents found via API search.\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: API fetch skipped/failed: {e}\")\n",
    "\n",
    "# Choose newest .txt file and archive the rest\n",
    "txt_files = sorted(INPUT_DIR.glob(\"*.txt\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "if not txt_files:\n",
    "    raise FileNotFoundError(f\"No .txt files found in {INPUT_DIR}\")\n",
    "input_src_path = txt_files[0]\n",
    "# Archive any extras to keep the folder clean for next runs\n",
    "for extra in txt_files[1:]:\n",
    "    shutil.move(extra, INPUT_DIR / \"archive\" / extra.name)\n",
    "    print(f\"Archived extra file: {extra.name}\")\n",
    "file_to_move = input_src_path.name\n",
    "\n",
    "\n",
    "column_names = [\n",
    "    \"Card Nbr\",\n",
    "    \"Acct Nbr\",\n",
    "    \"Trans Amt\",\n",
    "    \"RTXN Typ\",\n",
    "    \"RetRefNbr\",\n",
    "    \"Comment\",\n",
    "    \"Merchant\"\n",
    "]\n",
    "\n",
    "column_widths = [16, 20, 18, 18, 12, 35, 40]\n",
    "\n",
    "df = pd.read_fwf(\n",
    "    input_src_path,\n",
    "    widths=column_widths,\n",
    "    names=column_names,\n",
    "    encoding='latin1'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Card and Acct and Tran Amt'] = df['Card Nbr'] + df['Acct Nbr'] + df['Trans Amt']\n",
    "\n",
    "# locating row index that starts Records On Fiserv ACH File but not ON AT_CACT File which separates top half of the report from bottom half\n",
    "idx = df[df['RetRefNbr'].str.contains('t not ON AT_', case=False, na=False)].index[0]\n",
    "\n",
    "top = df.loc[:idx]\n",
    "top = top[top['Card Nbr'].str.contains('5', na=False)]\n",
    "bottom = df.loc[idx:]\n",
    "bottom = bottom[bottom['Card Nbr'].str.contains('5', na=False)]\n",
    "\n",
    "# now we just find unique occurances of Card and Acct and Tran Amt (occurances from either dataframe that isn't in the other one)\n",
    "unique_in_top = top[~top['Card and Acct and Tran Amt'].isin(bottom['Card and Acct and Tran Amt'])]\n",
    "unique_in_bottom = bottom[~bottom['Card and Acct and Tran Amt'].isin(top['Card and Acct and Tran Amt'])]\n",
    "result = pd.concat([unique_in_top, unique_in_bottom])\n",
    "result = result[['Card Nbr', 'Acct Nbr', 'Trans Amt', 'RTXN Typ', 'RetRefNbr', 'Merchant']]\n",
    "\n",
    "field_widths = [120, 10]\n",
    "field_names = ['Not Needed', 'Date']\n",
    "input2 = pd.read_fwf(\n",
    "    input_src_path,\n",
    "    widths=field_widths,\n",
    "    names=field_names,\n",
    "    encoding='latin1'\n",
    ")\n",
    "input2['RecordID'] = pd.Series(range(1, len(input2) + 1), dtype='int32')\n",
    "\n",
    "# adding date to result dataframe\n",
    "date_str = str(input2.at[1, 'Date']).strip()\n",
    "result['Date'] = date_str\n",
    "result['Source'] = \"co_vsus re-run\"\n",
    "\n",
    "result['Trans Amt'] = result['Trans Amt'].str.replace(\",\",\"\")\n",
    "result['Trans Amt'] = pd.to_numeric(result['Trans Amt'], errors=\"coerce\")\n",
    "result['Trans Amt'] = np.where(result['RTXN Typ'] == \"PWTH\", 0 - result['Trans Amt'], result['Trans Amt'])\n",
    "result = result[['Card Nbr', 'Date', 'Source', 'Trans Amt', 'Acct Nbr', 'RTXN Typ', 'RetRefNbr', 'Merchant']]\n",
    "\n",
    "\n",
    "cardnbrs = list(result['Card Nbr'])\n",
    "acctnbrs = list(result['Acct Nbr'])\n",
    "amount = list(result['Trans Amt'])\n",
    "deb_or_cred = []\n",
    "merchants = list(result['Merchant'])\n",
    "\n",
    "# Save unadjusted version of account numbers because we pad with leading zeros\n",
    "# Necsesary for later merge against COCC active accounts\n",
    "unadjusted_card = cardnbrs.copy()\n",
    "unadjusted_acctnbr = acctnbrs.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe94d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(result)):\n",
    "\n",
    "    # left padding acctnbrs with 0s\n",
    "    while len(acctnbrs[i]) < 12:\n",
    "        acctnbrs[i] = '0' + acctnbrs[i]\n",
    "\n",
    "    # determining if debit or credit based on sign of Trans Amt\n",
    "    if amount[i] < 0:\n",
    "        deb_or_cred.append(\"Debit\")\n",
    "        amount[i] = amount[i] * -1  # making all amounts positive\n",
    "    elif amount[i] > 0:\n",
    "        deb_or_cred.append(\"Credit\")\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # appending last 4 digits of card number to the merchant\n",
    "\n",
    "    merchants[i] += f\" ({cardnbrs[i][-4:]})\"\n",
    "\n",
    "# Matching against COCC\n",
    "temp_df = pd.DataFrame({\n",
    "    'cardnbr': unadjusted_card,\n",
    "    'acctnbr': unadjusted_acctnbr,\n",
    "    'amount': amount,\n",
    "    'merchant': merchants\n",
    "}).copy()\n",
    "\n",
    "# Make string if not already\n",
    "temp_df['acctnbr'] = temp_df['acctnbr'].astype(str)\n",
    "\n",
    "\n",
    "active_accts = DeltaTable(src.config.SILVER / \"account\").to_pandas()\n",
    "\n",
    "# Merging\n",
    "merged_df = pd.merge(temp_df, active_accts, how='outer', on='acctnbr', indicator=True)\n",
    "\n",
    "# Exceptions dataframe creation\n",
    "exceptions = merged_df[merged_df['_merge'] == 'left_only'].copy()\n",
    "\n",
    "# # Write out exceptions here to check if this works\n",
    "# TEMP_OUTPUT = Path(r\"C:\\Users\\w322800\\Documents\\gh\\bcsb-prod\\Reports\\Risk Management\\Daily Mismatched Debit Card Txns\\bin\\exceptions.parquet\")\n",
    "# exceptions.to_parquet(TEMP_OUTPUT, index=False)\n",
    "\n",
    "# Save for separate distribution\n",
    "exceptions = exceptions[[\n",
    "    'cardnbr',\n",
    "    'acctnbr',\n",
    "    'amount',\n",
    "    'merchant'\n",
    "]].copy()\n",
    "\n",
    "# move txt file to archive\n",
    "input_archive_path = INPUT_DIR / Path('./archive') / Path(file_to_move)\n",
    "shutil.move(input_src_path, input_archive_path)\n",
    "print(f\"Moved {file_to_move} to input/archive directory.\")\n",
    "\n",
    "# filling in template\n",
    "wb = load_workbook(ASSETS_PATH / Path(\"txtparser_template.xlsx\"))\n",
    "ws = wb.active\n",
    "\n",
    "for i, value in enumerate(deb_or_cred):\n",
    "    ws.cell(row=8+2*i, column=1, value=value)\n",
    "for i, value in enumerate(acctnbrs):\n",
    "    ws.cell(row=8+2*i, column=3, value=value)\n",
    "for i, value in enumerate(amount):\n",
    "    ws.cell(row=8+2*i, column=5, value=value)\n",
    "for i, value in enumerate(merchants):\n",
    "    ws.cell(row=8+2*i, column=7, value=value)\n",
    "\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "# output_date_str = f\"{today.month}.{today.day:02}.{today.year % 100:02}\"\n",
    "# date_str = f\"{today.month}/{today.day:02}/{today.year % 100:02}\"\n",
    "filename = \"Daily Posting Sheet \" + date_str + \".xlsx\"\n",
    "output_file = os.path.join(OUTPUT_DIR,filename)\n",
    "\n",
    "ws['C3'] = f\"{date_str}\"\n",
    "\n",
    "# before saving, move everything in output folder to output/archive\n",
    "for file in OUTPUT_DIR.glob(\"*.xlsx\"):\n",
    "    file_to_move = file.name\n",
    "    src_path = OUTPUT_DIR / Path(file_to_move)\n",
    "    output_archive_path = OUTPUT_DIR / Path('./archive') / Path(file_to_move)\n",
    "    shutil.move(src_path, output_archive_path)\n",
    "    print(f\"Moved {file_to_move} to output/archive directory.\")\n",
    "\n",
    "# save spreadsheet to output directory\n",
    "wb.save(output_file)\n",
    "print(f\"Report saved to {output_file}\")\n",
    "\n",
    "# # Usage\n",
    "# # # Distribution\n",
    "# subject = f\"Daily Transaction Mismatch for Posting - {date_str}\" \n",
    "# body = \"Hi all, \\n\\nPlease see the attached Daily Transaction Mismatch file for Posting.\" \\\n",
    "# \"\\n\\nPlease reach to Patrick Quinn (patrick.quinn@bcsbmail.com) or BusinessIntelligence@bcsbmail.com if you have any questions or issues.\"\n",
    "# attachment_paths = [output_file]\n",
    "\n",
    "# # Send main file to deposit ops\n",
    "# cdutils.distribution.email_out(EMAIL_TO, EMAIL_CC, EMAIL_BCC, subject, body, attachment_paths)\n",
    "\n",
    "# EXCEPTION_FILENAME = \"Exceptions \" + date_str + \".txt\"\n",
    "# EXCEPTION_OUTPUT = OUTPUT_DIR / EXCEPTION_FILENAME\n",
    "\n",
    "# # Define the email subject and body, which we may adjust if there are no exceptions.\n",
    "# subject = f\"Exceptions: Daily Transaction Mismatch for Posting - {date_str}\"\n",
    "# body = (\n",
    "#     \"Hi all,\\n\\n\"\n",
    "#     \"Please see the attached exceptions regarding the Daily Transaction Mismatch file for Posting.\\n\\n\"\n",
    "#     \"This shows the items that have account numbers that don't match active accounts in COCC.\\n\\n\"\n",
    "#     \"Please reach to BusinessIntelligence@bcsbmail.com if you have any questions or issues.\"\n",
    "# )\n",
    "\n",
    "# if exceptions.empty:\n",
    "#     # If the exceptions DataFrame is empty, create a simple message file and update the email body.\n",
    "#     report_content = \"No transaction mismatch exceptions found for this reporting period.\"\n",
    "#     body = \"Hi all,\\n\\nThere were no transaction mismatch exceptions found for today's posting file.\"\n",
    "#     print(\"No exceptions found. A note will be written to the output file.\")\n",
    "\n",
    "# else:\n",
    "#     # If there are exceptions, build the formatted fixed-width report.\n",
    "#     df = exceptions.copy() # Work on a copy to avoid SettingWithCopyWarning\n",
    "    \n",
    "#     # Convert all columns to string to measure length accurately\n",
    "#     df['cardnbr'] = df['cardnbr'].astype(str)\n",
    "#     df['acctnbr'] = df['acctnbr'].astype(str)\n",
    "#     # Ensure amount has two decimal places for consistent formatting\n",
    "#     df['amount'] = df['amount'].apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "#     # --- Calculate column widths ---\n",
    "#     # Start with header length, then find the max length in each column.\n",
    "#     # Add padding for space between columns.\n",
    "#     padding = 2\n",
    "#     col_widths = {\n",
    "#         col: max(df[col].str.len().max(), len(col)) + padding\n",
    "#         for col in df.columns\n",
    "#     }\n",
    "\n",
    "#     # --- Build the report string line-by-line ---\n",
    "#     report_lines = []\n",
    "    \n",
    "#     # 1. Create the main header for the report\n",
    "#     title = \" Daily Transaction Mismatch Exceptions Report \"\n",
    "#     total_width = sum(col_widths.values())\n",
    "#     report_lines.append(\"=\" * total_width)\n",
    "#     report_lines.append(f\"=={title.center(total_width - 4)}==\")\n",
    "#     report_lines.append(\"=\" * total_width)\n",
    "#     report_lines.append(\"\") # Blank line\n",
    "    \n",
    "#     # 2. Add metadata\n",
    "#     report_lines.append(f\"Report Date: {date_str}\")\n",
    "#     report_lines.append(f\"Total Exceptions: {len(df)}\")\n",
    "#     report_lines.append(\"\") # Blank line\n",
    "\n",
    "#     # 3. Create the column headers row\n",
    "#     header_line = \"\".join([col.ljust(col_widths[col]) for col in df.columns])\n",
    "#     report_lines.append(header_line)\n",
    "\n",
    "#     # 4. Create the separator line under the headers\n",
    "#     separator_line = \"\".join((\"-\" * (col_widths[col] - padding)).ljust(col_widths[col]) for col in df.columns)\n",
    "#     report_lines.append(separator_line)\n",
    "\n",
    "#     # 5. Add each data row, formatted to the correct width\n",
    "#     for index, row in df.iterrows():\n",
    "#         data_line = \"\".join([str(row[col]).ljust(col_widths[col]) for col in df.columns])\n",
    "#         report_lines.append(data_line)\n",
    "    \n",
    "#     # 6. Add a footer\n",
    "#     report_lines.append(\"\") # Blank line\n",
    "#     report_lines.append(\"--- End of Report ---\")\n",
    "\n",
    "#     # Join all lines into a single string for writing\n",
    "#     report_content = \"\\n\".join(report_lines)\n",
    "\n",
    "# # --- Write the generated content to the .txt file ---\n",
    "# with open(EXCEPTION_OUTPUT, \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(report_content)\n",
    "# print(f\"Formatted text exception report saved to {EXCEPTION_OUTPUT}\")\n",
    "\n",
    "\n",
    "# # # Distribution (This section now uses the conditionally-set body)\n",
    "# attachment_paths = [output_file, EXCEPTION_OUTPUT]\n",
    "\n",
    "# # Send exceptions email\n",
    "# cdutils.distribution.email_out(EXCEPTION_EMAIL_TO, EXCEPTION_EMAIL_CC, EXCEPTION_EMAIL_BCC, subject, body, attachment_paths)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "# print(f\"Starting [{__version__}]\")\n",
    "# main()\n",
    "# print(\"Complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7539bf1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcsb-prod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
