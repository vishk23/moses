{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a724e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Navigate to project root (equivalent to cd ..)\n",
    "project_dir = Path(__file__).parent.parent if '__file__' in globals() else Path.cwd().parent\n",
    "os.chdir(project_dir)\n",
    "\n",
    "# Add src directory to Python path for imports\n",
    "src_dir = project_dir / \"src\"\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "# Set environment for dev testing\n",
    "os.environ['REPORT_ENV'] = 'dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90119b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core logic specific to project/report\n",
    "\n",
    "import src.config\n",
    "import pandas as pd\n",
    "from deltalake import DeltaTable\n",
    "import cdutils.deduplication\n",
    "import src.loan_trial.fetch_data\n",
    "import numpy as np\n",
    "\n",
    "def _extract_latest_user_field(\n",
    "    user_fields: pd.DataFrame,\n",
    "    field_code: str,\n",
    "    column_name: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Return the most recent user field value per account for the given code.\"\"\"\n",
    "\n",
    "    subset = user_fields[user_fields['acctuserfieldcd'] == field_code].copy()\n",
    "    if subset.empty:\n",
    "        return pd.DataFrame(columns=['acctnbr', column_name])\n",
    "\n",
    "    subset = subset.sort_values(\n",
    "        by=['acctnbr', 'acctdatelastmaint'],\n",
    "        ascending=[True, False]\n",
    "    ).copy()\n",
    "    subset = subset.drop_duplicates(subset=['acctnbr'], keep='first')\n",
    "    subset = subset.rename(columns={'acctuserfieldvalue': column_name})\n",
    "\n",
    "    return subset[['acctnbr', column_name]].copy()\n",
    "\n",
    "\n",
    "# def main_pipeline():\n",
    "    # Main loan data, silver table\n",
    "TABLE_PATH = src.config.SILVER / \"account\"\n",
    "accts = DeltaTable(TABLE_PATH).to_pandas()\n",
    "\n",
    "    # MACRO_TYPE_MAPPING = {\n",
    "    #         'CML': 'Loan',\n",
    "    #         'MLN': 'Loan',\n",
    "    #         'CNS': 'Loan',\n",
    "    #         'MTG': 'Loan',\n",
    "    #         'CK': 'Deposit',\n",
    "    #         'SAV': 'Deposit',\n",
    "    #         'TD': 'Deposit'\n",
    "    #     }\n",
    "\n",
    "    # accts['Macro Account Type'] = accts['mjaccttypcd'].map(MACRO_TYPE_MAPPING)\n",
    "    # accts = accts[accts['Macro Account Type'] == 'Loan'].copy()\n",
    "\n",
    "    # accts = accts[[\n",
    "    #     'acctnbr',\n",
    "    #     'ownersortname',\n",
    "    #     'mjaccttypcd',\n",
    "    #     'currmiaccttypcd',\n",
    "    #     'product',\n",
    "    #     'curracctstatcd',\n",
    "    #     'noteintrate',\n",
    "    #     'notebal',\n",
    "    #     'bookbalance',\n",
    "    #     'branchname',\n",
    "    #     'loanofficer',\n",
    "    #     'contractdate',\n",
    "    #     'datemat',\n",
    "    #     'creditlimitamt',\n",
    "    #     'loanlimityn',\n",
    "    #     'credlimitclatresamt',\n",
    "    #     'nextratechg',\n",
    "    #     'amortterm',\n",
    "    #     'riskratingcd',\n",
    "    #     'fdiccatcd',\n",
    "    #     'fdiccatdesc',\n",
    "    #     'inactivedate',\n",
    "    #     'taxrptfororgnbr',\n",
    "    #     'taxrptforpersnbr'\n",
    "    # ]].copy()\n",
    "accts['taxrptfororgnbr'] = np.where(accts['taxrptfororgnbr'].isna(), np.nan, accts['taxrptfororgnbr'].astype('Int64').astype(str))\n",
    "accts['taxrptforpersnbr'] = np.where(accts['taxrptforpersnbr'].isna(), np.nan, accts['taxrptforpersnbr'].astype('Int64').astype(str))\n",
    "\n",
    "    # # Get investor data\n",
    "    # invr = src.loan_trial.fetch_data.fetch_invr()\n",
    "    # wh_invr = invr['wh_invr'].copy()\n",
    "\n",
    "\n",
    "    # acctgrpinvr = invr['acctgrpinvr'].copy()\n",
    "\n",
    "    # wh_org = DeltaTable(src.config.BRONZE / \"wh_org\").to_pandas()\n",
    "    # wh_org = wh_org[[\n",
    "    #     'orgnbr',\n",
    "    #     'orgname'\n",
    "    # ]].copy()\n",
    "    # dedupe_list = [\n",
    "    #     {'df':wh_org, 'field':'orgnbr'}\n",
    "    # ]\n",
    "    # wh_org = cdutils.deduplication.dedupe(dedupe_list).copy()\n",
    "    # wh_org['orgnbr'] = wh_org['orgnbr'].astype(str)\n",
    "    # wh_invr['acctgrpnbr'] = wh_invr['acctgrpnbr'].astype(str)\n",
    "    # acctgrpinvr['acctgrpnbr'] = acctgrpinvr['acctgrpnbr'].astype(str)\n",
    "    # acctgrpinvr['invrorgnbr'] = acctgrpinvr['invrorgnbr'].astype(str)\n",
    "\n",
    "    # merged_investor = wh_invr.merge(acctgrpinvr, on='acctgrpnbr', how='left').merge(wh_org, left_on='invrorgnbr', right_on='orgnbr')\n",
    "    # merged_investor = merged_investor.sort_values(by='pctowned', ascending=False).copy()\n",
    "    # dedupe_list = [\n",
    "    #     {'df':merged_investor, 'field':'acctnbr'}\n",
    "    # ]\n",
    "    # merged_investor = cdutils.deduplication.dedupe(dedupe_list).copy()\n",
    "    # merged_investor = merged_investor.drop(columns=['orgnbr','invrorgnbr','pctowned','acctgrpnbr']).copy()\n",
    "    # merged_investor['acctnbr'] = merged_investor['acctnbr'].astype(str)\n",
    "    # assert merged_investor['acctnbr'].is_unique, \"Duplicates exist. Pre-merge of investor data to full df\"\n",
    "\n",
    "    # merged_investor = merged_investor.rename(columns={\n",
    "    #     'orgname':'Investor Name',\n",
    "    #     'originvrrate':'Orig Investor Rate',\n",
    "    #     'currinvrrate':'Current Investor Rate'\n",
    "    # }).copy()\n",
    "\n",
    "    # accts = accts.merge(merged_investor, on='acctnbr', how='left')\n",
    "\n",
    "    # # acctloan\n",
    "    # acctloan = DeltaTable(src.config.BRONZE / \"wh_acctloan\").to_pandas()\n",
    "    # acctloan = acctloan[[\n",
    "    #     'acctnbr',\n",
    "    #     'currduedate',\n",
    "    #     'totalpaymentsdue',\n",
    "    #     'totalpidue',\n",
    "    #     'minintrate',\n",
    "    #     'maxintrate',\n",
    "    #     'maxratechangedown',\n",
    "    #     'maxratechangeup',\n",
    "    #     'ratechangerndmethcd',\n",
    "    #     'pmtchangerndmethcd',\n",
    "    #     'marginpct',\n",
    "    #     'marginfixed',\n",
    "    #     'deffeerem',\n",
    "    #     'deffeerate',\n",
    "    #     'defcostrem',\n",
    "    #     'defcostrate',\n",
    "    #     'escbal',\n",
    "    #     'escrowdue',\n",
    "    #     'escintrate',\n",
    "    #     'escaccruedint',\n",
    "    #     'esccompmth',\n",
    "    #     'creditreporttypcd',\n",
    "    #     'purpcd'\n",
    "    # ]].copy()\n",
    "\n",
    "    # acctloan['acctnbr'] = acctloan['acctnbr'].astype(str)\n",
    "    # assert acctloan['acctnbr'].is_unique, \"Duplicates premerge accts & acctloan\"\n",
    "    \n",
    "    # accts = accts.merge(acctloan, how='left', on='acctnbr')\n",
    "\n",
    "    # # wh_loans \n",
    "    # wh_loans = DeltaTable(src.config.BRONZE / \"wh_loans\").to_pandas()\n",
    "    # wh_loans = wh_loans[[\n",
    "    #     'acctnbr',\n",
    "    #     'rcf',\n",
    "    #     'ratechangeleaddays',\n",
    "    #     'revolveloanyn'\n",
    "    # ]].copy()\n",
    "\n",
    "    # wh_loans['acctnbr'] = wh_loans['acctnbr'].astype(str)\n",
    "    # assert wh_loans['acctnbr'].is_unique, \"Duplicates premerge accts & wh_loans\"\n",
    "    # accts = accts.merge(wh_loans, how='left', on='acctnbr')\n",
    "\n",
    "    # # wh_acctcommon \n",
    "    # wh_acctcommon = DeltaTable(src.config.BRONZE / \"wh_acctcommon\").to_pandas()\n",
    "    # wh_acctcommon = wh_acctcommon[[\n",
    "    #     'acctnbr',\n",
    "    #     'intbase',\n",
    "    #     'intmethcd',\n",
    "    #     'ratetypcd',\n",
    "    #     'daysmethcd'\n",
    "    # ]].copy()\n",
    "\n",
    "    # wh_acctcommon['acctnbr'] = wh_acctcommon['acctnbr'].astype(str)\n",
    "    # assert wh_acctcommon['acctnbr'].is_unique, \"Duplicates premerge accts & wh_acctcommon\"\n",
    "    # accts = accts.merge(wh_acctcommon, how='left', on='acctnbr')\n",
    "\n",
    "    # acctsubacct = src.loan_trial.fetch_data.fetch_acctsubacct()\n",
    "    # acctsubacct = acctsubacct['acctsubacct'].copy()\n",
    "    # acctsubacct = acctsubacct.sort_values(by='effdate', ascending=False)\n",
    "\n",
    "    # dedupe_list = [\n",
    "    #     {'df':acctsubacct, 'field':'acctnbr'}\n",
    "    # ]\n",
    "    # acctsubacct = cdutils.deduplication.dedupe(dedupe_list).copy()\n",
    "    # acctsubacct = acctsubacct[[\n",
    "    #     'acctnbr',\n",
    "    #     'escrowcushionamt',\n",
    "    #     'alternateescpmtamt'\n",
    "    # ]].copy()\n",
    "    # acctsubacct['acctnbr'] = acctsubacct['acctnbr'].astype(str)\n",
    "    # assert acctsubacct['acctnbr'].is_unique, \"Duplicates premerge accts & acctsubacct\"\n",
    "    # accts = accts.merge(acctsubacct, how='left', on='acctnbr')\n",
    "\n",
    "    # # Prop data\n",
    "    # property = DeltaTable(src.config.SILVER / \"property\").to_pandas()\n",
    "    # property = property[[\n",
    "    #     'propnbr',\n",
    "    #     'aprsvalueamt',\n",
    "    #     'proptypcd',\n",
    "    #     'proptypdesc',\n",
    "    #     'propdesc',\n",
    "    #     'propvalue',\n",
    "    #     'owneroccupiedcd',\n",
    "    #     'owneroccupieddesc',\n",
    "    #     'purchaseprice',\n",
    "    #     'purchasedate',\n",
    "    #     'platbooknbr',\n",
    "    #     'platbookpage',\n",
    "    #     'floodzone',\n",
    "    #     'floodzoneyn'\n",
    "    # ]].copy()\n",
    "\n",
    "    # # Link\n",
    "    # account_property_link = DeltaTable(src.config.SILVER / \"account_property_link\").to_pandas()\n",
    "    # account_property_link = account_property_link[[\n",
    "    #     'acctnbr',\n",
    "    #     'propnbr'\n",
    "    # ]].copy()\n",
    "\n",
    "    # property['propnbr'] = property['propnbr'].astype(str)\n",
    "    # assert property['propnbr'].is_unique, \"Duplicates on property premerge with linking table\"\n",
    "\n",
    "    # merged_prop = account_property_link.merge(property, how='left', on='propnbr')\n",
    "    # merged_prop = merged_prop.sort_values(by='aprsvalueamt', ascending=False)\n",
    "    # dedupe_list = [\n",
    "    #     {'df':merged_prop, 'field':'acctnbr'}\n",
    "    # ]\n",
    "    # merged_prop = cdutils.deduplication.dedupe(dedupe_list).copy()\n",
    "    # #\n",
    "    \n",
    "    # merged_prop['acctnbr'] = merged_prop['acctnbr'].astype(str)\n",
    "    # assert merged_prop['acctnbr'].is_unique, \"Duplicates premerge merged_prop and accts\"\n",
    "    # accts = accts.merge(merged_prop, how='left', on='acctnbr')\n",
    "\n",
    "    # # Insurance data for escrow\n",
    "    # insurance = DeltaTable(src.config.SILVER / \"insurance\").to_pandas()\n",
    "    # insurance = insurance[[\n",
    "    #     'intrpolicynbr',\n",
    "    #     'escrowyn'\n",
    "    # ]].copy()\n",
    "\n",
    "    # insurance = insurance.rename(columns={\n",
    "    #     'escrowyn':'Escrow Insurance'\n",
    "    # }).copy()\n",
    "\n",
    "    # assert insurance['intrpolicynbr'].is_unique, \"Duplicates premerge insurance and acct_prop_ins_link\"\n",
    "    # acct_prop_ins_link = DeltaTable(src.config.SILVER / \"acct_prop_ins_link\").to_pandas()\n",
    "    # acct_prop_ins_link = acct_prop_ins_link[[\n",
    "    #     'propnbr',\n",
    "    #     'intrpolicynbr'\n",
    "    # ]].copy()\n",
    "    # acct_prop_ins_link = acct_prop_ins_link.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # insurance['intrpolicynbr'] = insurance['intrpolicynbr'].astype(str)\n",
    "    # acct_prop_ins_link['propnbr'] = acct_prop_ins_link['propnbr'].astype(str)\n",
    "    # acct_prop_ins_link['intrpolicynbr'] = acct_prop_ins_link['intrpolicynbr'].astype(str)\n",
    "\n",
    "    # acct_prop_ins_link = acct_prop_ins_link.merge(insurance, how='left', on='intrpolicynbr')\n",
    "    # dedupe_list = [\n",
    "    #     {'df':acct_prop_ins_link, 'field':'propnbr'}\n",
    "    # ]\n",
    "    # acct_prop_ins_link = cdutils.deduplication.dedupe(dedupe_list).copy()\n",
    "\n",
    "    # assert acct_prop_ins_link['propnbr'].is_unique, \"Duplication premerge acct_propins and acct\"\n",
    "    # accts['propnbr'] = accts['propnbr'].astype(str)\n",
    "    # acct_prop_ins_link['propnbr'] = acct_prop_ins_link['propnbr'].astype(str)\n",
    "    # acct_prop_ins_link[['propnbr','Escrow Insurance']]\n",
    "    # accts = accts.merge(acct_prop_ins_link, how='left', on='propnbr')\n",
    "\n",
    "    # # Append naics from WH_ACCT\n",
    "    # wh_acct = src.loan_trial.fetch_data.fetch_wh_acct()\n",
    "    # wh_acct = wh_acct['wh_acct'].copy()\n",
    "\n",
    "    # wh_acct['acctnbr'] = wh_acct['acctnbr'].astype(str)\n",
    "    # assert wh_acct['acctnbr'].is_unique, \"Duplicates before wh_acct and accts merge\"\n",
    "\n",
    "    # accts = accts.merge(wh_acct, how='left', on='acctnbr')\n",
    "\n",
    "    # # Append user fields\n",
    "    # wh_acctuserfields = src.loan_trial.fetch_data.fetch_userfields()\n",
    "    # wh_acctuserfields = wh_acctuserfields['wh_acctuserfields'].copy()\n",
    "    # wh_acctuserfields['acctnbr'] = wh_acctuserfields['acctnbr'].astype(str)\n",
    "    # wh_acctuserfields['acctdatelastmaint'] = pd.to_datetime(\n",
    "    #     wh_acctuserfields['acctdatelastmaint'],\n",
    "    #     errors='coerce'\n",
    "    # )\n",
    "\n",
    "    # user_field_map = {\n",
    "    #     'HHNU': 'HHNU',\n",
    "    #     'SCRA': 'SCRA',\n",
    "    #     'ASST': 'ASST',\n",
    "    #     'DTYP': 'DTYP'\n",
    "    # }\n",
    "\n",
    "    # for code, column in user_field_map.items():\n",
    "    #     latest_user_field = _extract_latest_user_field(\n",
    "    #         wh_acctuserfields,\n",
    "    #         field_code=code,\n",
    "    #         column_name=column\n",
    "    #     )\n",
    "    #     assert latest_user_field['acctnbr'].is_unique, (\n",
    "    #         f\"Duplicates before {code} & accts\"\n",
    "    #     )\n",
    "    #     accts = accts.merge(latest_user_field, how='left', on='acctnbr')\n",
    "\n",
    "# # Allow promo\n",
    "wh_org = DeltaTable(src.config.BRONZE / \"wh_org\").to_pandas()\n",
    "wh_org = wh_org[[\n",
    "    'orgnbr',\n",
    "    'allowpromoyn'\n",
    "]].copy()\n",
    "dedupe_list = [\n",
    "    {'df':wh_org, 'field':'orgnbr'}\n",
    "]\n",
    "wh_org = cdutils.deduplication.dedupe(dedupe_list).copy()\n",
    "wh_org['orgnbr'] = wh_org['orgnbr'].astype(str)\n",
    "\n",
    "wh_pers = DeltaTable(src.config.BRONZE / \"wh_pers\").to_pandas()\n",
    "wh_pers = wh_pers[[\n",
    "    'persnbr',\n",
    "    'allowpromoyn'\n",
    "]].copy()\n",
    "dedupe_list = [\n",
    "    {'df':wh_pers, 'field':'persnbr'}\n",
    "]\n",
    "wh_pers = cdutils.deduplication.dedupe(dedupe_list).copy()\n",
    "wh_pers['persnbr'] = wh_pers['persnbr'].astype(str)\n",
    "\n",
    "accts = accts.merge(wh_org, left_on='taxrptforpersnbr', right_on='orgnbr').merge(wh_pers, left_on='taxrptforpersnbr', right_on='persnbr')\n",
    "accts['allowpromoyn'] = np.where(accts['allowpromoyn_x'].isnull(), accts['allowpromoyn_y'], accts['allowpromoyn_x'])\n",
    "accts = accts.drop(columns=['allowpromoyn_x','allowpromoyn_y','taxrptfororgnbr','taxrptforpersnbr',]).copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "accts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core logic specific to project/report\n",
    "\n",
    "import src.config\n",
    "import pandas as pd\n",
    "from deltalake import DeltaTable\n",
    "from pathlib import Path\n",
    "import cdutils.deduplication\n",
    "import src.loan_trial.fetch_data\n",
    "\n",
    "# def main_pipeline():\n",
    "# Main loan data, silver table\n",
    "TABLE_PATH = src.config.SILVER / \"account\"\n",
    "accts = DeltaTable(TABLE_PATH).to_pandas()\n",
    "\n",
    "MACRO_TYPE_MAPPING = {\n",
    "        'CML': 'Loan',\n",
    "        'MLN': 'Loan',\n",
    "        'CNS': 'Loan',\n",
    "        'MTG': 'Loan',\n",
    "        'CK': 'Deposit',\n",
    "        'SAV': 'Deposit',\n",
    "        'TD': 'Deposit'\n",
    "    }\n",
    "\n",
    "accts['Macro Account Type'] = accts['mjaccttypcd'].map(MACRO_TYPE_MAPPING)\n",
    "accts = accts[accts['Macro Account Type'] == 'Loan'].copy()\n",
    "\n",
    "accts = accts[[\n",
    "    'acctnbr',\n",
    "    'ownersortname',\n",
    "    'mjaccttypcd',\n",
    "    'currmiaccttypcd',\n",
    "    'product',\n",
    "    'curracctstatcd',\n",
    "    'noteintrate',\n",
    "    'notebal',\n",
    "    'bookbalance',\n",
    "    'branchname',\n",
    "    'loanofficer',\n",
    "    'contractdate',\n",
    "    'datemat',\n",
    "    'creditlimitamt',\n",
    "    'loanlimityn',\n",
    "]].copy()\n",
    "\n",
    "# Get investor data\n",
    "invr = src.loan_trial.fetch_data.fetch_invr()\n",
    "wh_invr = invr['wh_invr'].copy()\n",
    "\n",
    "\n",
    "acctgrpinvr = invr['acctgrpinvr'].copy()\n",
    "\n",
    "wh_org = DeltaTable(src.config.BRONZE / \"wh_org\").to_pandas()\n",
    "wh_org = wh_org[[\n",
    "    'orgnbr',\n",
    "    'orgname'\n",
    "]].copy()\n",
    "dedupe_list = [\n",
    "    {'df':wh_org, 'field':'orgnbr'}\n",
    "]\n",
    "wh_org = cdutils.deduplication.dedupe(dedupe_list).copy()\n",
    "wh_org['orgnbr'] = wh_org['orgnbr'].astype(str)\n",
    "wh_invr['acctgrpnbr'] = wh_invr['acctgrpnbr'].astype(str)\n",
    "acctgrpinvr['acctgrpnbr'] = wh_invr['acctgrpnbr'].astype(str)\n",
    "acctgrpinvr['invrorgnbr'] = acctgrpinvr['invrorgnbr'].astype(str)\n",
    "\n",
    "merged_investor = wh_invr.merge(acctgrpinvr, on='acctgrpnbr', how='left').merge(wh_org, left_on='invrorgnbr', right_on='orgnbr')\n",
    "merged_investor = merged_investor.sort_values(by='pctowned', ascending=False).copy()\n",
    "dedupe_list = [\n",
    "    {'df':merged_investor, 'field':'acctnbr'}\n",
    "]\n",
    "merged_investor = cdutils.deduplication.dedupe(dedupe_list)\n",
    "merged_investor = merged_investor.drop(columns=['orgnbr','invrorgnbr','pctowned','acctgrpnbr']).copy()\n",
    "merged_investor['acctnbr'] = merged_investor['acctnbr'].astype(str)\n",
    "assert merged_investor['acctnbr'].is_unique, \"Duplicates exist. Pre-merge of investor data to full df\"\n",
    "\n",
    "merged_investor = merged_investor.rename(columns={\n",
    "    'orgname':'Investor Name',\n",
    "    'originvrrate':'Orig Investor Rate',\n",
    "    'currinvrrate':'Current Investor Rate'\n",
    "}).copy()\n",
    "\n",
    "accts = accts.merge(merged_investor, on='acctnbr', how='left')\n",
    "# return accts\n",
    "\n",
    "\n",
    "# notenextratechange (WH_ACCTCOMMON)\n",
    "# noteratechangecalpercd (WH_ACCTCOMMON)\n",
    "# rcf\n",
    "#H\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daed6a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab344476",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_investor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f105653",
   "metadata": {},
   "outputs": [],
   "source": [
    "accts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_invr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00565532",
   "metadata": {},
   "outputs": [],
   "source": [
    "acctgrpinvr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5397824",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_investor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6c09a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdutils.database.connect # type: ignore\n",
    "from sqlalchemy import text # type: ignore\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "def fetch_rtxnbal():\n",
    "    participant = text(\"\"\"\n",
    "    SELECT\n",
    "        a.*\n",
    "    FROM\n",
    "        OSIBANK.RPT_MM_GLINT a\n",
    "    \"\"\")\n",
    "\n",
    "    queries = [\n",
    "        # {\n",
    "        #     'key': 'wh_rtxn',\n",
    "        #     'sql': wh_rtxn.bindparams(\n",
    "        #         start_date=start_date.strftime('%Y-%m-%d'),\n",
    "        #         end_date=end_date.strftime('%Y-%m-%d')\n",
    "        #     ),\n",
    "        #     'engine': 2\n",
    "        # },\n",
    "        {\n",
    "            'key': 'participant',\n",
    "            'sql': participant,\n",
    "            'engine': 1\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    data = cdutils.database.connect.retrieve_data(queries)\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_rtxnbal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bce313",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant = data['participant'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729c287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1137885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcsb-prod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
