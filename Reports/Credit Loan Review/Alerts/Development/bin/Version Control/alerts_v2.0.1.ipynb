{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Complete!\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Portfolio Alerts\n",
    "# Developed by CD\n",
    "# v2.0.1\n",
    "\n",
    "from io import StringIO\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta, date\n",
    "from sqlalchemy.ext.asyncio import create_async_engine\n",
    "from sqlalchemy import text\n",
    "from typing import List\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "from cryptography.fernet import Fernet\n",
    "from dotenv import load_dotenv\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import sys\n",
    "nest_asyncio.apply()\n",
    "\n",
    "if sys.platform == \"win32\":\n",
    "    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "\n",
    "\n",
    "def retrieve_data():\n",
    "    \"\"\"\n",
    "    Retrieve data from COCC database\n",
    "    \"\"\"\n",
    "    class DatabaseHandler:\n",
    "        \"\"\"\n",
    "        This class abstracts the connection to the database and allows a clean\n",
    "        interface for the developer to use.\n",
    "\n",
    "        This connector can handle async queries\n",
    "\n",
    "        \"\"\"\n",
    "        def __init__(self, tns_admin_path):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                tns_admin_path (str): Oracle driver path\n",
    "                credentials_path_db1 (str): Database 1 credentials path\n",
    "                credentials_path_db1 (str): Databsae 2 credentials path\n",
    "            \"\"\"\n",
    "            os.environ['TNS_ADMIN'] = tns_admin_path\n",
    "            \n",
    "            # Load private key\n",
    "            key_key_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Utility\\env_admin\\key.key'\n",
    "            with open(key_key_path, \"rb\") as key_file:\n",
    "                key = key_file.read()\n",
    "\n",
    "            cipher = Fernet(key)\n",
    "            \n",
    "            # Load encrypted data\n",
    "            encoded_env_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Utility\\env_admin\\.env.enc'\n",
    "            with open(encoded_env_path, \"rb\") as encrypted_file:\n",
    "                encrypted_data = encrypted_file.read()\n",
    "\n",
    "            decrypted_data = cipher.decrypt(encrypted_data).decode()\n",
    "\n",
    "            env_file = StringIO(decrypted_data)\n",
    "            load_dotenv(stream=env_file)\n",
    "\n",
    "            self.username1 = os.getenv('main_username')\n",
    "            self.password1 = os.getenv('main_password')\n",
    "            self.dsn1 = os.getenv('main_dsn')\n",
    "\n",
    "            self.username2 = os.getenv('datamart_username')\n",
    "            self.password2 = os.getenv('datamart_password')\n",
    "            self.dsn2 = os.getenv('datamart_dsn')\n",
    "\n",
    "            self.connection_string1 = f'oracle+oracledb://{self.username1}:{self.password1}@{self.dsn1}'\n",
    "            self.connection_string2 = f'oracle+oracledb://{self.username2}:{self.password2}@{self.dsn2}'\n",
    "\n",
    "            self.engine1 = create_async_engine(self.connection_string1, max_identifier_length=128, echo=False, future=True)\n",
    "            self.engine1.dialect.hide_parameters = True\n",
    "            self.engine2 = create_async_engine(self.connection_string2, max_identifier_length=128, echo=False, future=True)\n",
    "            self.engine1.dialect.hide_parameters = True\n",
    "\n",
    "\n",
    "        async def query(self, sql_query, engine=1):\n",
    "            \"\"\"\n",
    "            This allows abstraction of the connection and the class\n",
    "            so the developer can query a single table as a dataframe\n",
    "\n",
    "            Args:\n",
    "                sql_query (str): The query to SQL database is passed as a string\n",
    "                engine (int): This selects the database. There are two engines:\n",
    "                    1 -> R1625\n",
    "                    2 -> COCC DataMart\n",
    "\n",
    "            Returns:\n",
    "                df: The SQL query is returned as a pandas DataFrame\n",
    "\n",
    "            Usage:\n",
    "                df = db_handler.query(\"SELECT * FROM DB.TABLE\", engine=1)\n",
    "\n",
    "                In this example, db_handler = DatabaseHandler(args)\n",
    "            \"\"\"\n",
    "            if engine == 1:\n",
    "                selected_engine = self.engine1\n",
    "            elif engine == 2:\n",
    "                selected_engine = self.engine2\n",
    "            else:\n",
    "                raise ValueError(\"Engine must be 1 or 2\")\n",
    "\n",
    "            async with selected_engine.connect() as connection:\n",
    "                result = await connection.execute(sql_query)\n",
    "                rows = result.fetchall()\n",
    "                if not rows:\n",
    "                    return pd.DataFrame()\n",
    "                df = pd.DataFrame(rows, columns=result.keys())\n",
    "            return df\n",
    "\n",
    "        async def close(self):\n",
    "            if self.engine1:\n",
    "                await self.engine1.dispose()\n",
    "            if self.engine2:\n",
    "                await self.engine2.dispose()\n",
    "\n",
    "\n",
    "    # Database Connection Configuration\n",
    "    tns_admin_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Utility\\env_admin\\tns_admin'\n",
    "    db_handler = DatabaseHandler(tns_admin_path)\n",
    "\n",
    "    async def fetch_data(queries):\n",
    "        try:\n",
    "            tasks = {query['key']: asyncio.create_task(db_handler.query(query['sql'], query['engine'])) for query in queries}\n",
    "            results = await asyncio.gather(*tasks.values())\n",
    "            return {key: df for key, df in zip(tasks.keys(), results)}\n",
    "        except Exception as e:\n",
    "            print(f\"Error\")\n",
    "            raise\n",
    "        finally:\n",
    "            await db_handler.close()\n",
    "\n",
    "    def run_sql_queries():\n",
    "        # lookup table\n",
    "        # Engine 1\n",
    "        lookup_df = text(\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            sys.all_tab_columns col\n",
    "        \"\"\")\n",
    "\n",
    "        # acctcommon\n",
    "        # engine 1\n",
    "        acctcommon = text(\"\"\"\n",
    "        SELECT \n",
    "            a.ACCTNBR, \n",
    "            a.EFFDATE, \n",
    "            a.MJACCTTYPCD, \n",
    "            a.PRODUCT, \n",
    "            a.CURRMIACCTTYPCD, \n",
    "            a.BOOKBALANCE, \n",
    "            a.LOANOFFICER, \n",
    "            a.OWNERNAME, \n",
    "            a.CURRACCTSTATCD, \n",
    "            a.CONTRACTDATE, \n",
    "            a.NOTEBAL\n",
    "        FROM \n",
    "            OSIBANK.WH_ACCTCOMMON a\n",
    "        WHERE \n",
    "            a.CURRACCTSTATCD IN ('ACT')\n",
    "        \"\"\")\n",
    "\n",
    "        acctloan = text(\"\"\"\n",
    "        SELECT \n",
    "            a.ACCTNBR, \n",
    "            a.COBAL, \n",
    "            a.CREDITLIMITAMT, \n",
    "            a.RISKRATINGCD, \n",
    "            a.TOTALPCTSOLD, \n",
    "            a.CREDLIMITCLATRESAMT\n",
    "        FROM \n",
    "            OSIBANK.WH_ACCTLOAN a\n",
    "        \"\"\")\n",
    "\n",
    "        loans = text(\"\"\"\n",
    "        SELECT \n",
    "            a.ACCTNBR, \n",
    "            a.AVAILBALAMT\n",
    "        FROM \n",
    "            OSIBANK.WH_LOANS a\n",
    "        \"\"\")\n",
    "\n",
    "        househldacct = text(\"\"\"\n",
    "        SELECT \n",
    "            a.HOUSEHOLDNBR, \n",
    "            a.ACCTNBR\n",
    "        FROM \n",
    "            OSIEXTN.HOUSEHLDACCT a\n",
    "        \"\"\")\n",
    "\n",
    "        allroles = text(\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            OSIBANK.WH_ALLROLES a\n",
    "        WHERE\n",
    "            a.ACCTROLECD IN ('GUAR')\n",
    "        \"\"\")\n",
    "\n",
    "        persaddruse = text(\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            OSIBANK.PERSADDRUSE\n",
    "        \"\"\")\n",
    "\n",
    "        wh_addr = text(\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            OSIBANK.WH_ADDR\n",
    "        \"\"\")\n",
    "\n",
    "        pers = text(\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            OSIBANK.PERS\n",
    "        \"\"\")\n",
    "\n",
    "        acctstatistichist = text(\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            OSIBANK.ACCTSTATISTICHIST\n",
    "        \"\"\")\n",
    "\n",
    "        acctloanlimithist = text(\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            OSIBANK.ACCTLOANLIMITHIST\n",
    "        \"\"\")\n",
    "\n",
    "        queries = [\n",
    "            {'key':'acctcommon', 'sql':acctcommon, 'engine':1},\n",
    "            {'key':'acctloan', 'sql':acctloan, 'engine':1},\n",
    "            {'key':'loans', 'sql':loans, 'engine':1},\n",
    "            {'key':'househldacct', 'sql':househldacct, 'engine':1},\n",
    "            {'key':'allroles', 'sql':allroles, 'engine':1},\n",
    "            {'key':'persaddruse', 'sql':persaddruse, 'engine':1},\n",
    "            {'key':'wh_addr', 'sql':wh_addr, 'engine':1},\n",
    "            {'key':'pers', 'sql':pers, 'engine':1},\n",
    "            {'key':'acctstatistichist', 'sql':acctstatistichist, 'engine':1},\n",
    "            {'key':'acctloanlimithist', 'sql':acctloanlimithist, 'engine':1},\n",
    "        ]\n",
    "\n",
    "        async def run_queries():\n",
    "            return await fetch_data(queries)\n",
    "        \n",
    "        loop = asyncio.get_event_loop()\n",
    "        if loop.is_running():\n",
    "            return loop.run_until_complete(run_queries())\n",
    "        else:\n",
    "            return asyncio.run(run_queries())\n",
    "        \n",
    "    data = run_sql_queries()\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "#################################\n",
    "# Core ETL\n",
    "\n",
    "def filter_and_merge_loan_tables(acctcommon, acctloan, loans):\n",
    "    \"\"\"\n",
    "    This filters on CML Loans & merges tables to consolidate loan data.\n",
    "    Data cleansing on numeric fields is performed.\n",
    "    \n",
    "    Args:\n",
    "        acctcommon: WH_ACCTCOMMON\n",
    "        acctloan: WH_ACCTLOAN\n",
    "        loans: WH_LOANS\n",
    "        \n",
    "    Returns:\n",
    "        df: Consolidated loan data as a dataframe\n",
    "        \n",
    "    Operations:\n",
    "        - mjaccttypcd (Major) == 'CML'\n",
    "        - left merge of df (acctcommon) & acctloan on 'acctnbr'\n",
    "        - left merge of df & loans on 'acctnbr'\n",
    "        - drop all fields that are completely null/empty\n",
    "        - Replace null/na values with 0 for numeric fields:\n",
    "            - total pct sold\n",
    "            - avail bal amt\n",
    "            - credit limit collateral reserve amt\n",
    "        - loans with risk rating 4 or 5 are excluded\n",
    "    \"\"\"\n",
    "\n",
    "    # CML loans\n",
    "    df = acctcommon[acctcommon['mjaccttypcd'].isin(['CML'])]\n",
    "\n",
    "    # Merging and dropping blank fields\n",
    "    df = pd.merge(df, acctloan, on='acctnbr', how='left', suffixes=('_df', '_acctloan'))\n",
    "    df = pd.merge(df, loans, on='acctnbr', how='left', suffixes=('_df', '_loans'))\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    \n",
    "    # Data Cleansing\n",
    "    df['totalpctsold'] = df['totalpctsold'].fillna(0)\n",
    "    df['availbalamt'] = df['availbalamt'].fillna(0)\n",
    "    df['credlimitclatresamt'] = df['credlimitclatresamt'].fillna(0)\n",
    "    df = df[~df['riskratingcd'].isin(['4','5'])]\n",
    "    df = df[~df['curracctstatcd'].isin(['NPFM'])] # This is handled by SQL query normally\n",
    "    \n",
    "    # Unit test\n",
    "    assert not df['curracctstatcd'].isin(['NPFM']).any(), \"NPFM loans were not filtered out\"\n",
    "    assert not df['riskratingcd'].isin(['4','5']).any(), \"4 and 5 rated loans were not filtered out\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#################################\n",
    "def append_total_exposure_field(df):\n",
    "    \"\"\" \n",
    "    Single Obligor Exposure Calculation\n",
    "    \n",
    "    Args:\n",
    "        df: loan_data is loaded in\n",
    "    \n",
    "    Returns:\n",
    "        df: loan_data is returned with new fields appended\n",
    "        \n",
    "    Operations:\n",
    "        bookbalance -> if currmiaccttypcd == 'CM45', use notebal, else bookbalance\n",
    "            - Tax Exempt bonds always have $0 as book balance so adjustment is made\n",
    "        net balance == bookbalance - cobal\n",
    "            - BCSB balance - Charged off amount (COBAL)\n",
    "        net available == available balance amount * (1 - total pct sold)\n",
    "        net collateral reserve == collateral reserve * (1 - total pct sold)\n",
    "        total exposure == net balance + net available + net collateral reserve\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Tax Exempt bonds always have $0 Book Balance so need to take NOTEBAL\n",
    "    df['bookbalance'] = np.where(df['currmiaccttypcd'].isin(['CM45']), df['notebal'], df['bookbalance'])\n",
    "    df['Net Balance'] = df['bookbalance'] - df['cobal']\n",
    "    df['Net Available'] = df['availbalamt'] * (1 - df['totalpctsold'])\n",
    "    df['Net Collateral Reserve'] = df['credlimitclatresamt'] * (1 - df['totalpctsold'])\n",
    "    df['Total Exposure'] = df['Net Balance'] + df['Net Available'] + df['Net Collateral Reserve']\n",
    "    return df\n",
    "\n",
    "def drop_hh_duplicates(df):\n",
    "    \"\"\"\n",
    "    Drop duplicate rows in Household table\n",
    "    \n",
    "    Args:\n",
    "        df: HOUSEHLDACCT table (COCC)\n",
    "        \n",
    "    Returns:\n",
    "        cleaned_df: de-duplicated df\n",
    "        \n",
    "    Operations:\n",
    "        - drop_duplicates(subset='acctnbr', keep='first')\n",
    "    \"\"\"\n",
    "    cleaned_df = df.drop_duplicates(subset='acctnbr', keep='first')\n",
    "    \n",
    "    assert cleaned_df['acctnbr'].duplicated().sum() == 0, \"There are duplicate acctnbrs\" \n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "def append_household_number(df, househldacct):\n",
    "    \"\"\"\n",
    "    Append Household Number to Loan Data\n",
    "    \n",
    "    Args:\n",
    "        df: loan_data\n",
    "        househldacct: Household Acct Table from COCC (OSIEXTEN.HOUSEHLDACCT)\n",
    "    \n",
    "    Returns:\n",
    "        df: loan_data with household number appended\n",
    "        \n",
    "    Operations:\n",
    "        - Left merge of df & househldacct table on 'acctnbr'\n",
    "    \"\"\"\n",
    "    df = pd.merge(df, househldacct, on='acctnbr', how='left', suffixes=('_df', '_househldacct'))\n",
    "    return df\n",
    "\n",
    "\n",
    "def household_total_exposure(df):\n",
    "    \"\"\"\n",
    "    Household Total Exposure:\n",
    "    Grouping on household key, the total exposure is summed\n",
    "    \n",
    "    Args:\n",
    "        df: loan_data\n",
    "    \n",
    "    Returns:\n",
    "        household_grouping_df: A new dataframe with 2 columns:\n",
    "            - Householdnbr\n",
    "            - Total Exposure ($)\n",
    "    \n",
    "    Operations:\n",
    "        - Group By: Householdnbr\n",
    "        - Sum: Total Exposure\n",
    "    \n",
    "    \"\"\"\n",
    "    household_grouping_df = df.groupby('householdnbr')['Total Exposure'].sum().reset_index()\n",
    "    household_grouping_df = pd.DataFrame(household_grouping_df)\n",
    "    return household_grouping_df\n",
    "\n",
    "\n",
    "def append_household_exposure(df, household_grouping_df):\n",
    "    \"\"\"\n",
    "    Append household exposure back to loan_data\n",
    "    \n",
    "    Args:\n",
    "        df: loan_data\n",
    "        household_grouping_df: df with household number & total exposure\n",
    "        \n",
    "    Returns:\n",
    "        df: loan data after appending household exposure\n",
    "        \n",
    "    Operations:\n",
    "        - Left merge of df & household_grouping_df on 'householdnbr'\n",
    "        \n",
    "    \"\"\"\n",
    "    df = pd.merge(df, household_grouping_df, on='householdnbr', how='left', suffixes=('_df','_hhgroup'))\n",
    "    return df\n",
    "\n",
    "def filter_to_target_products(df):\n",
    "    \"\"\" \n",
    "    Filtering data down to products within Alerts criteria\n",
    "    \n",
    "    Args:\n",
    "        df: loan_data\n",
    "    \n",
    "    Returns:\n",
    "        df: loan_data after filters are applied to set the scope of Alerts system\n",
    "        \n",
    "    Operations:\n",
    "        - currmiaccttypcd (minor) is in:\n",
    "            - \"CM06\",\"CM11\",\"CM30\",\"CM52\",\"CM57\",\"CM62\",\"CM71\",\"CM76\"\n",
    "        - creditlimitamt <= $500,000\n",
    "        - total household exposure <= $1,000,000\n",
    "    \"\"\"\n",
    "    # Lines of Credit\n",
    "    df = df[df['currmiaccttypcd'].isin([\"CM06\",\"CM11\",\"CM30\",\"CM52\",\"CM57\",\"CM62\",\"CM71\",\"CM76\"])]\n",
    "    # Credit Limit Amount <= $500M & Household Exposure <= $1MM\n",
    "    df = df[(df['creditlimitamt'] <= 500000) & (df['Total Exposure_hhgroup'] <= 1000000)]\n",
    "    return df\n",
    "\n",
    "\n",
    "#################################\n",
    "# Personal Guarantors extracted\n",
    "def personal_guarantors(allroles, persaddruse, wh_addr, pers):\n",
    "    \"\"\"\n",
    "    Personal Guarantor information is pulled from COCC and several tables are merged.\n",
    "    \n",
    "    Args:\n",
    "        allroles: ALLROLES table (COCC)\n",
    "        persaddruse: PERSADDRUSE table (COCC)\n",
    "        wh_addr: WH_ADDR table (COCC)\n",
    "        pers: WH_PERS table (COCC)\n",
    "        \n",
    "    Returns:\n",
    "        df: Dataframe of personal guarantors\n",
    "        \n",
    "    Operations:\n",
    "        - allroles table where 'acctrolecd' = 'GUAR' (guarantor role)\n",
    "        - allroles where 'persnbr' is not null (this excludes organizations)\n",
    "        - persaddruse where 'addrusecd' == 'PRI' (only primary address is considered)\n",
    "        - left merge of allroles & persaddruse tables on 'persnbr'\n",
    "        - left merge of df (merged df from earlier step) & wh_addr on 'addrnbr'\n",
    "        - left merge of df & pers on 'persnbr'\n",
    "        - filtered out unnecessary fields\n",
    "            - keeping only ['acctnbr','persnbr','firstname','lastname','text1',\n",
    "                            'cityname','statecd','zipcd']\n",
    "    \"\"\"\n",
    "    allroles = allroles[allroles['acctrolecd'] == 'GUAR']\n",
    "    allroles = allroles[allroles['persnbr'].notnull()]\n",
    "    persaddruse = persaddruse[persaddruse['addrusecd'] == \"PRI\"]\n",
    "    # Merge\n",
    "    df = pd.merge(allroles, persaddruse, on='persnbr',how='left', suffixes=('_allroles','_persaddruse'))\n",
    "    df = pd.merge(df, wh_addr, on='addrnbr',how='left', suffixes=('_df','_addr'))\n",
    "    df = pd.merge(df, pers, on='persnbr', how='left', suffixes=('_df','_pers'))\n",
    "    df = df[['acctnbr','persnbr','firstname','lastname','text1','cityname','statecd','zipcd']]\n",
    "    return df\n",
    "\n",
    "def merge_guar_with_loan_data(df, pg_section):\n",
    "    \"\"\"\n",
    "    Merging Loan Data & Personal Guarantor information\n",
    "    \n",
    "    Args:\n",
    "        df: loan_data\n",
    "        pg_section: personal guarantor dataframe\n",
    "    \n",
    "    Returns:\n",
    "        df: loan_data merged with personal guarantor data (inner merge)\n",
    "        \n",
    "    Operations:\n",
    "        - Inner merge of df & pg_section (personal guarantor section) on 'acctnbr'\n",
    "    \"\"\"\n",
    "    df = pd.merge(df, pg_section, on='acctnbr', how='inner', suffixes=('_df','_pg'))\n",
    "    return df\n",
    "\n",
    "\n",
    "#################################\n",
    "def acctstatistichist_cleaning(df, acctcommon):\n",
    "    \"\"\" \n",
    "    Cleans acctstatistichist table and adds new fields for filtering\n",
    "    \n",
    "    Args:\n",
    "        df: ACCTSTATISTICHIST table (COCC)\n",
    "        acctcommon: WH_ACCTCOMMON table (COCC)\n",
    "            - Used for current date\n",
    "    \n",
    "    Returns:\n",
    "        df: ACCSTATISTICHIST with new calculated date fields\n",
    "            - 'event_date': date (month) of event occurance\n",
    "            - 'current_date': current_date\n",
    "            - 'year_start': First day of year (used for YTD calculations)\n",
    "            - 'year_ago_date': Today's date minus 1 year (for TTM calculations)\n",
    "        \n",
    "    Operations:\n",
    "        - monthcd zero fill 2 digits\n",
    "        - monthcd to string type\n",
    "        - yearnbr to string type\n",
    "        - event_date field = df['yearnbr'] + \"-\" + df['monthcd'] + \"-01\"\n",
    "        - current_date == First record in EFFDATE field from acctcommon table\n",
    "            -> this is appended to the dataframe as 'current_date' column\n",
    "        - year_start = current_date year + '01-01'\n",
    "        - year_ago_date = current_date - 1 year\n",
    "    \"\"\"\n",
    "    df['monthcd'] = df['monthcd'].str.zfill(2)\n",
    "    df['monthcd'] = df['monthcd'].astype(str)\n",
    "    df['yearnbr'] = df['yearnbr'].astype(str)\n",
    "    df['event_date'] = df['yearnbr'] + \"-\" + df['monthcd'] + \"-01\"\n",
    "    df['event_date'] = pd.to_datetime(df['event_date'])\n",
    "    \n",
    "    current_date = acctcommon['effdate'][0]\n",
    "    df['current_date'] = current_date\n",
    "    \n",
    "    df['year_start'] = pd.to_datetime(df['current_date'].dt.year.astype(str) + '-01-01')\n",
    "    df['year_ago_date'] = df['current_date'] - pd.DateOffset(years=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#################################\n",
    "def count_pd(df):\n",
    "    \"\"\"\n",
    "    This will count past due (15+) flags on the account\n",
    "    \n",
    "    Args:\n",
    "        df: ACCTSTATISTICHIST table (COCC)\n",
    "        \n",
    "    Returns:\n",
    "        merged_df: A dataframe with 3 columns:\n",
    "            - acctnbr\n",
    "            - ytd_pd (count)\n",
    "            - ttm_pd (count)\n",
    "    \n",
    "    Operations:\n",
    "        - ytd_df created where event_date >= year_start date\n",
    "        - ttm_df created where event_date >= year_ago date\n",
    "        - statistictypcd (statistic type code) = 'PD'\n",
    "        - Group by acctnbr, sum statistic count\n",
    "        - rename columns to ytd_pd & ttm_pd\n",
    "        - Outer merge ytd_df & ttm_df on acctnbr\n",
    "        - fill null values with 0\n",
    "    \"\"\"\n",
    "    ytd_df = df[df['event_date'] >= df['year_start']]\n",
    "    ttm_df = df[df['event_date'] >= df['year_ago_date']]\n",
    "    \n",
    "    ytd_df = ytd_df[ytd_df['statistictypcd'].isin(['PD'])]\n",
    "    ttm_df = ttm_df[ttm_df['statistictypcd'].isin(['PD'])]\n",
    "    \n",
    "    # Unit Tests\n",
    "    assert (ytd_df['event_date'] >= ytd_df['year_start']).all(), \"Filtering did not apply correctly\"\n",
    "    assert (ttm_df['event_date'] >= ttm_df['year_ago_date']).all(), \"Filtering did not apply correctly\"\n",
    "    \n",
    "    ytd_df = ytd_df.groupby('acctnbr')['statisticcount'].sum().reset_index()\n",
    "    ttm_df = ttm_df.groupby('acctnbr')['statisticcount'].sum().reset_index()\n",
    "    \n",
    "    ytd_df = ytd_df.rename(columns={'statisticcount':'ytd_pd'})\n",
    "    ttm_df = ttm_df.rename(columns={'statisticcount':'ttm_pd'})\n",
    "    \n",
    "    merged_df = pd.merge(ytd_df, ttm_df, on='acctnbr', how='outer')\n",
    "    merged_df['ytd_pd'] = merged_df['ytd_pd'].fillna(0)\n",
    "    merged_df['ttm_pd'] = merged_df['ttm_pd'].fillna(0)\n",
    "    \n",
    "    # Unit Tests\n",
    "    assert merged_df['ytd_pd'].isnull().sum() == 0, \"There are null values\"\n",
    "    assert merged_df['ttm_pd'].isnull().sum() == 0, \"There are null values\"\n",
    "\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "\n",
    "#################################\n",
    "def count_pd30(df):\n",
    "    \"\"\"\n",
    "    This will count past due (30+) flags on the account\n",
    "    \n",
    "    Args:\n",
    "        df: ACCTSTATISTICHIST table (COCC)\n",
    "        \n",
    "    Returns:\n",
    "        merged_df: A dataframe with 3 columns:\n",
    "            - acctnbr\n",
    "            - ytd_pd30 (count)\n",
    "            - ttm_pd30 (count)\n",
    "    \n",
    "    Operations:\n",
    "        - ytd_df created where event_date >= year_start date\n",
    "        - ttm_df created where event_date >= year_ago date\n",
    "        - statistictypcd (statistic type code) = 'PD30'\n",
    "        - Group by acctnbr, sum statistic count\n",
    "        - rename columns to ytd_pd30 & ttm_pd30\n",
    "        - Outer merge ytd_df & ttm_df on acctnbr\n",
    "        - fill null values with 0\n",
    "    \"\"\"\n",
    "    ytd_df = df[df['event_date'] >= df['year_start']]\n",
    "    ttm_df = df[df['event_date'] >= df['year_ago_date']]\n",
    "    \n",
    "    ytd_df = ytd_df[ytd_df['statistictypcd'].isin(['PD30'])]\n",
    "    ttm_df = ttm_df[ttm_df['statistictypcd'].isin(['PD30'])]\n",
    "    \n",
    "    # Unit Tests\n",
    "    assert (ytd_df['event_date'] >= ytd_df['year_start']).all(), \"Filtering did not apply correctly\"\n",
    "    assert (ttm_df['event_date'] >= ttm_df['year_ago_date']).all(), \"Filtering did not apply correctly\"\n",
    "    \n",
    "    ytd_df = ytd_df.groupby('acctnbr')['statisticcount'].sum().reset_index()\n",
    "    ttm_df = ttm_df.groupby('acctnbr')['statisticcount'].sum().reset_index()\n",
    "    \n",
    "    ytd_df = ytd_df.rename(columns={'statisticcount':'ytd_pd30'})\n",
    "    ttm_df = ttm_df.rename(columns={'statisticcount':'ttm_pd30'})\n",
    "    \n",
    "    merged_df = pd.merge(ytd_df, ttm_df, on='acctnbr', how='outer')\n",
    "    merged_df['ytd_pd30'] = merged_df['ytd_pd30'].fillna(0)\n",
    "    merged_df['ttm_pd30'] = merged_df['ttm_pd30'].fillna(0)\n",
    "    \n",
    "    # Unit Tests\n",
    "    assert merged_df['ytd_pd30'].isnull().sum() == 0, \"There are null values\"\n",
    "    assert merged_df['ttm_pd30'].isnull().sum() == 0, \"There are null values\"\n",
    "\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "\n",
    "#################################\n",
    "def append_pd_info(loan_data, pd_df, pd30_df):\n",
    "    \"\"\"\n",
    "    Appending past due and past due 30 counts to loan data\n",
    "    \n",
    "    Args:\n",
    "        loan_data: filtered down loan_data\n",
    "        pd_df: past due 15 days data\n",
    "        pd30_df: past due 30 days data\n",
    "        \n",
    "    Returns:\n",
    "        df: loan_data, with appended past due and past due 30 counts\n",
    "    \n",
    "    Operations:\n",
    "    \"\"\"\n",
    "    df = pd.merge(loan_data, pd_df, on='acctnbr', how='left')\n",
    "    df = pd.merge(df, pd30_df, on='acctnbr', how='left')\n",
    "    \n",
    "    df['ytd_pd'] = df['ytd_pd'].fillna(0)\n",
    "    df['ttm_pd'] = df['ttm_pd'].fillna(0)\n",
    "    df['ytd_pd30'] = df['ytd_pd30'].fillna(0)\n",
    "    df['ttm_pd30'] = df['ttm_pd30'].fillna(0)\n",
    "    \n",
    "    assert df['ytd_pd'].isnull().sum() == 0, \"There are null values\"\n",
    "    assert df['ttm_pd'].isnull().sum() == 0, \"There are null values\"\n",
    "    assert df['ytd_pd30'].isnull().sum() == 0, \"There are null values\"\n",
    "    assert df['ttm_pd30'].isnull().sum() == 0, \"There are null values\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#################################\n",
    "def deposit_criteria_testing():\n",
    "    \"\"\"\n",
    "    Consolidates deposits by household and calculates deposit change (%) over trailing 12 months\n",
    "        \n",
    "    Returns:\n",
    "        grouped_df: deposit dataframe with deposit change over time and count of overdrafts for each household\n",
    "        \n",
    "    Operations:\n",
    "        - Access daily deposit update from Excel file on DA-1 drive\n",
    "        - Fill null values with 0 for columns:\n",
    "            - NOTEBAL\n",
    "            - Year Ago Balance\n",
    "            - TTM Overdrafts\n",
    "        - Group by household number and sum NOTEBAL, Year Ago Balance, and TTM Overdrafts\n",
    "        - Deposit Change Pct = (NOTEBAL/Year Ago Balance) - 1\n",
    "        - Renamed HOUSEHOLDNBR field to match loan_data householdnbr field\n",
    "    \"\"\"\n",
    "    deposit_file_path = r'\\\\10.161.85.66\\Home\\Share\\Line of Business_Shared Services\\Commercial Credit\\Deposits\\DailyDeposit\\DailyDeposit.xlsx'\n",
    "    deposit_data = pd.read_excel(deposit_file_path, engine='openpyxl')\n",
    "    \n",
    "    deposit_data['NOTEBAL'].fillna(0)\n",
    "    deposit_data['Year Ago Balance'].fillna(0)\n",
    "    deposit_data['TTM Overdrafts'].fillna(0)\n",
    "\n",
    "    grouped_df = deposit_data.groupby('HOUSEHOLDNBR').agg({\n",
    "        'NOTEBAL':'sum',\n",
    "        'Year Ago Balance':'sum',\n",
    "        'TTM Overdrafts':'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    grouped_df['Deposit Change Pct'] = (grouped_df['NOTEBAL']/grouped_df['Year Ago Balance']) - 1\n",
    "    grouped_df = grouped_df.rename(columns={'HOUSEHOLDNBR':'householdnbr'})\n",
    "    \n",
    "    return grouped_df \n",
    "\n",
    "\n",
    "#################################\n",
    "def append_deposit_data(loan_data, deposit_data):\n",
    "    \"\"\"\n",
    "    Append deposit criteria to the loan data\n",
    "    \n",
    "    Args:\n",
    "        loan_data: loan data\n",
    "        deposit_data: deposit data aggregated to household\n",
    "        \n",
    "    Returns:\n",
    "        merged_df: loan_data with deposit data appended\n",
    "        \n",
    "    Operations:\n",
    "        - left merge with loan_data & deposit data on householdnbr\n",
    "    \n",
    "    \"\"\"\n",
    "    merged_df = pd.merge(loan_data, deposit_data, on='householdnbr', how='left')\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "#################################\n",
    "def line_utilization_fetch(loan_data):\n",
    "    \"\"\"\n",
    "    This function gathers line utilization data over past 12 months for each item\n",
    "    \n",
    "    Args:\n",
    "        db_handler: Database Connection abstraction for SQL query\n",
    "        loan_data: loan_data is passed in for unique account numbers\n",
    "        \n",
    "    Returns:\n",
    "        df1: Line Utilization\n",
    "            - 2 column table with:\n",
    "                - acctnbr\n",
    "                - avg line utilization over trailing 12 months\n",
    "            \n",
    "        df2: 30 Day Cleanup Provision\n",
    "            - 2 column table with:\n",
    "                - acctnbr\n",
    "                - cleanup (1=Fail, 0=Pass)\n",
    "    Operations:\n",
    "        - unique account numbers extracted from loan_data\n",
    "        - current_date and year_ago_date are calculated from loan_data (effdate)\n",
    "        - SQL Query:\n",
    "            SELECT b.ACCTNBR, b.EFFDATE, b.BOOKBALANCE, c.CREDITLIMITAMT\n",
    "            FROM COCCDM.WH_ACCTCOMMON b\n",
    "            JOIN COCCDM.WH_ACCTLOAN c\n",
    "            ON b.ACCTNBR = c.ACCTNBR AND b.EFFDATE = c.EFFDATE\n",
    "            WHERE b.ACCTNBR IN ({acctnbr_placeholder})\n",
    "            AND b.EFFDATE BETWEEN TO_DATE('{year_ago_date}', 'yyyy-mm-dd hh24:mi:ss') AND TO_DATE('{current_date}', 'yyyy-mm-dd hh24:mi:ss')\n",
    "        - if creditlimitamt is null, replace with 0\n",
    "        - Calculate line utilization:\n",
    "            - ttm line utilization = bookbalance / creditlimit amount\n",
    "            - fill na values with 0 (0/0) and inf with 100 (credit limit = 0, bookbalance > 0)\n",
    "            - group by acctnbr and take average line utilization\n",
    "        - Calculate 30 day cleanup provision:\n",
    "            - sort by acctnbr and effdate in ascending order\n",
    "            - create a rolling 30 day window and adjust slider through full date range for each\n",
    "            acctnbr\n",
    "            - return 0 if it was paid to 0 for at least 30 days in past year, else return 1 (fail)\n",
    "    \n",
    "    \"\"\"\n",
    "    acctnbrs = loan_data['acctnbr'].unique().tolist()\n",
    "    acctnbr_placeholder = ', '.join([f\"'{acct}'\" for acct in acctnbrs])\n",
    "    \n",
    "    current_date = loan_data['effdate'][0]\n",
    "    temp_data = {\n",
    "        'current_date': [current_date]\n",
    "    }\n",
    "\n",
    "    temp_df = pd.DataFrame(temp_data)\n",
    "    temp_df\n",
    "\n",
    "    temp_df['year_ago_date'] = temp_df['current_date'] - pd.DateOffset(years=1)\n",
    "\n",
    "    current_date = temp_df['current_date'][0].strftime('%Y-%m-%d')+' 00:00:00'\n",
    "    year_ago_date = temp_df['year_ago_date'][0].strftime('%Y-%m-%d')+' 00:00:00'\n",
    "    \n",
    "    def retrieve_data():\n",
    "\n",
    "        class DatabaseHandler:\n",
    "            \"\"\"\n",
    "            This class abstracts the connection to the database and allows a clean\n",
    "            interface for the developer to use.\n",
    "\n",
    "            This connector can handle async queries\n",
    "\n",
    "            \"\"\"\n",
    "            def __init__(self, tns_admin_path):\n",
    "                \"\"\"\n",
    "                Args:\n",
    "                    tns_admin_path (str): Oracle driver path\n",
    "                    credentials_path_db1 (str): Database 1 credentials path\n",
    "                    credentials_path_db1 (str): Databsae 2 credentials path\n",
    "                \"\"\"\n",
    "                os.environ['TNS_ADMIN'] = tns_admin_path\n",
    "                \n",
    "                # Load private key\n",
    "                key_key_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Utility\\env_admin\\key.key'\n",
    "                with open(key_key_path, \"rb\") as key_file:\n",
    "                    key = key_file.read()\n",
    "\n",
    "                cipher = Fernet(key)\n",
    "                \n",
    "                # Load encrypted data\n",
    "                encoded_env_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Utility\\env_admin\\.env.enc'\n",
    "                with open(encoded_env_path, \"rb\") as encrypted_file:\n",
    "                    encrypted_data = encrypted_file.read()\n",
    "\n",
    "                decrypted_data = cipher.decrypt(encrypted_data).decode()\n",
    "\n",
    "                env_file = StringIO(decrypted_data)\n",
    "                load_dotenv(stream=env_file)\n",
    "\n",
    "                self.username1 = os.getenv('main_username')\n",
    "                self.password1 = os.getenv('main_password')\n",
    "                self.dsn1 = os.getenv('main_dsn')\n",
    "\n",
    "                self.username2 = os.getenv('datamart_username')\n",
    "                self.password2 = os.getenv('datamart_password')\n",
    "                self.dsn2 = os.getenv('datamart_dsn')\n",
    "\n",
    "                self.connection_string1 = f'oracle+oracledb://{self.username1}:{self.password1}@{self.dsn1}'\n",
    "                self.connection_string2 = f'oracle+oracledb://{self.username2}:{self.password2}@{self.dsn2}'\n",
    "\n",
    "                self.engine1 = create_async_engine(self.connection_string1, max_identifier_length=128, echo=False, future=True)\n",
    "                self.engine1.dialect.hide_parameters = True\n",
    "                self.engine2 = create_async_engine(self.connection_string2, max_identifier_length=128, echo=False, future=True)\n",
    "                self.engine1.dialect.hide_parameters = True\n",
    "\n",
    "\n",
    "            async def query(self, sql_query, engine=1):\n",
    "                \"\"\"\n",
    "                This allows abstraction of the connection and the class\n",
    "                so the developer can query a single table as a dataframe\n",
    "\n",
    "                Args:\n",
    "                    sql_query (str): The query to SQL database is passed as a string\n",
    "                    engine (int): This selects the database. There are two engines:\n",
    "                        1 -> R1625\n",
    "                        2 -> COCC DataMart\n",
    "\n",
    "                Returns:\n",
    "                    df: The SQL query is returned as a pandas DataFrame\n",
    "\n",
    "                Usage:\n",
    "                    df = db_handler.query(\"SELECT * FROM DB.TABLE\", engine=1)\n",
    "\n",
    "                    In this example, db_handler = DatabaseHandler(args)\n",
    "                \"\"\"\n",
    "                if engine == 1:\n",
    "                    selected_engine = self.engine1\n",
    "                elif engine == 2:\n",
    "                    selected_engine = self.engine2\n",
    "                else:\n",
    "                    raise ValueError(\"Engine must be 1 or 2\")\n",
    "\n",
    "                async with selected_engine.connect() as connection:\n",
    "                    result = await connection.execute(sql_query)\n",
    "                    rows = result.fetchall()\n",
    "                    if not rows:\n",
    "                        return pd.DataFrame()\n",
    "                    df = pd.DataFrame(rows, columns=result.keys())\n",
    "                return df\n",
    "\n",
    "            async def close(self):\n",
    "                if self.engine1:\n",
    "                    await self.engine1.dispose()\n",
    "                if self.engine2:\n",
    "                    await self.engine2.dispose()\n",
    "\n",
    "\n",
    "        # Database Connection Configuration\n",
    "        tns_admin_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Utility\\env_admin\\tns_admin'\n",
    "        db_handler = DatabaseHandler(tns_admin_path)\n",
    "\n",
    "        async def fetch_data(queries):\n",
    "            try:\n",
    "                tasks = {query['key']: asyncio.create_task(db_handler.query(query['sql'], query['engine'])) for query in queries}\n",
    "                results = await asyncio.gather(*tasks.values())\n",
    "                return {key: df for key, df in zip(tasks.keys(), results)}\n",
    "            except Exception as e:\n",
    "                print(f\"Error\")\n",
    "                raise\n",
    "            finally:\n",
    "                await db_handler.close()\n",
    "\n",
    "        def run_sql_queries():\n",
    "            query = text(f\"\"\"\n",
    "                SELECT b.ACCTNBR, b.EFFDATE, b.BOOKBALANCE, c.CREDITLIMITAMT\n",
    "                FROM COCCDM.WH_ACCTCOMMON b\n",
    "                JOIN COCCDM.WH_ACCTLOAN c\n",
    "                ON b.ACCTNBR = c.ACCTNBR AND b.EFFDATE = c.EFFDATE\n",
    "                WHERE b.ACCTNBR IN ({acctnbr_placeholder})\n",
    "                AND b.EFFDATE BETWEEN TO_DATE('{year_ago_date}', 'yyyy-mm-dd hh24:mi:ss') AND TO_DATE('{current_date}', 'yyyy-mm-dd hh24:mi:ss')\n",
    "            \"\"\")\n",
    "\n",
    "            queries = [\n",
    "                {'key':'query', 'sql':query, 'engine':2},\n",
    "                # {'key':'acctcommon', 'sql':acctcommon, 'engine':1},\n",
    "                # {'key':'persaddruse', 'sql':persaddruse, 'engine':1},\n",
    "                # {'key':'orgaddruse', 'sql':orgaddruse, 'engine':1},\n",
    "                # {'key':'wh_addr', 'sql':wh_addr, 'engine':1},\n",
    "                # {'key':'wh_allroles', 'sql':wh_allroles, 'engine':1},\n",
    "            ]\n",
    "\n",
    "            async def run_queries():\n",
    "                return await fetch_data(queries)\n",
    "            \n",
    "            loop = asyncio.get_event_loop()\n",
    "            if loop.is_running():\n",
    "                return loop.run_until_complete(run_queries())\n",
    "            else:\n",
    "                return asyncio.run(run_queries())\n",
    "            \n",
    "        data = run_sql_queries()\n",
    "        \n",
    "        return data\n",
    "\n",
    "    data = retrieve_data()\n",
    "    df = data['query'].copy()\n",
    "    \n",
    "    df['bookbalance'] = pd.to_numeric(df['bookbalance'], errors='coerce')\n",
    "    df['creditlimitamt'] = pd.to_numeric(df['creditlimitamt'], errors='coerce')\n",
    "    \n",
    "    df['creditlimitamt'] = df['creditlimitamt'].fillna(0)\n",
    "    \n",
    "    df1 = df\n",
    "    df1['ttm line utilization'] = df1['bookbalance'] / df1['creditlimitamt']\n",
    "    df1['ttm line utilization'] = df1['ttm line utilization'].fillna(0)\n",
    "    df1['ttm line utilization'] = df1['ttm line utilization'].replace([np.inf], 1.00)\n",
    "    df1 = df1.groupby('acctnbr')['ttm line utilization'].mean().reset_index()\n",
    "    \n",
    "    df2 = df\n",
    "    df2['effdate'] = pd.to_datetime(df2['effdate'])\n",
    "    df2 = df2.sort_values(by=['acctnbr','effdate'])\n",
    "    \n",
    "    def check_30_day_cleanup(group):\n",
    "        group['rolling_zeros'] = group['bookbalance'].rolling(window=30).apply(lambda x: (x == 0).all(), raw=True)\n",
    "        return 0 if (group['rolling_zeros'] == 1).any() else 1\n",
    "    \n",
    "    df2 = df2.groupby('acctnbr').apply(check_30_day_cleanup, include_groups=False).reset_index(name='cleanup_provision')\n",
    "    \n",
    "    return df1, df2\n",
    "\n",
    "\n",
    "#################################\n",
    "def append_line_utilization_data(loan_data, utilization_data, cleanup_data):\n",
    "    \"\"\"\n",
    "    Appends line utilization data to loan_data\n",
    "    \n",
    "    Args:\n",
    "        utilization_data: df with line utilization % over ttm\n",
    "        cleanup_data : df with 30-day cleanup test (boolean)\n",
    "        \n",
    "    Returns:\n",
    "        df: loan_data with additional tests\n",
    "        \n",
    "    Operations:\n",
    "        - left merge with acctnbr & utilization data on acctnbr\n",
    "        - left merge with acctnbr & cleanup_data on acctnbr\n",
    "    \"\"\"\n",
    "    df = pd.merge(loan_data, utilization_data, on='acctnbr', how='left')\n",
    "    df = pd.merge(df, cleanup_data, on='acctnbr', how='left')\n",
    "    return df\n",
    "\n",
    "\n",
    "#################################\n",
    "def get_inactive_date(acctloanlimithist):\n",
    "    \"\"\"\n",
    "    Getting inactive date for each item\n",
    "    \n",
    "    Args: \n",
    "        acctloanlimithist: ACCTLOANLIMITHIST table (COCC)\n",
    "        \n",
    "    Returns:\n",
    "        df: df with the most recent inactive date per product\n",
    "        \n",
    "    Operations:\n",
    "        - ensure inactivedate is a datetime field\n",
    "        - groupby acctnbr, take max inactive date\n",
    "    \"\"\"\n",
    "    acctloanlimithist['inactivedate'] = pd.to_datetime(acctloanlimithist['inactivedate'])\n",
    "    df = acctloanlimithist.groupby('acctnbr')['inactivedate'].max().reset_index()\n",
    "    \n",
    "    assert df['acctnbr'].duplicated().sum() == 0, \"There are duplicate acctnbrs\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#################################\n",
    "def append_inactive_date(loan_data, inactive_date_df):\n",
    "    \"\"\"\n",
    "    Append inactive date to loan_data\n",
    "    \n",
    "    Args:\n",
    "        loan_data: loan_data\n",
    "        inactive_date_df = df with the most recent inactive date per product\n",
    "    \n",
    "    Returns:\n",
    "        df: loan_data with inactive date appended\n",
    "    \n",
    "    Operations:\n",
    "        - left merge with loan_data & inactive_date on acctnbr\n",
    "    \n",
    "    \"\"\"\n",
    "    df = pd.merge(loan_data, inactive_date_df, on='acctnbr', how='left')\n",
    "    return df\n",
    "\n",
    "\n",
    "#################################\n",
    "def criteria_flags(loan_data):\n",
    "    \"\"\"\n",
    "    Criteria flags are assigned on to each line item for\n",
    "    identification of fails.\n",
    "    \n",
    "    Args:\n",
    "        loan_data\n",
    "        \n",
    "        # Parameters\n",
    "        ttm_pd_amt = 3\n",
    "        ttm_pd30_amt = 1\n",
    "        ttm_overdrafts = 5\n",
    "        deposit_change_pct = -.3\n",
    "        min_deposits = 250000\n",
    "        utilization_limit = .6\n",
    "        \n",
    "    Returns:\n",
    "        df: loan_data with new identifier flag columns\n",
    "            ['past_due_flag']\n",
    "            ['ttm_overdrafts_flag']\n",
    "            ['deposit_change_flag']\n",
    "            ['ttm_utilization_flag']\n",
    "            - 'cleanup_provision' already exists as a boolean column\n",
    "    \n",
    "    Operations:\n",
    "        - parameters are set\n",
    "        - if ttm_pd > parameter or ttm_pd30 >= parameter, then past_due_flag = 1, else 0\n",
    "        - if ttm_overdrafts >= parameter, then ttm_overdrafts_flag = 1, else 0\n",
    "        - if deposit_change_pct >= parameter, then deposit_change_flag = 1, else 0\n",
    "        - if ttm_line_utilization >= parameter, then ttm_utilization_flag = 1, else 0\n",
    "        - flag created for passing all tests (1: passed all, 0: failed at least 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parameters\n",
    "    ttm_pd_amt = 3\n",
    "    ttm_pd30_amt = 1\n",
    "    ttm_overdrafts = 5\n",
    "    deposit_change_pct = -.3\n",
    "    min_deposits = 250000\n",
    "    utilization_limit = .6\n",
    "    \n",
    "    # Flag Column Creation\n",
    "    loan_data['past_due_flag'] = np.where((loan_data['ttm_pd'] >= ttm_pd_amt) | (loan_data['ttm_pd30'] >= ttm_pd30_amt), 1, 0) \n",
    "    loan_data['ttm_overdrafts_flag'] = np.where((loan_data['TTM Overdrafts'] >= ttm_overdrafts), 1, 0)\n",
    "    loan_data['deposit_change_flag'] = np.where((loan_data['Deposit Change Pct'] <= deposit_change_pct) & (loan_data['Year Ago Balance'] >= min_deposits), 1, 0)\n",
    "    loan_data['ttm_utilization_flag'] = np.where((loan_data['ttm line utilization'] >= .6), 1, 0)\n",
    "    loan_data['passed_all_flag'] = np.where((loan_data['past_due_flag'] == 0) & (loan_data['ttm_overdrafts_flag'] == 0) & (loan_data['deposit_change_flag'] == 0) & (loan_data['ttm_utilization_flag'] == 0) & (loan_data['cleanup_provision'] == 0), 1, 0)\n",
    "    \n",
    "    return loan_data\n",
    "\n",
    "\n",
    "# #################################\n",
    "def main():\n",
    "\n",
    "        # Database Connection Configuration\n",
    "    data = retrieve_data()\n",
    "\n",
    "\n",
    "    acctcommon = data['acctcommon'].copy()\n",
    "    acctloan = data['acctloan'].copy()\n",
    "    loans = data['loans'].copy()\n",
    "    househldacct = data['househldacct'].copy()\n",
    "\n",
    "    # # Data for Xactus\n",
    "    # allroles = data['allroles'].copy()\n",
    "    # persaddruse = data['persaddruse'].copy()\n",
    "    # wh_addr = data['wh_addr'].copy()\n",
    "    # pers = data['pers'].copy()\n",
    "\n",
    "    acctstatistichist = data['acctstatistichist'].copy()\n",
    "    acctloanlimithist = data['acctloanlimithist'].copy()\n",
    "\n",
    "    # Core ETL\n",
    "    loan_data = filter_and_merge_loan_tables(acctcommon, acctloan, loans)\n",
    "    loan_data = append_total_exposure_field(loan_data)\n",
    "    househldacct = drop_hh_duplicates(househldacct)\n",
    "    loan_data = append_household_number(loan_data, househldacct)\n",
    "    household_grouping_df = household_total_exposure(loan_data)\n",
    "    loan_data = append_household_exposure(loan_data, household_grouping_df)\n",
    "    loan_data = filter_to_target_products(loan_data)\n",
    "    acctstatistic_output = acctstatistichist_cleaning(acctstatistichist, acctcommon)\n",
    "    pd_df = count_pd(acctstatistic_output)\n",
    "    pd30_df = count_pd30(acctstatistic_output)\n",
    "    loan_data = append_pd_info(loan_data, pd_df, pd30_df)\n",
    "    deposit_data = deposit_criteria_testing()\n",
    "    loan_data = append_deposit_data(loan_data, deposit_data)\n",
    "    utilization_data, cleanup_data = line_utilization_fetch(loan_data)\n",
    "    loan_data = append_line_utilization_data(loan_data, utilization_data, cleanup_data)\n",
    "    inactive_date_df = get_inactive_date(acctloanlimithist)\n",
    "    loan_data = append_inactive_date(loan_data, inactive_date_df)\n",
    "    loan_data = criteria_flags(loan_data)\n",
    "\n",
    "    # Consolidation of the columns necessary\n",
    "    final_df = loan_data[['acctnbr','effdate','ownername','product','loanofficer','inactivedate','Net Balance','Net Available','Net Collateral Reserve','cobal','creditlimitamt','Total Exposure_hhgroup','ttm_pd','ttm_pd30','TTM Overdrafts','NOTEBAL','Year Ago Balance','Deposit Change Pct','ttm line utilization','cleanup_provision','riskratingcd','past_due_flag','ttm_overdrafts_flag','deposit_change_flag','ttm_utilization_flag','passed_all_flag']]\n",
    "\n",
    "    # Writing output\n",
    "    file_path = r'\\\\10.161.85.66\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Alerts\\Production\\Output\\alerts.xlsx'\n",
    "    final_df.to_excel(file_path, index=False, engine='openpyxl')\n",
    "\n",
    "    # Produce Documentation (docstrings)\n",
    "    documentation_list = [\n",
    "                            filter_and_merge_loan_tables, \n",
    "                            append_total_exposure_field, \n",
    "                            append_household_number, \n",
    "                            household_total_exposure, \n",
    "                            append_household_exposure, \n",
    "                            filter_to_target_products,\n",
    "                            acctstatistichist_cleaning,\n",
    "                            count_pd,\n",
    "                            count_pd30,\n",
    "                            append_pd_info,\n",
    "                            deposit_criteria_testing,\n",
    "                            append_deposit_data,\n",
    "                            line_utilization_fetch,\n",
    "                            append_line_utilization_data,\n",
    "                            get_inactive_date,\n",
    "                            append_inactive_date,\n",
    "                            criteria_flags]\n",
    "\n",
    "    # for i in documentation_list:\n",
    "    #     print(help(i))\n",
    "    #     print(\"\")\n",
    "        \n",
    "    print('Execution Complete!')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "    \n",
    "# main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data for Xactus\n",
    "allroles = data['allroles'].copy()\n",
    "persaddruse = data['persaddruse'].copy()\n",
    "wh_addr = data['wh_addr'].copy()\n",
    "pers = data['pers'].copy()\n",
    "################################\n",
    "# # Personal Guarantor\n",
    "pg_section = personal_guarantors(allroles, persaddruse, wh_addr, pers)\n",
    "target_loans_with_guar = merge_guar_with_loan_data(loan_data, pg_section)\n",
    "\n",
    "# assert len(target_loans_with_guar) > 0, \"There are no records\"\n",
    "# xactus_extract = target_loans_with_guar[['acctnbr','persnbr_pg','firstname','lastname','text1','cityname','statecd','zipcd']]\n",
    "# file_path = r'Y:\\GlobalWave\\CLO Intern Deliverables\\070824PFS_Check_v2.xlsx'\n",
    "# colin_list = pd.read_excel(file_path, engine='openpyxl')\n",
    "# colin_list = colin_list.astype({\"Person Number\": float})\n",
    "# merged_df = pd.merge(xactus_extract, colin_list, how='left', left_on='persnbr_pg', right_on='Person Number', suffixes=('_xactus','_colin'), indicator=True)\n",
    "# merged_df.groupby('_merge')['persnbr_pg'].count()\n",
    "# # Output Guarantor Data\n",
    "# file_name = r'\\\\10.161.85.66\\Home\\Share\\Line of Business_Shared Services\\Commercial Credit\\CML_Executive_Leadership_Projects\\Alerts\\Xactus\\Data\\guarantor_data.xlsx'\n",
    "# merged_df.to_excel(file_name, index=False)\n",
    "### Pending external action on the Xactus SFTP setup & information regarding permission to run soft pull credit scores\n",
    "### Will continue developing the other tests\n",
    "# target_loans_with_guar.info(verbose=True, null_counts=True)\n",
    "\n",
    "# # Initializing Database for Xactus\n",
    "# file_path = r'\\\\10.161.85.66\\Home\\Share\\Line of Business_Shared Services\\Commercial Credit\\CML_Executive_Leadership_Projects\\Alerts\\Xactus\\Database\\temporary.db'\n",
    "# engine = create_engine(f'sqlite:///{file_path}')\n",
    "\n",
    "# with engine.connect() as connection:\n",
    "#     connection.execute(\"\"\"\n",
    "#     CREATE TABLE IF NOT EXISTS guarantors (\n",
    "#         acctnbr INTEGER,\n",
    "#         persnbr INTEGER,\n",
    "#         firstname TEXT,\n",
    "#         lastname TEXT,\n",
    "#         creditscore INTEGER,\n",
    "#         effdate DATETIME\n",
    "#     );\n",
    "#     \"\"\")\n",
    "    \n",
    "# with engine.connect() as connection:\n",
    "#     data = pd.read_sql(\"SELECT * FROM guarantors\", connection)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 298 entries, 0 to 297\n",
      "Data columns (total 46 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   acctnbr                 298 non-null    int64         \n",
      " 1   effdate                 298 non-null    datetime64[ns]\n",
      " 2   mjaccttypcd             298 non-null    object        \n",
      " 3   product                 298 non-null    object        \n",
      " 4   currmiaccttypcd         298 non-null    object        \n",
      " 5   bookbalance             298 non-null    object        \n",
      " 6   loanofficer             298 non-null    object        \n",
      " 7   ownername               298 non-null    object        \n",
      " 8   curracctstatcd          298 non-null    object        \n",
      " 9   contractdate            298 non-null    datetime64[ns]\n",
      " 10  notebal                 298 non-null    object        \n",
      " 11  cobal                   298 non-null    object        \n",
      " 12  creditlimitamt          298 non-null    object        \n",
      " 13  riskratingcd            298 non-null    object        \n",
      " 14  totalpctsold            298 non-null    object        \n",
      " 15  credlimitclatresamt     298 non-null    object        \n",
      " 16  availbalamt             298 non-null    object        \n",
      " 17  Net Balance             298 non-null    object        \n",
      " 18  Net Available           298 non-null    object        \n",
      " 19  Net Collateral Reserve  298 non-null    object        \n",
      " 20  Total Exposure_df       298 non-null    object        \n",
      " 21  householdnbr            298 non-null    float64       \n",
      " 22  Total Exposure_hhgroup  298 non-null    object        \n",
      " 23  ytd_pd                  298 non-null    float64       \n",
      " 24  ttm_pd                  298 non-null    float64       \n",
      " 25  ytd_pd30                298 non-null    float64       \n",
      " 26  ttm_pd30                298 non-null    float64       \n",
      " 27  NOTEBAL                 291 non-null    float64       \n",
      " 28  Year Ago Balance        291 non-null    float64       \n",
      " 29  TTM Overdrafts          291 non-null    float64       \n",
      " 30  Deposit Change Pct      291 non-null    float64       \n",
      " 31  ttm line utilization    298 non-null    float64       \n",
      " 32  cleanup_provision       298 non-null    int64         \n",
      " 33  inactivedate            298 non-null    datetime64[ns]\n",
      " 34  past_due_flag           298 non-null    int64         \n",
      " 35  ttm_overdrafts_flag     298 non-null    int64         \n",
      " 36  deposit_change_flag     298 non-null    int64         \n",
      " 37  ttm_utilization_flag    298 non-null    int64         \n",
      " 38  passed_all_flag         298 non-null    int64         \n",
      " 39  persnbr                 298 non-null    float64       \n",
      " 40  firstname               298 non-null    object        \n",
      " 41  lastname                298 non-null    object        \n",
      " 42  text1                   297 non-null    object        \n",
      " 43  cityname                297 non-null    object        \n",
      " 44  statecd                 297 non-null    object        \n",
      " 45  zipcd                   297 non-null    object        \n",
      "dtypes: datetime64[ns](3), float64(11), int64(7), object(25)\n",
      "memory usage: 107.2+ KB\n"
     ]
    }
   ],
   "source": [
    "target_loans_with_guar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert len(target_loans_with_guar) > 0, \"There are no records\"\n",
    "xactus_extract = target_loans_with_guar[['acctnbr','persnbr','firstname','lastname','text1','cityname','statecd','zipcd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Alerts\\Production\\Xactus\\xactus_extract.xlsx'\n",
    "xactus_extract.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85050 entries, 0 to 85049\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   acctnbr          85050 non-null  int64         \n",
      " 1   effdate          85050 non-null  datetime64[ns]\n",
      " 2   mjaccttypcd      85050 non-null  object        \n",
      " 3   product          85050 non-null  object        \n",
      " 4   currmiaccttypcd  85050 non-null  object        \n",
      " 5   bookbalance      85050 non-null  object        \n",
      " 6   loanofficer      24358 non-null  object        \n",
      " 7   ownername        85050 non-null  object        \n",
      " 8   curracctstatcd   85050 non-null  object        \n",
      " 9   contractdate     85049 non-null  datetime64[ns]\n",
      " 10  notebal          85050 non-null  object        \n",
      "dtypes: datetime64[ns](2), int64(1), object(8)\n",
      "memory usage: 7.1+ MB\n"
     ]
    }
   ],
   "source": [
    "acctcommon.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ownername_df = acctcommon[['acctnbr','ownername']].copy()\n",
    "merged_xactus_extract = pd.merge(xactus_extract, ownername_df, how='left', on='acctnbr')\n",
    "file_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Alerts\\Production\\Xactus\\xactus_extract.xlsx'\n",
    "merged_xactus_extract.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_xactus_extract.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 298 entries, 0 to 297\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   acctnbr    298 non-null    int64  \n",
      " 1   persnbr    298 non-null    float64\n",
      " 2   firstname  298 non-null    object \n",
      " 3   lastname   298 non-null    object \n",
      " 4   text1      297 non-null    object \n",
      " 5   cityname   297 non-null    object \n",
      " 6   statecd    297 non-null    object \n",
      " 7   zipcd      297 non-null    object \n",
      " 8   ownername  298 non-null    object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 21.1+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_xactus_extract.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'Y:\\GlobalWave\\CLO Intern Deliverables\\070824PFS_Check_v2.xlsx'\n",
    "colin_list = pd.read_excel(file_path, engine='openpyxl')\n",
    "colin_list = colin_list.astype({\"Person Number\": float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account Number</th>\n",
       "      <th>Person Number</th>\n",
       "      <th>Person Name</th>\n",
       "      <th>Ownername</th>\n",
       "      <th>RISKRATINGCD</th>\n",
       "      <th>CURRACCTSTATCD</th>\n",
       "      <th>LOANOFFICER</th>\n",
       "      <th>Role Type</th>\n",
       "      <th>BCSB PFS in CT (Y/N)</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100135</td>\n",
       "      <td>1120917.0</td>\n",
       "      <td>Ronald R. Houle</td>\n",
       "      <td>H.B. Precision Products, Inc.</td>\n",
       "      <td>3P</td>\n",
       "      <td>ACT</td>\n",
       "      <td>SBLC LOAN OFFICER</td>\n",
       "      <td>GUAR</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151019596</td>\n",
       "      <td>1065620.0</td>\n",
       "      <td>Carlton E. Barney</td>\n",
       "      <td>The Glow Works, Inc. Dba The Lighting Gallery</td>\n",
       "      <td>3E</td>\n",
       "      <td>ACT</td>\n",
       "      <td>EBL PROGRAM ADMIN</td>\n",
       "      <td>GUAR</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150474866</td>\n",
       "      <td>1071878.0</td>\n",
       "      <td>Paul W. Riendeau</td>\n",
       "      <td>New England Refrigeration &amp; Heating Inc</td>\n",
       "      <td>3E</td>\n",
       "      <td>ACT</td>\n",
       "      <td>EBL PROGRAM ADMIN</td>\n",
       "      <td>GUAR</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150873901</td>\n",
       "      <td>1152441.0</td>\n",
       "      <td>David A. Soccio</td>\n",
       "      <td>Eagle Cornice Co. Inc</td>\n",
       "      <td>3C</td>\n",
       "      <td>ACT</td>\n",
       "      <td>DAMON T. ARPIN</td>\n",
       "      <td>GUAR</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150873901</td>\n",
       "      <td>1152442.0</td>\n",
       "      <td>Jon D. Hogberg</td>\n",
       "      <td>Eagle Cornice Co. Inc</td>\n",
       "      <td>3C</td>\n",
       "      <td>ACT</td>\n",
       "      <td>DAMON T. ARPIN</td>\n",
       "      <td>GUAR</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>500225281241</td>\n",
       "      <td>1033134.0</td>\n",
       "      <td>Frederick R. Reuter</td>\n",
       "      <td>Roseland Nursery Inc</td>\n",
       "      <td>3C</td>\n",
       "      <td>ACT</td>\n",
       "      <td>ROGER A. CABRAL</td>\n",
       "      <td>GUAR</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>500225281241</td>\n",
       "      <td>1068064.0</td>\n",
       "      <td>Susan L. Reuter</td>\n",
       "      <td>Roseland Nursery Inc</td>\n",
       "      <td>3C</td>\n",
       "      <td>ACT</td>\n",
       "      <td>ROGER A. CABRAL</td>\n",
       "      <td>GUAR</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>150952672</td>\n",
       "      <td>1068020.0</td>\n",
       "      <td>Louis F. Mathews</td>\n",
       "      <td>A &amp; L Plumbing Inc</td>\n",
       "      <td>3M</td>\n",
       "      <td>ACT</td>\n",
       "      <td>ANDREW J. OMER</td>\n",
       "      <td>GUAR</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>150952672</td>\n",
       "      <td>1062125.0</td>\n",
       "      <td>Stephen Antoch</td>\n",
       "      <td>A &amp; L Plumbing Inc</td>\n",
       "      <td>3M</td>\n",
       "      <td>ACT</td>\n",
       "      <td>ANDREW J. OMER</td>\n",
       "      <td>GUAR</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Account Number  Person Number          Person Name  \\\n",
       "0           100135      1120917.0      Ronald R. Houle   \n",
       "1        151019596      1065620.0    Carlton E. Barney   \n",
       "2        150474866      1071878.0     Paul W. Riendeau   \n",
       "3        150873901      1152441.0      David A. Soccio   \n",
       "4        150873901      1152442.0       Jon D. Hogberg   \n",
       "..             ...            ...                  ...   \n",
       "313   500225281241      1033134.0  Frederick R. Reuter   \n",
       "314   500225281241      1068064.0      Susan L. Reuter   \n",
       "315      150952672      1068020.0     Louis F. Mathews   \n",
       "316      150952672      1062125.0       Stephen Antoch   \n",
       "317          Total            NaN                  NaN   \n",
       "\n",
       "                                         Ownername RISKRATINGCD  \\\n",
       "0                    H.B. Precision Products, Inc.           3P   \n",
       "1    The Glow Works, Inc. Dba The Lighting Gallery           3E   \n",
       "2          New England Refrigeration & Heating Inc           3E   \n",
       "3                            Eagle Cornice Co. Inc           3C   \n",
       "4                            Eagle Cornice Co. Inc           3C   \n",
       "..                                             ...          ...   \n",
       "313                           Roseland Nursery Inc           3C   \n",
       "314                           Roseland Nursery Inc           3C   \n",
       "315                             A & L Plumbing Inc           3M   \n",
       "316                             A & L Plumbing Inc           3M   \n",
       "317                                            NaN          NaN   \n",
       "\n",
       "    CURRACCTSTATCD        LOANOFFICER Role Type BCSB PFS in CT (Y/N) Notes  \n",
       "0              ACT  SBLC LOAN OFFICER      GUAR                    Y   NaN  \n",
       "1              ACT  EBL PROGRAM ADMIN      GUAR                    Y   NaN  \n",
       "2              ACT  EBL PROGRAM ADMIN      GUAR                    Y   NaN  \n",
       "3              ACT     DAMON T. ARPIN      GUAR                    Y   NaN  \n",
       "4              ACT     DAMON T. ARPIN      GUAR                    Y   NaN  \n",
       "..             ...                ...       ...                  ...   ...  \n",
       "313            ACT    ROGER A. CABRAL      GUAR                    Y   NaN  \n",
       "314            ACT    ROGER A. CABRAL      GUAR                    Y   NaN  \n",
       "315            ACT     ANDREW J. OMER      GUAR                    Y   NaN  \n",
       "316            ACT     ANDREW J. OMER      GUAR                    Y   NaN  \n",
       "317            NaN                NaN       NaN                   65     9  \n",
       "\n",
       "[318 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
