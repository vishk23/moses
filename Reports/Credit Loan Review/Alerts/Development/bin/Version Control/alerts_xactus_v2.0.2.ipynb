{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Portfolio Alerts\n",
    "# Developed by CD\n",
    "# v2.0.1\n",
    "\n",
    "from io import StringIO\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta, date\n",
    "from sqlalchemy.ext.asyncio import create_async_engine\n",
    "from sqlalchemy import text\n",
    "from typing import List\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "from cryptography.fernet import Fernet\n",
    "from dotenv import load_dotenv\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import sys\n",
    "nest_asyncio.apply()\n",
    "\n",
    "if sys.platform == \"win32\":\n",
    "    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "\n",
    "\n",
    "def retrieve_data():\n",
    "    \"\"\"\n",
    "    Retrieve data from COCC database\n",
    "    \"\"\"\n",
    "    class DatabaseHandler:\n",
    "        \"\"\"\n",
    "        This class abstracts the connection to the database and allows a clean\n",
    "        interface for the developer to use.\n",
    "\n",
    "        This connector can handle async queries\n",
    "\n",
    "        \"\"\"\n",
    "        def __init__(self, tns_admin_path):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                tns_admin_path (str): Oracle driver path\n",
    "                credentials_path_db1 (str): Database 1 credentials path\n",
    "                credentials_path_db1 (str): Databsae 2 credentials path\n",
    "            \"\"\"\n",
    "            os.environ['TNS_ADMIN'] = tns_admin_path\n",
    "            \n",
    "            # Load private key\n",
    "            key_key_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Utility\\env_admin\\key.key'\n",
    "            with open(key_key_path, \"rb\") as key_file:\n",
    "                key = key_file.read()\n",
    "\n",
    "            cipher = Fernet(key)\n",
    "            \n",
    "            # Load encrypted data\n",
    "            encoded_env_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Utility\\env_admin\\.env.enc'\n",
    "            with open(encoded_env_path, \"rb\") as encrypted_file:\n",
    "                encrypted_data = encrypted_file.read()\n",
    "\n",
    "            decrypted_data = cipher.decrypt(encrypted_data).decode()\n",
    "\n",
    "            env_file = StringIO(decrypted_data)\n",
    "            load_dotenv(stream=env_file)\n",
    "\n",
    "            self.username1 = os.getenv('main_username')\n",
    "            self.password1 = os.getenv('main_password')\n",
    "            self.dsn1 = os.getenv('main_dsn')\n",
    "\n",
    "            self.username2 = os.getenv('datamart_username')\n",
    "            self.password2 = os.getenv('datamart_password')\n",
    "            self.dsn2 = os.getenv('datamart_dsn')\n",
    "\n",
    "            self.connection_string1 = f'oracle+oracledb://{self.username1}:{self.password1}@{self.dsn1}'\n",
    "            self.connection_string2 = f'oracle+oracledb://{self.username2}:{self.password2}@{self.dsn2}'\n",
    "\n",
    "            self.engine1 = create_async_engine(self.connection_string1, max_identifier_length=128, echo=False, future=True)\n",
    "            self.engine1.dialect.hide_parameters = True\n",
    "            self.engine2 = create_async_engine(self.connection_string2, max_identifier_length=128, echo=False, future=True)\n",
    "            self.engine1.dialect.hide_parameters = True\n",
    "\n",
    "\n",
    "        async def query(self, sql_query, engine=1):\n",
    "            \"\"\"\n",
    "            This allows abstraction of the connection and the class\n",
    "            so the developer can query a single table as a dataframe\n",
    "\n",
    "            Args:\n",
    "                sql_query (str): The query to SQL database is passed as a string\n",
    "                engine (int): This selects the database. There are two engines:\n",
    "                    1 -> R1625\n",
    "                    2 -> COCC DataMart\n",
    "\n",
    "            Returns:\n",
    "                df: The SQL query is returned as a pandas DataFrame\n",
    "\n",
    "            Usage:\n",
    "                df = db_handler.query(\"SELECT * FROM DB.TABLE\", engine=1)\n",
    "\n",
    "                In this example, db_handler = DatabaseHandler(args)\n",
    "            \"\"\"\n",
    "            if engine == 1:\n",
    "                selected_engine = self.engine1\n",
    "            elif engine == 2:\n",
    "                selected_engine = self.engine2\n",
    "            else:\n",
    "                raise ValueError(\"Engine must be 1 or 2\")\n",
    "\n",
    "            async with selected_engine.connect() as connection:\n",
    "                result = await connection.execute(sql_query)\n",
    "                rows = result.fetchall()\n",
    "                if not rows:\n",
    "                    return pd.DataFrame()\n",
    "                df = pd.DataFrame(rows, columns=result.keys())\n",
    "            return df\n",
    "\n",
    "        async def close(self):\n",
    "            if self.engine1:\n",
    "                await self.engine1.dispose()\n",
    "            if self.engine2:\n",
    "                await self.engine2.dispose()\n",
    "\n",
    "\n",
    "    # Database Connection Configuration\n",
    "    tns_admin_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Utility\\env_admin\\tns_admin'\n",
    "    db_handler = DatabaseHandler(tns_admin_path)\n",
    "\n",
    "    async def fetch_data(queries):\n",
    "        try:\n",
    "            tasks = {query['key']: asyncio.create_task(db_handler.query(query['sql'], query['engine'])) for query in queries}\n",
    "            results = await asyncio.gather(*tasks.values())\n",
    "            return {key: df for key, df in zip(tasks.keys(), results)}\n",
    "        except Exception as e:\n",
    "            print(f\"Error\")\n",
    "            raise\n",
    "        finally:\n",
    "            await db_handler.close()\n",
    "\n",
    "    def run_sql_queries():\n",
    "        # lookup table\n",
    "        # Engine 1\n",
    "        lookup_df = text(\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            sys.all_tab_columns col\n",
    "        \"\"\")\n",
    "\n",
    "        # acctcommon\n",
    "        # engine 1\n",
    "        acctcommon = text(\"\"\"\n",
    "        SELECT \n",
    "            a.ACCTNBR, \n",
    "            a.EFFDATE, \n",
    "            a.MJACCTTYPCD, \n",
    "            a.PRODUCT, \n",
    "            a.CURRMIACCTTYPCD, \n",
    "            a.BOOKBALANCE, \n",
    "            a.LOANOFFICER, \n",
    "            a.OWNERNAME, \n",
    "            a.CURRACCTSTATCD, \n",
    "            a.CONTRACTDATE, \n",
    "            a.NOTEBAL\n",
    "        FROM \n",
    "            OSIBANK.WH_ACCTCOMMON a\n",
    "        WHERE \n",
    "            a.CURRACCTSTATCD IN ('ACT')\n",
    "        \"\"\")\n",
    "\n",
    "        acctloan = text(\"\"\"\n",
    "        SELECT \n",
    "            a.ACCTNBR, \n",
    "            a.COBAL, \n",
    "            a.CREDITLIMITAMT, \n",
    "            a.RISKRATINGCD, \n",
    "            a.TOTALPCTSOLD, \n",
    "            a.CREDLIMITCLATRESAMT\n",
    "        FROM \n",
    "            OSIBANK.WH_ACCTLOAN a\n",
    "        \"\"\")\n",
    "\n",
    "        loans = text(\"\"\"\n",
    "        SELECT \n",
    "            a.ACCTNBR, \n",
    "            a.AVAILBALAMT\n",
    "        FROM \n",
    "            OSIBANK.WH_LOANS a\n",
    "        \"\"\")\n",
    "\n",
    "        househldacct = text(\"\"\"\n",
    "        SELECT \n",
    "            a.HOUSEHOLDNBR, \n",
    "            a.ACCTNBR\n",
    "        FROM \n",
    "            OSIEXTN.HOUSEHLDACCT a\n",
    "        \"\"\")\n",
    "\n",
    "        allroles = text(\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            OSIBANK.WH_ALLROLES a\n",
    "        WHERE\n",
    "            a.ACCTROLECD IN ('GUAR')\n",
    "        \"\"\")\n",
    "\n",
    "        persaddruse = text(\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            OSIBANK.PERSADDRUSE\n",
    "        \"\"\")\n",
    "\n",
    "        wh_addr = text(\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            OSIBANK.WH_ADDR\n",
    "        \"\"\")\n",
    "\n",
    "        pers = text(\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            OSIBANK.PERS\n",
    "        \"\"\")\n",
    "\n",
    "        acctstatistichist = text(\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            OSIBANK.ACCTSTATISTICHIST\n",
    "        \"\"\")\n",
    "\n",
    "        acctloanlimithist = text(\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            OSIBANK.ACCTLOANLIMITHIST\n",
    "        \"\"\")\n",
    "\n",
    "        queries = [\n",
    "            {'key':'acctcommon', 'sql':acctcommon, 'engine':1},\n",
    "            {'key':'acctloan', 'sql':acctloan, 'engine':1},\n",
    "            {'key':'loans', 'sql':loans, 'engine':1},\n",
    "            {'key':'househldacct', 'sql':househldacct, 'engine':1},\n",
    "            {'key':'allroles', 'sql':allroles, 'engine':1},\n",
    "            {'key':'persaddruse', 'sql':persaddruse, 'engine':1},\n",
    "            {'key':'wh_addr', 'sql':wh_addr, 'engine':1},\n",
    "            {'key':'pers', 'sql':pers, 'engine':1},\n",
    "            {'key':'acctstatistichist', 'sql':acctstatistichist, 'engine':1},\n",
    "            {'key':'acctloanlimithist', 'sql':acctloanlimithist, 'engine':1},\n",
    "        ]\n",
    "\n",
    "        async def run_queries():\n",
    "            return await fetch_data(queries)\n",
    "        \n",
    "        loop = asyncio.get_event_loop()\n",
    "        if loop.is_running():\n",
    "            return loop.run_until_complete(run_queries())\n",
    "        else:\n",
    "            return asyncio.run(run_queries())\n",
    "        \n",
    "    data = run_sql_queries()\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "#################################\n",
    "# Core ETL\n",
    "\n",
    "def filter_and_merge_loan_tables(acctcommon, acctloan, loans):\n",
    "    \"\"\"\n",
    "    This filters on CML Loans & merges tables to consolidate loan data.\n",
    "    Data cleansing on numeric fields is performed.\n",
    "    \n",
    "    Args:\n",
    "        acctcommon: WH_ACCTCOMMON\n",
    "        acctloan: WH_ACCTLOAN\n",
    "        loans: WH_LOANS\n",
    "        \n",
    "    Returns:\n",
    "        df: Consolidated loan data as a dataframe\n",
    "        \n",
    "    Operations:\n",
    "        - mjaccttypcd (Major) == 'CML'\n",
    "        - left merge of df (acctcommon) & acctloan on 'acctnbr'\n",
    "        - left merge of df & loans on 'acctnbr'\n",
    "        - drop all fields that are completely null/empty\n",
    "        - Replace null/na values with 0 for numeric fields:\n",
    "            - total pct sold\n",
    "            - avail bal amt\n",
    "            - credit limit collateral reserve amt\n",
    "        - loans with risk rating 4 or 5 are excluded\n",
    "    \"\"\"\n",
    "\n",
    "    # CML loans\n",
    "    df = acctcommon[acctcommon['mjaccttypcd'].isin(['CML'])]\n",
    "\n",
    "    # Merging and dropping blank fields\n",
    "    df = pd.merge(df, acctloan, on='acctnbr', how='left', suffixes=('_df', '_acctloan'))\n",
    "    df = pd.merge(df, loans, on='acctnbr', how='left', suffixes=('_df', '_loans'))\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    \n",
    "    # Data Cleansing\n",
    "    df['totalpctsold'] = df['totalpctsold'].fillna(0)\n",
    "    df['availbalamt'] = df['availbalamt'].fillna(0)\n",
    "    df['credlimitclatresamt'] = df['credlimitclatresamt'].fillna(0)\n",
    "    df = df[~df['riskratingcd'].isin(['4','5'])]\n",
    "    df = df[~df['curracctstatcd'].isin(['NPFM'])] # This is handled by SQL query normally\n",
    "    \n",
    "    # Unit test\n",
    "    assert not df['curracctstatcd'].isin(['NPFM']).any(), \"NPFM loans were not filtered out\"\n",
    "    assert not df['riskratingcd'].isin(['4','5']).any(), \"4 and 5 rated loans were not filtered out\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#################################\n",
    "def append_total_exposure_field(df):\n",
    "    \"\"\" \n",
    "    Single Obligor Exposure Calculation\n",
    "    \n",
    "    Args:\n",
    "        df: loan_data is loaded in\n",
    "    \n",
    "    Returns:\n",
    "        df: loan_data is returned with new fields appended\n",
    "        \n",
    "    Operations:\n",
    "        bookbalance -> if currmiaccttypcd == 'CM45', use notebal, else bookbalance\n",
    "            - Tax Exempt bonds always have $0 as book balance so adjustment is made\n",
    "        net balance == bookbalance - cobal\n",
    "            - BCSB balance - Charged off amount (COBAL)\n",
    "        net available == available balance amount * (1 - total pct sold)\n",
    "        net collateral reserve == collateral reserve * (1 - total pct sold)\n",
    "        total exposure == net balance + net available + net collateral reserve\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Tax Exempt bonds always have $0 Book Balance so need to take NOTEBAL\n",
    "    df['bookbalance'] = np.where(df['currmiaccttypcd'].isin(['CM45']), df['notebal'], df['bookbalance'])\n",
    "    df['Net Balance'] = df['bookbalance'] - df['cobal']\n",
    "    df['Net Available'] = df['availbalamt'] * (1 - df['totalpctsold'])\n",
    "    df['Net Collateral Reserve'] = df['credlimitclatresamt'] * (1 - df['totalpctsold'])\n",
    "    df['Total Exposure'] = df['Net Balance'] + df['Net Available'] + df['Net Collateral Reserve']\n",
    "    return df\n",
    "\n",
    "def drop_hh_duplicates(df):\n",
    "    \"\"\"\n",
    "    Drop duplicate rows in Household table\n",
    "    \n",
    "    Args:\n",
    "        df: HOUSEHLDACCT table (COCC)\n",
    "        \n",
    "    Returns:\n",
    "        cleaned_df: de-duplicated df\n",
    "        \n",
    "    Operations:\n",
    "        - drop_duplicates(subset='acctnbr', keep='first')\n",
    "    \"\"\"\n",
    "    cleaned_df = df.drop_duplicates(subset='acctnbr', keep='first')\n",
    "    \n",
    "    assert cleaned_df['acctnbr'].duplicated().sum() == 0, \"There are duplicate acctnbrs\" \n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "def append_household_number(df, househldacct):\n",
    "    \"\"\"\n",
    "    Append Household Number to Loan Data\n",
    "    \n",
    "    Args:\n",
    "        df: loan_data\n",
    "        househldacct: Household Acct Table from COCC (OSIEXTEN.HOUSEHLDACCT)\n",
    "    \n",
    "    Returns:\n",
    "        df: loan_data with household number appended\n",
    "        \n",
    "    Operations:\n",
    "        - Left merge of df & househldacct table on 'acctnbr'\n",
    "    \"\"\"\n",
    "    df = pd.merge(df, househldacct, on='acctnbr', how='left', suffixes=('_df', '_househldacct'))\n",
    "    return df\n",
    "\n",
    "\n",
    "def household_total_exposure(df):\n",
    "    \"\"\"\n",
    "    Household Total Exposure:\n",
    "    Grouping on household key, the total exposure is summed\n",
    "    \n",
    "    Args:\n",
    "        df: loan_data\n",
    "    \n",
    "    Returns:\n",
    "        household_grouping_df: A new dataframe with 2 columns:\n",
    "            - Householdnbr\n",
    "            - Total Exposure ($)\n",
    "    \n",
    "    Operations:\n",
    "        - Group By: Householdnbr\n",
    "        - Sum: Total Exposure\n",
    "    \n",
    "    \"\"\"\n",
    "    household_grouping_df = df.groupby('householdnbr')['Total Exposure'].sum().reset_index()\n",
    "    household_grouping_df = pd.DataFrame(household_grouping_df)\n",
    "    return household_grouping_df\n",
    "\n",
    "\n",
    "def append_household_exposure(df, household_grouping_df):\n",
    "    \"\"\"\n",
    "    Append household exposure back to loan_data\n",
    "    \n",
    "    Args:\n",
    "        df: loan_data\n",
    "        household_grouping_df: df with household number & total exposure\n",
    "        \n",
    "    Returns:\n",
    "        df: loan data after appending household exposure\n",
    "        \n",
    "    Operations:\n",
    "        - Left merge of df & household_grouping_df on 'householdnbr'\n",
    "        \n",
    "    \"\"\"\n",
    "    df = pd.merge(df, household_grouping_df, on='householdnbr', how='left', suffixes=('_df','_hhgroup'))\n",
    "    return df\n",
    "\n",
    "def filter_to_target_products(df):\n",
    "    \"\"\" \n",
    "    Filtering data down to products within Alerts criteria\n",
    "    \n",
    "    Args:\n",
    "        df: loan_data\n",
    "    \n",
    "    Returns:\n",
    "        df: loan_data after filters are applied to set the scope of Alerts system\n",
    "        \n",
    "    Operations:\n",
    "        - currmiaccttypcd (minor) is in:\n",
    "            - \"CM06\",\"CM11\",\"CM30\",\"CM52\",\"CM57\",\"CM62\",\"CM71\",\"CM76\"\n",
    "        - creditlimitamt <= $500,000\n",
    "        - total household exposure <= $1,000,000\n",
    "    \"\"\"\n",
    "    # Lines of Credit\n",
    "    df = df[df['currmiaccttypcd'].isin([\"CM06\",\"CM11\",\"CM30\",\"CM52\",\"CM57\",\"CM62\",\"CM71\",\"CM76\"])]\n",
    "    # Credit Limit Amount <= $500M & Household Exposure <= $1MM\n",
    "    df = df[(df['creditlimitamt'] <= 500000) & (df['Total Exposure_hhgroup'] <= 1000000)]\n",
    "    return df\n",
    "\n",
    "\n",
    "#################################\n",
    "# Personal Guarantors extracted\n",
    "def personal_guarantors(allroles, persaddruse, wh_addr, pers):\n",
    "    \"\"\"\n",
    "    Personal Guarantor information is pulled from COCC and several tables are merged.\n",
    "    \n",
    "    Args:\n",
    "        allroles: ALLROLES table (COCC)\n",
    "        persaddruse: PERSADDRUSE table (COCC)\n",
    "        wh_addr: WH_ADDR table (COCC)\n",
    "        pers: WH_PERS table (COCC)\n",
    "        \n",
    "    Returns:\n",
    "        df: Dataframe of personal guarantors\n",
    "        \n",
    "    Operations:\n",
    "        - allroles table where 'acctrolecd' = 'GUAR' (guarantor role)\n",
    "        - allroles where 'persnbr' is not null (this excludes organizations)\n",
    "        - persaddruse where 'addrusecd' == 'PRI' (only primary address is considered)\n",
    "        - left merge of allroles & persaddruse tables on 'persnbr'\n",
    "        - left merge of df (merged df from earlier step) & wh_addr on 'addrnbr'\n",
    "        - left merge of df & pers on 'persnbr'\n",
    "        - filtered out unnecessary fields\n",
    "            - keeping only ['acctnbr','persnbr','firstname','lastname','text1',\n",
    "                            'cityname','statecd','zipcd']\n",
    "    \"\"\"\n",
    "    allroles = allroles[allroles['acctrolecd'] == 'GUAR']\n",
    "    allroles = allroles[allroles['persnbr'].notnull()]\n",
    "    persaddruse = persaddruse[persaddruse['addrusecd'] == \"PRI\"]\n",
    "    # Merge\n",
    "    df = pd.merge(allroles, persaddruse, on='persnbr',how='left', suffixes=('_allroles','_persaddruse'))\n",
    "    df = pd.merge(df, wh_addr, on='addrnbr',how='left', suffixes=('_df','_addr'))\n",
    "    df = pd.merge(df, pers, on='persnbr', how='left', suffixes=('_df','_pers'))\n",
    "    df = df[['acctnbr','persnbr','firstname','lastname','text1','cityname','statecd','zipcd']]\n",
    "    return df\n",
    "\n",
    "def merge_guar_with_loan_data(df, pg_section):\n",
    "    \"\"\"\n",
    "    Merging Loan Data & Personal Guarantor information\n",
    "    \n",
    "    Args:\n",
    "        df: loan_data\n",
    "        pg_section: personal guarantor dataframe\n",
    "    \n",
    "    Returns:\n",
    "        df: loan_data merged with personal guarantor data (inner merge)\n",
    "        \n",
    "    Operations:\n",
    "        - Inner merge of df & pg_section (personal guarantor section) on 'acctnbr'\n",
    "    \"\"\"\n",
    "    df = pd.merge(df, pg_section, on='acctnbr', how='inner', suffixes=('_df','_pg'))\n",
    "    return df\n",
    "\n",
    "\n",
    "#################################\n",
    "def acctstatistichist_cleaning(df, acctcommon):\n",
    "    \"\"\" \n",
    "    Cleans acctstatistichist table and adds new fields for filtering\n",
    "    \n",
    "    Args:\n",
    "        df: ACCTSTATISTICHIST table (COCC)\n",
    "        acctcommon: WH_ACCTCOMMON table (COCC)\n",
    "            - Used for current date\n",
    "    \n",
    "    Returns:\n",
    "        df: ACCSTATISTICHIST with new calculated date fields\n",
    "            - 'event_date': date (month) of event occurance\n",
    "            - 'current_date': current_date\n",
    "            - 'year_start': First day of year (used for YTD calculations)\n",
    "            - 'year_ago_date': Today's date minus 1 year (for TTM calculations)\n",
    "        \n",
    "    Operations:\n",
    "        - monthcd zero fill 2 digits\n",
    "        - monthcd to string type\n",
    "        - yearnbr to string type\n",
    "        - event_date field = df['yearnbr'] + \"-\" + df['monthcd'] + \"-01\"\n",
    "        - current_date == First record in EFFDATE field from acctcommon table\n",
    "            -> this is appended to the dataframe as 'current_date' column\n",
    "        - year_start = current_date year + '01-01'\n",
    "        - year_ago_date = current_date - 1 year\n",
    "    \"\"\"\n",
    "    df['monthcd'] = df['monthcd'].str.zfill(2)\n",
    "    df['monthcd'] = df['monthcd'].astype(str)\n",
    "    df['yearnbr'] = df['yearnbr'].astype(str)\n",
    "    df['event_date'] = df['yearnbr'] + \"-\" + df['monthcd'] + \"-01\"\n",
    "    df['event_date'] = pd.to_datetime(df['event_date'])\n",
    "    \n",
    "    current_date = acctcommon['effdate'][0]\n",
    "    df['current_date'] = current_date\n",
    "    \n",
    "    df['year_start'] = pd.to_datetime(df['current_date'].dt.year.astype(str) + '-01-01')\n",
    "    df['year_ago_date'] = df['current_date'] - pd.DateOffset(years=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#################################\n",
    "def count_pd(df):\n",
    "    \"\"\"\n",
    "    This will count past due (15+) flags on the account\n",
    "    \n",
    "    Args:\n",
    "        df: ACCTSTATISTICHIST table (COCC)\n",
    "        \n",
    "    Returns:\n",
    "        merged_df: A dataframe with 3 columns:\n",
    "            - acctnbr\n",
    "            - ytd_pd (count)\n",
    "            - ttm_pd (count)\n",
    "    \n",
    "    Operations:\n",
    "        - ytd_df created where event_date >= year_start date\n",
    "        - ttm_df created where event_date >= year_ago date\n",
    "        - statistictypcd (statistic type code) = 'PD'\n",
    "        - Group by acctnbr, sum statistic count\n",
    "        - rename columns to ytd_pd & ttm_pd\n",
    "        - Outer merge ytd_df & ttm_df on acctnbr\n",
    "        - fill null values with 0\n",
    "    \"\"\"\n",
    "    ytd_df = df[df['event_date'] >= df['year_start']]\n",
    "    ttm_df = df[df['event_date'] >= df['year_ago_date']]\n",
    "    \n",
    "    ytd_df = ytd_df[ytd_df['statistictypcd'].isin(['PD'])]\n",
    "    ttm_df = ttm_df[ttm_df['statistictypcd'].isin(['PD'])]\n",
    "    \n",
    "    # Unit Tests\n",
    "    assert (ytd_df['event_date'] >= ytd_df['year_start']).all(), \"Filtering did not apply correctly\"\n",
    "    assert (ttm_df['event_date'] >= ttm_df['year_ago_date']).all(), \"Filtering did not apply correctly\"\n",
    "    \n",
    "    ytd_df = ytd_df.groupby('acctnbr')['statisticcount'].sum().reset_index()\n",
    "    ttm_df = ttm_df.groupby('acctnbr')['statisticcount'].sum().reset_index()\n",
    "    \n",
    "    ytd_df = ytd_df.rename(columns={'statisticcount':'ytd_pd'})\n",
    "    ttm_df = ttm_df.rename(columns={'statisticcount':'ttm_pd'})\n",
    "    \n",
    "    merged_df = pd.merge(ytd_df, ttm_df, on='acctnbr', how='outer')\n",
    "    merged_df['ytd_pd'] = merged_df['ytd_pd'].fillna(0)\n",
    "    merged_df['ttm_pd'] = merged_df['ttm_pd'].fillna(0)\n",
    "    \n",
    "    # Unit Tests\n",
    "    assert merged_df['ytd_pd'].isnull().sum() == 0, \"There are null values\"\n",
    "    assert merged_df['ttm_pd'].isnull().sum() == 0, \"There are null values\"\n",
    "\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "\n",
    "#################################\n",
    "def count_pd30(df):\n",
    "    \"\"\"\n",
    "    This will count past due (30+) flags on the account\n",
    "    \n",
    "    Args:\n",
    "        df: ACCTSTATISTICHIST table (COCC)\n",
    "        \n",
    "    Returns:\n",
    "        merged_df: A dataframe with 3 columns:\n",
    "            - acctnbr\n",
    "            - ytd_pd30 (count)\n",
    "            - ttm_pd30 (count)\n",
    "    \n",
    "    Operations:\n",
    "        - ytd_df created where event_date >= year_start date\n",
    "        - ttm_df created where event_date >= year_ago date\n",
    "        - statistictypcd (statistic type code) = 'PD30'\n",
    "        - Group by acctnbr, sum statistic count\n",
    "        - rename columns to ytd_pd30 & ttm_pd30\n",
    "        - Outer merge ytd_df & ttm_df on acctnbr\n",
    "        - fill null values with 0\n",
    "    \"\"\"\n",
    "    ytd_df = df[df['event_date'] >= df['year_start']]\n",
    "    ttm_df = df[df['event_date'] >= df['year_ago_date']]\n",
    "    \n",
    "    ytd_df = ytd_df[ytd_df['statistictypcd'].isin(['PD30'])]\n",
    "    ttm_df = ttm_df[ttm_df['statistictypcd'].isin(['PD30'])]\n",
    "    \n",
    "    # Unit Tests\n",
    "    assert (ytd_df['event_date'] >= ytd_df['year_start']).all(), \"Filtering did not apply correctly\"\n",
    "    assert (ttm_df['event_date'] >= ttm_df['year_ago_date']).all(), \"Filtering did not apply correctly\"\n",
    "    \n",
    "    ytd_df = ytd_df.groupby('acctnbr')['statisticcount'].sum().reset_index()\n",
    "    ttm_df = ttm_df.groupby('acctnbr')['statisticcount'].sum().reset_index()\n",
    "    \n",
    "    ytd_df = ytd_df.rename(columns={'statisticcount':'ytd_pd30'})\n",
    "    ttm_df = ttm_df.rename(columns={'statisticcount':'ttm_pd30'})\n",
    "    \n",
    "    merged_df = pd.merge(ytd_df, ttm_df, on='acctnbr', how='outer')\n",
    "    merged_df['ytd_pd30'] = merged_df['ytd_pd30'].fillna(0)\n",
    "    merged_df['ttm_pd30'] = merged_df['ttm_pd30'].fillna(0)\n",
    "    \n",
    "    # Unit Tests\n",
    "    assert merged_df['ytd_pd30'].isnull().sum() == 0, \"There are null values\"\n",
    "    assert merged_df['ttm_pd30'].isnull().sum() == 0, \"There are null values\"\n",
    "\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "\n",
    "#################################\n",
    "def append_pd_info(loan_data, pd_df, pd30_df):\n",
    "    \"\"\"\n",
    "    Appending past due and past due 30 counts to loan data\n",
    "    \n",
    "    Args:\n",
    "        loan_data: filtered down loan_data\n",
    "        pd_df: past due 15 days data\n",
    "        pd30_df: past due 30 days data\n",
    "        \n",
    "    Returns:\n",
    "        df: loan_data, with appended past due and past due 30 counts\n",
    "    \n",
    "    Operations:\n",
    "    \"\"\"\n",
    "    df = pd.merge(loan_data, pd_df, on='acctnbr', how='left')\n",
    "    df = pd.merge(df, pd30_df, on='acctnbr', how='left')\n",
    "    \n",
    "    df['ytd_pd'] = df['ytd_pd'].fillna(0)\n",
    "    df['ttm_pd'] = df['ttm_pd'].fillna(0)\n",
    "    df['ytd_pd30'] = df['ytd_pd30'].fillna(0)\n",
    "    df['ttm_pd30'] = df['ttm_pd30'].fillna(0)\n",
    "    \n",
    "    assert df['ytd_pd'].isnull().sum() == 0, \"There are null values\"\n",
    "    assert df['ttm_pd'].isnull().sum() == 0, \"There are null values\"\n",
    "    assert df['ytd_pd30'].isnull().sum() == 0, \"There are null values\"\n",
    "    assert df['ttm_pd30'].isnull().sum() == 0, \"There are null values\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#################################\n",
    "def deposit_criteria_testing():\n",
    "    \"\"\"\n",
    "    Consolidates deposits by household and calculates deposit change (%) over trailing 12 months\n",
    "        \n",
    "    Returns:\n",
    "        grouped_df: deposit dataframe with deposit change over time and count of overdrafts for each household\n",
    "        \n",
    "    Operations:\n",
    "        - Access daily deposit update from Excel file on DA-1 drive\n",
    "        - Fill null values with 0 for columns:\n",
    "            - NOTEBAL\n",
    "            - Year Ago Balance\n",
    "            - TTM Overdrafts\n",
    "        - Group by household number and sum NOTEBAL, Year Ago Balance, and TTM Overdrafts\n",
    "        - Deposit Change Pct = (NOTEBAL/Year Ago Balance) - 1\n",
    "        - Renamed HOUSEHOLDNBR field to match loan_data householdnbr field\n",
    "    \"\"\"\n",
    "    deposit_file_path = r'\\\\10.161.85.66\\Home\\Share\\Line of Business_Shared Services\\Commercial Credit\\Deposits\\DailyDeposit\\DailyDeposit.xlsx'\n",
    "    deposit_data = pd.read_excel(deposit_file_path, engine='openpyxl')\n",
    "    \n",
    "    deposit_data['NOTEBAL'].fillna(0)\n",
    "    deposit_data['Year Ago Balance'].fillna(0)\n",
    "    deposit_data['TTM Overdrafts'].fillna(0)\n",
    "\n",
    "    grouped_df = deposit_data.groupby('HOUSEHOLDNBR').agg({\n",
    "        'NOTEBAL':'sum',\n",
    "        'Year Ago Balance':'sum',\n",
    "        'TTM Overdrafts':'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    grouped_df['Deposit Change Pct'] = (grouped_df['NOTEBAL']/grouped_df['Year Ago Balance']) - 1\n",
    "    grouped_df = grouped_df.rename(columns={'HOUSEHOLDNBR':'householdnbr'})\n",
    "    \n",
    "    return grouped_df \n",
    "\n",
    "\n",
    "#################################\n",
    "def append_deposit_data(loan_data, deposit_data):\n",
    "    \"\"\"\n",
    "    Append deposit criteria to the loan data\n",
    "    \n",
    "    Args:\n",
    "        loan_data: loan data\n",
    "        deposit_data: deposit data aggregated to household\n",
    "        \n",
    "    Returns:\n",
    "        merged_df: loan_data with deposit data appended\n",
    "        \n",
    "    Operations:\n",
    "        - left merge with loan_data & deposit data on householdnbr\n",
    "    \n",
    "    \"\"\"\n",
    "    merged_df = pd.merge(loan_data, deposit_data, on='householdnbr', how='left')\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "#################################\n",
    "def line_utilization_fetch(loan_data):\n",
    "    \"\"\"\n",
    "    This function gathers line utilization data over past 12 months for each item\n",
    "    \n",
    "    Args:\n",
    "        db_handler: Database Connection abstraction for SQL query\n",
    "        loan_data: loan_data is passed in for unique account numbers\n",
    "        \n",
    "    Returns:\n",
    "        df1: Line Utilization\n",
    "            - 2 column table with:\n",
    "                - acctnbr\n",
    "                - avg line utilization over trailing 12 months\n",
    "            \n",
    "        df2: 30 Day Cleanup Provision\n",
    "            - 2 column table with:\n",
    "                - acctnbr\n",
    "                - cleanup (1=Fail, 0=Pass)\n",
    "    Operations:\n",
    "        - unique account numbers extracted from loan_data\n",
    "        - current_date and year_ago_date are calculated from loan_data (effdate)\n",
    "        - SQL Query:\n",
    "            SELECT b.ACCTNBR, b.EFFDATE, b.BOOKBALANCE, c.CREDITLIMITAMT\n",
    "            FROM COCCDM.WH_ACCTCOMMON b\n",
    "            JOIN COCCDM.WH_ACCTLOAN c\n",
    "            ON b.ACCTNBR = c.ACCTNBR AND b.EFFDATE = c.EFFDATE\n",
    "            WHERE b.ACCTNBR IN ({acctnbr_placeholder})\n",
    "            AND b.EFFDATE BETWEEN TO_DATE('{year_ago_date}', 'yyyy-mm-dd hh24:mi:ss') AND TO_DATE('{current_date}', 'yyyy-mm-dd hh24:mi:ss')\n",
    "        - if creditlimitamt is null, replace with 0\n",
    "        - Calculate line utilization:\n",
    "            - ttm line utilization = bookbalance / creditlimit amount\n",
    "            - fill na values with 0 (0/0) and inf with 100 (credit limit = 0, bookbalance > 0)\n",
    "            - group by acctnbr and take average line utilization\n",
    "        - Calculate 30 day cleanup provision:\n",
    "            - sort by acctnbr and effdate in ascending order\n",
    "            - create a rolling 30 day window and adjust slider through full date range for each\n",
    "            acctnbr\n",
    "            - return 0 if it was paid to 0 for at least 30 days in past year, else return 1 (fail)\n",
    "    \n",
    "    \"\"\"\n",
    "    acctnbrs = loan_data['acctnbr'].unique().tolist()\n",
    "    acctnbr_placeholder = ', '.join([f\"'{acct}'\" for acct in acctnbrs])\n",
    "    \n",
    "    current_date = loan_data['effdate'][0]\n",
    "    temp_data = {\n",
    "        'current_date': [current_date]\n",
    "    }\n",
    "\n",
    "    temp_df = pd.DataFrame(temp_data)\n",
    "    temp_df\n",
    "\n",
    "    temp_df['year_ago_date'] = temp_df['current_date'] - pd.DateOffset(years=1)\n",
    "\n",
    "    current_date = temp_df['current_date'][0].strftime('%Y-%m-%d')+' 00:00:00'\n",
    "    year_ago_date = temp_df['year_ago_date'][0].strftime('%Y-%m-%d')+' 00:00:00'\n",
    "    \n",
    "    def retrieve_data():\n",
    "\n",
    "        class DatabaseHandler:\n",
    "            \"\"\"\n",
    "            This class abstracts the connection to the database and allows a clean\n",
    "            interface for the developer to use.\n",
    "\n",
    "            This connector can handle async queries\n",
    "\n",
    "            \"\"\"\n",
    "            def __init__(self, tns_admin_path):\n",
    "                \"\"\"\n",
    "                Args:\n",
    "                    tns_admin_path (str): Oracle driver path\n",
    "                    credentials_path_db1 (str): Database 1 credentials path\n",
    "                    credentials_path_db1 (str): Databsae 2 credentials path\n",
    "                \"\"\"\n",
    "                os.environ['TNS_ADMIN'] = tns_admin_path\n",
    "                \n",
    "                # Load private key\n",
    "                key_key_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Utility\\env_admin\\key.key'\n",
    "                with open(key_key_path, \"rb\") as key_file:\n",
    "                    key = key_file.read()\n",
    "\n",
    "                cipher = Fernet(key)\n",
    "                \n",
    "                # Load encrypted data\n",
    "                encoded_env_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Utility\\env_admin\\.env.enc'\n",
    "                with open(encoded_env_path, \"rb\") as encrypted_file:\n",
    "                    encrypted_data = encrypted_file.read()\n",
    "\n",
    "                decrypted_data = cipher.decrypt(encrypted_data).decode()\n",
    "\n",
    "                env_file = StringIO(decrypted_data)\n",
    "                load_dotenv(stream=env_file)\n",
    "\n",
    "                self.username1 = os.getenv('main_username')\n",
    "                self.password1 = os.getenv('main_password')\n",
    "                self.dsn1 = os.getenv('main_dsn')\n",
    "\n",
    "                self.username2 = os.getenv('datamart_username')\n",
    "                self.password2 = os.getenv('datamart_password')\n",
    "                self.dsn2 = os.getenv('datamart_dsn')\n",
    "\n",
    "                self.connection_string1 = f'oracle+oracledb://{self.username1}:{self.password1}@{self.dsn1}'\n",
    "                self.connection_string2 = f'oracle+oracledb://{self.username2}:{self.password2}@{self.dsn2}'\n",
    "\n",
    "                self.engine1 = create_async_engine(self.connection_string1, max_identifier_length=128, echo=False, future=True)\n",
    "                self.engine1.dialect.hide_parameters = True\n",
    "                self.engine2 = create_async_engine(self.connection_string2, max_identifier_length=128, echo=False, future=True)\n",
    "                self.engine1.dialect.hide_parameters = True\n",
    "\n",
    "\n",
    "            async def query(self, sql_query, engine=1):\n",
    "                \"\"\"\n",
    "                This allows abstraction of the connection and the class\n",
    "                so the developer can query a single table as a dataframe\n",
    "\n",
    "                Args:\n",
    "                    sql_query (str): The query to SQL database is passed as a string\n",
    "                    engine (int): This selects the database. There are two engines:\n",
    "                        1 -> R1625\n",
    "                        2 -> COCC DataMart\n",
    "\n",
    "                Returns:\n",
    "                    df: The SQL query is returned as a pandas DataFrame\n",
    "\n",
    "                Usage:\n",
    "                    df = db_handler.query(\"SELECT * FROM DB.TABLE\", engine=1)\n",
    "\n",
    "                    In this example, db_handler = DatabaseHandler(args)\n",
    "                \"\"\"\n",
    "                if engine == 1:\n",
    "                    selected_engine = self.engine1\n",
    "                elif engine == 2:\n",
    "                    selected_engine = self.engine2\n",
    "                else:\n",
    "                    raise ValueError(\"Engine must be 1 or 2\")\n",
    "\n",
    "                async with selected_engine.connect() as connection:\n",
    "                    result = await connection.execute(sql_query)\n",
    "                    rows = result.fetchall()\n",
    "                    if not rows:\n",
    "                        return pd.DataFrame()\n",
    "                    df = pd.DataFrame(rows, columns=result.keys())\n",
    "                return df\n",
    "\n",
    "            async def close(self):\n",
    "                if self.engine1:\n",
    "                    await self.engine1.dispose()\n",
    "                if self.engine2:\n",
    "                    await self.engine2.dispose()\n",
    "\n",
    "\n",
    "        # Database Connection Configuration\n",
    "        tns_admin_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Utility\\env_admin\\tns_admin'\n",
    "        db_handler = DatabaseHandler(tns_admin_path)\n",
    "\n",
    "        async def fetch_data(queries):\n",
    "            try:\n",
    "                tasks = {query['key']: asyncio.create_task(db_handler.query(query['sql'], query['engine'])) for query in queries}\n",
    "                results = await asyncio.gather(*tasks.values())\n",
    "                return {key: df for key, df in zip(tasks.keys(), results)}\n",
    "            except Exception as e:\n",
    "                print(f\"Error\")\n",
    "                raise\n",
    "            finally:\n",
    "                await db_handler.close()\n",
    "\n",
    "        def run_sql_queries():\n",
    "            query = text(f\"\"\"\n",
    "                SELECT b.ACCTNBR, b.EFFDATE, b.BOOKBALANCE, c.CREDITLIMITAMT\n",
    "                FROM COCCDM.WH_ACCTCOMMON b\n",
    "                JOIN COCCDM.WH_ACCTLOAN c\n",
    "                ON b.ACCTNBR = c.ACCTNBR AND b.EFFDATE = c.EFFDATE\n",
    "                WHERE b.ACCTNBR IN ({acctnbr_placeholder})\n",
    "                AND b.EFFDATE BETWEEN TO_DATE('{year_ago_date}', 'yyyy-mm-dd hh24:mi:ss') AND TO_DATE('{current_date}', 'yyyy-mm-dd hh24:mi:ss')\n",
    "            \"\"\")\n",
    "\n",
    "            queries = [\n",
    "                {'key':'query', 'sql':query, 'engine':2},\n",
    "                # {'key':'acctcommon', 'sql':acctcommon, 'engine':1},\n",
    "                # {'key':'persaddruse', 'sql':persaddruse, 'engine':1},\n",
    "                # {'key':'orgaddruse', 'sql':orgaddruse, 'engine':1},\n",
    "                # {'key':'wh_addr', 'sql':wh_addr, 'engine':1},\n",
    "                # {'key':'wh_allroles', 'sql':wh_allroles, 'engine':1},\n",
    "            ]\n",
    "\n",
    "            async def run_queries():\n",
    "                return await fetch_data(queries)\n",
    "            \n",
    "            loop = asyncio.get_event_loop()\n",
    "            if loop.is_running():\n",
    "                return loop.run_until_complete(run_queries())\n",
    "            else:\n",
    "                return asyncio.run(run_queries())\n",
    "            \n",
    "        data = run_sql_queries()\n",
    "        \n",
    "        return data\n",
    "\n",
    "    data = retrieve_data()\n",
    "    df = data['query'].copy()\n",
    "    \n",
    "    df['bookbalance'] = pd.to_numeric(df['bookbalance'], errors='coerce')\n",
    "    df['creditlimitamt'] = pd.to_numeric(df['creditlimitamt'], errors='coerce')\n",
    "    \n",
    "    df['creditlimitamt'] = df['creditlimitamt'].fillna(0)\n",
    "    \n",
    "    df1 = df\n",
    "    df1['ttm line utilization'] = df1['bookbalance'] / df1['creditlimitamt']\n",
    "    df1['ttm line utilization'] = df1['ttm line utilization'].fillna(0)\n",
    "    df1['ttm line utilization'] = df1['ttm line utilization'].replace([np.inf], 1.00)\n",
    "    df1 = df1.groupby('acctnbr')['ttm line utilization'].mean().reset_index()\n",
    "    \n",
    "    df2 = df\n",
    "    df2['effdate'] = pd.to_datetime(df2['effdate'])\n",
    "    df2 = df2.sort_values(by=['acctnbr','effdate'])\n",
    "    \n",
    "    def check_30_day_cleanup(group):\n",
    "        group['rolling_zeros'] = group['bookbalance'].rolling(window=30).apply(lambda x: (x == 0).all(), raw=True)\n",
    "        return 0 if (group['rolling_zeros'] == 1).any() else 1\n",
    "    \n",
    "    df2 = df2.groupby('acctnbr').apply(check_30_day_cleanup, include_groups=False).reset_index(name='cleanup_provision')\n",
    "    \n",
    "    return df1, df2\n",
    "\n",
    "\n",
    "#################################\n",
    "def append_line_utilization_data(loan_data, utilization_data, cleanup_data):\n",
    "    \"\"\"\n",
    "    Appends line utilization data to loan_data\n",
    "    \n",
    "    Args:\n",
    "        utilization_data: df with line utilization % over ttm\n",
    "        cleanup_data : df with 30-day cleanup test (boolean)\n",
    "        \n",
    "    Returns:\n",
    "        df: loan_data with additional tests\n",
    "        \n",
    "    Operations:\n",
    "        - left merge with acctnbr & utilization data on acctnbr\n",
    "        - left merge with acctnbr & cleanup_data on acctnbr\n",
    "    \"\"\"\n",
    "    df = pd.merge(loan_data, utilization_data, on='acctnbr', how='left')\n",
    "    df = pd.merge(df, cleanup_data, on='acctnbr', how='left')\n",
    "    return df\n",
    "\n",
    "\n",
    "#################################\n",
    "def get_inactive_date(acctloanlimithist):\n",
    "    \"\"\"\n",
    "    Getting inactive date for each item\n",
    "    \n",
    "    Args: \n",
    "        acctloanlimithist: ACCTLOANLIMITHIST table (COCC)\n",
    "        \n",
    "    Returns:\n",
    "        df: df with the most recent inactive date per product\n",
    "        \n",
    "    Operations:\n",
    "        - ensure inactivedate is a datetime field\n",
    "        - groupby acctnbr, take max inactive date\n",
    "    \"\"\"\n",
    "    acctloanlimithist['inactivedate'] = pd.to_datetime(acctloanlimithist['inactivedate'])\n",
    "    df = acctloanlimithist.groupby('acctnbr')['inactivedate'].max().reset_index()\n",
    "    \n",
    "    assert df['acctnbr'].duplicated().sum() == 0, \"There are duplicate acctnbrs\"\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#################################\n",
    "def append_inactive_date(loan_data, inactive_date_df):\n",
    "    \"\"\"\n",
    "    Append inactive date to loan_data\n",
    "    \n",
    "    Args:\n",
    "        loan_data: loan_data\n",
    "        inactive_date_df = df with the most recent inactive date per product\n",
    "    \n",
    "    Returns:\n",
    "        df: loan_data with inactive date appended\n",
    "    \n",
    "    Operations:\n",
    "        - left merge with loan_data & inactive_date on acctnbr\n",
    "    \n",
    "    \"\"\"\n",
    "    df = pd.merge(loan_data, inactive_date_df, on='acctnbr', how='left')\n",
    "    return df\n",
    "\n",
    "\n",
    "#################################\n",
    "def criteria_flags(loan_data):\n",
    "    \"\"\"\n",
    "    Criteria flags are assigned on to each line item for\n",
    "    identification of fails.\n",
    "    \n",
    "    Args:\n",
    "        loan_data\n",
    "        \n",
    "        # Parameters\n",
    "        ttm_pd_amt = 3\n",
    "        ttm_pd30_amt = 1\n",
    "        ttm_overdrafts = 5\n",
    "        deposit_change_pct = -.3\n",
    "        min_deposits = 250000\n",
    "        utilization_limit = .6\n",
    "        \n",
    "    Returns:\n",
    "        df: loan_data with new identifier flag columns\n",
    "            ['past_due_flag']\n",
    "            ['ttm_overdrafts_flag']\n",
    "            ['deposit_change_flag']\n",
    "            ['ttm_utilization_flag']\n",
    "            - 'cleanup_provision' already exists as a boolean column\n",
    "    \n",
    "    Operations:\n",
    "        - parameters are set\n",
    "        - if ttm_pd > parameter or ttm_pd30 >= parameter, then past_due_flag = 1, else 0\n",
    "        - if ttm_overdrafts >= parameter, then ttm_overdrafts_flag = 1, else 0\n",
    "        - if deposit_change_pct >= parameter, then deposit_change_flag = 1, else 0\n",
    "        - if ttm_line_utilization >= parameter, then ttm_utilization_flag = 1, else 0\n",
    "        - flag created for passing all tests (1: passed all, 0: failed at least 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parameters\n",
    "    ttm_pd_amt = 3\n",
    "    ttm_pd30_amt = 1\n",
    "    ttm_overdrafts = 5\n",
    "    deposit_change_pct = -.3\n",
    "    min_deposits = 250000\n",
    "    utilization_limit = .6\n",
    "    \n",
    "    # Flag Column Creation\n",
    "    loan_data['past_due_flag'] = np.where((loan_data['ttm_pd'] >= ttm_pd_amt) | (loan_data['ttm_pd30'] >= ttm_pd30_amt), 1, 0) \n",
    "    loan_data['ttm_overdrafts_flag'] = np.where((loan_data['TTM Overdrafts'] >= ttm_overdrafts), 1, 0)\n",
    "    loan_data['deposit_change_flag'] = np.where((loan_data['Deposit Change Pct'] <= deposit_change_pct) & (loan_data['Year Ago Balance'] >= min_deposits), 1, 0)\n",
    "    loan_data['ttm_utilization_flag'] = np.where((loan_data['ttm line utilization'] >= utilization_limit), 1, 0)\n",
    "    loan_data['passed_all_flag'] = np.where((loan_data['past_due_flag'] == 0) & (loan_data['ttm_overdrafts_flag'] == 0) & (loan_data['deposit_change_flag'] == 0) & (loan_data['ttm_utilization_flag'] == 0) & (loan_data['cleanup_provision'] == 0), 1, 0)\n",
    "    \n",
    "    return loan_data\n",
    "\n",
    "\n",
    "# # #################################\n",
    "# def main():\n",
    "\n",
    "    # Database Connection Configuration\n",
    "data = retrieve_data()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "acctcommon = data['acctcommon'].copy()\n",
    "acctloan = data['acctloan'].copy()\n",
    "loans = data['loans'].copy()\n",
    "househldacct = data['househldacct'].copy()\n",
    "\n",
    "# Data for Xactus\n",
    "allroles = data['allroles'].copy()\n",
    "persaddruse = data['persaddruse'].copy()\n",
    "wh_addr = data['wh_addr'].copy()\n",
    "pers = data['pers'].copy()\n",
    "\n",
    "acctstatistichist = data['acctstatistichist'].copy()\n",
    "acctloanlimithist = data['acctloanlimithist'].copy()\n",
    "\n",
    "# Core ETL\n",
    "loan_data = filter_and_merge_loan_tables(acctcommon, acctloan, loans)\n",
    "loan_data = append_total_exposure_field(loan_data)\n",
    "househldacct = drop_hh_duplicates(househldacct)\n",
    "loan_data = append_household_number(loan_data, househldacct)\n",
    "household_grouping_df = household_total_exposure(loan_data)\n",
    "loan_data = append_household_exposure(loan_data, household_grouping_df)\n",
    "loan_data = filter_to_target_products(loan_data)\n",
    "acctstatistic_output = acctstatistichist_cleaning(acctstatistichist, acctcommon)\n",
    "pd_df = count_pd(acctstatistic_output)\n",
    "pd30_df = count_pd30(acctstatistic_output)\n",
    "loan_data = append_pd_info(loan_data, pd_df, pd30_df)\n",
    "deposit_data = deposit_criteria_testing()\n",
    "loan_data = append_deposit_data(loan_data, deposit_data)\n",
    "utilization_data, cleanup_data = line_utilization_fetch(loan_data)\n",
    "loan_data = append_line_utilization_data(loan_data, utilization_data, cleanup_data)\n",
    "inactive_date_df = get_inactive_date(acctloanlimithist)\n",
    "loan_data = append_inactive_date(loan_data, inactive_date_df)\n",
    "loan_data = criteria_flags(loan_data)\n",
    "\n",
    "# # Consolidation of the columns necessary\n",
    "# final_df = loan_data[['acctnbr','effdate','ownername','product','loanofficer','inactivedate','Net Balance','Net Available','Net Collateral Reserve','cobal','creditlimitamt','Total Exposure_hhgroup','ttm_pd','ttm_pd30','TTM Overdrafts','NOTEBAL','Year Ago Balance','Deposit Change Pct','ttm line utilization','cleanup_provision','riskratingcd','past_due_flag','ttm_overdrafts_flag','deposit_change_flag','ttm_utilization_flag','passed_all_flag']]\n",
    "\n",
    "# # Writing output\n",
    "# file_path = r'\\\\10.161.85.66\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Alerts\\Production\\Output\\alerts.xlsx'\n",
    "# final_df.to_excel(file_path, index=False, engine='openpyxl')\n",
    "\n",
    "# # Produce Documentation (docstrings)\n",
    "# documentation_list = [\n",
    "#                         filter_and_merge_loan_tables, \n",
    "#                         append_total_exposure_field, \n",
    "#                         append_household_number, \n",
    "#                         household_total_exposure, \n",
    "#                         append_household_exposure, \n",
    "#                         filter_to_target_products,\n",
    "#                         acctstatistichist_cleaning,\n",
    "#                         count_pd,\n",
    "#                         count_pd30,\n",
    "#                         append_pd_info,\n",
    "#                         deposit_criteria_testing,\n",
    "#                         append_deposit_data,\n",
    "#                         line_utilization_fetch,\n",
    "#                         append_line_utilization_data,\n",
    "#                         get_inactive_date,\n",
    "#                         append_inactive_date,\n",
    "#                         criteria_flags]\n",
    "\n",
    "# # for i in documentation_list:\n",
    "# #     print(help(i))\n",
    "# #     print(\"\")\n",
    "    \n",
    "# print('Execution Complete!')\n",
    "    \n",
    "# # if __name__ == \"__main__\":\n",
    "# #     main()\n",
    "\n",
    "    \n",
    "# # main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data for Xactus\n",
    "allroles = data['allroles'].copy()\n",
    "persaddruse = data['persaddruse'].copy()\n",
    "wh_addr = data['wh_addr'].copy()\n",
    "pers = data['pers'].copy()\n",
    "################################\n",
    "# # Personal Guarantor\n",
    "pg_section = personal_guarantors(allroles, persaddruse, wh_addr, pers)\n",
    "target_loans_with_guar = merge_guar_with_loan_data(loan_data, pg_section)\n",
    "\n",
    "# assert len(target_loans_with_guar) > 0, \"There are no records\"\n",
    "# xactus_extract = target_loans_with_guar[['acctnbr','persnbr_pg','firstname','lastname','text1','cityname','statecd','zipcd']]\n",
    "# file_path = r'Y:\\GlobalWave\\CLO Intern Deliverables\\070824PFS_Check_v2.xlsx'\n",
    "# colin_list = pd.read_excel(file_path, engine='openpyxl')\n",
    "# colin_list = colin_list.astype({\"Person Number\": float})\n",
    "# merged_df = pd.merge(xactus_extract, colin_list, how='left', left_on='persnbr_pg', right_on='Person Number', suffixes=('_xactus','_colin'), indicator=True)\n",
    "# merged_df.groupby('_merge')['persnbr_pg'].count()\n",
    "# # Output Guarantor Data\n",
    "# file_name = r'\\\\10.161.85.66\\Home\\Share\\Line of Business_Shared Services\\Commercial Credit\\CML_Executive_Leadership_Projects\\Alerts\\Xactus\\Data\\guarantor_data.xlsx'\n",
    "# merged_df.to_excel(file_name, index=False)\n",
    "### Pending external action on the Xactus SFTP setup & information regarding permission to run soft pull credit scores\n",
    "### Will continue developing the other tests\n",
    "# target_loans_with_guar.info(verbose=True, null_counts=True)\n",
    "\n",
    "# # Initializing Database for Xactus\n",
    "# file_path = r'\\\\10.161.85.66\\Home\\Share\\Line of Business_Shared Services\\Commercial Credit\\CML_Executive_Leadership_Projects\\Alerts\\Xactus\\Database\\temporary.db'\n",
    "# engine = create_engine(f'sqlite:///{file_path}')\n",
    "\n",
    "# with engine.connect() as connection:\n",
    "#     connection.execute(\"\"\"\n",
    "#     CREATE TABLE IF NOT EXISTS guarantors (\n",
    "#         acctnbr INTEGER,\n",
    "#         persnbr INTEGER,\n",
    "#         firstname TEXT,\n",
    "#         lastname TEXT,\n",
    "#         creditscore INTEGER,\n",
    "#         effdate DATETIME\n",
    "#     );\n",
    "#     \"\"\")\n",
    "    \n",
    "# with engine.connect() as connection:\n",
    "#     data = pd.read_sql(\"SELECT * FROM guarantors\", connection)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 301 entries, 0 to 300\n",
      "Data columns (total 46 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   acctnbr                 301 non-null    int64         \n",
      " 1   effdate                 301 non-null    datetime64[ns]\n",
      " 2   mjaccttypcd             301 non-null    object        \n",
      " 3   product                 301 non-null    object        \n",
      " 4   currmiaccttypcd         301 non-null    object        \n",
      " 5   bookbalance             301 non-null    object        \n",
      " 6   loanofficer             301 non-null    object        \n",
      " 7   ownername               301 non-null    object        \n",
      " 8   curracctstatcd          301 non-null    object        \n",
      " 9   contractdate            301 non-null    datetime64[ns]\n",
      " 10  notebal                 301 non-null    object        \n",
      " 11  cobal                   301 non-null    object        \n",
      " 12  creditlimitamt          301 non-null    object        \n",
      " 13  riskratingcd            301 non-null    object        \n",
      " 14  totalpctsold            301 non-null    object        \n",
      " 15  credlimitclatresamt     301 non-null    object        \n",
      " 16  availbalamt             301 non-null    object        \n",
      " 17  Net Balance             301 non-null    object        \n",
      " 18  Net Available           301 non-null    object        \n",
      " 19  Net Collateral Reserve  301 non-null    object        \n",
      " 20  Total Exposure_df       301 non-null    object        \n",
      " 21  householdnbr            301 non-null    float64       \n",
      " 22  Total Exposure_hhgroup  301 non-null    object        \n",
      " 23  ytd_pd                  301 non-null    float64       \n",
      " 24  ttm_pd                  301 non-null    float64       \n",
      " 25  ytd_pd30                301 non-null    float64       \n",
      " 26  ttm_pd30                301 non-null    float64       \n",
      " 27  NOTEBAL                 294 non-null    float64       \n",
      " 28  Year Ago Balance        294 non-null    float64       \n",
      " 29  TTM Overdrafts          294 non-null    float64       \n",
      " 30  Deposit Change Pct      294 non-null    float64       \n",
      " 31  ttm line utilization    301 non-null    float64       \n",
      " 32  cleanup_provision       301 non-null    int64         \n",
      " 33  inactivedate            301 non-null    datetime64[ns]\n",
      " 34  past_due_flag           301 non-null    int64         \n",
      " 35  ttm_overdrafts_flag     301 non-null    int64         \n",
      " 36  deposit_change_flag     301 non-null    int64         \n",
      " 37  ttm_utilization_flag    301 non-null    int64         \n",
      " 38  passed_all_flag         301 non-null    int64         \n",
      " 39  persnbr                 301 non-null    float64       \n",
      " 40  firstname               301 non-null    object        \n",
      " 41  lastname                301 non-null    object        \n",
      " 42  text1                   300 non-null    object        \n",
      " 43  cityname                300 non-null    object        \n",
      " 44  statecd                 300 non-null    object        \n",
      " 45  zipcd                   300 non-null    object        \n",
      "dtypes: datetime64[ns](3), float64(11), int64(7), object(25)\n",
      "memory usage: 108.3+ KB\n"
     ]
    }
   ],
   "source": [
    "target_loans_with_guar.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert len(target_loans_with_guar) > 0, \"There are no records\"\n",
    "xactus_extract = target_loans_with_guar[['acctnbr','persnbr','firstname','lastname','text1','cityname','statecd','zipcd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with Colin dataset\n",
    "colin_path = r'Z:\\Chad Projects\\Alerts\\Production\\Xactus\\Colin_PFS_check_completed\\010925PFSCheck2.xlsx'\n",
    "colin_df = pd.read_excel(colin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Permission 1/9/25\n",
       "Y    235\n",
       "N     63\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colin_df['Permission 1/9/25'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acctnbr</th>\n",
       "      <th>persnbr</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>text1</th>\n",
       "      <th>cityname</th>\n",
       "      <th>statecd</th>\n",
       "      <th>zipcd</th>\n",
       "      <th>ownername</th>\n",
       "      <th>Permission 7/8/24</th>\n",
       "      <th>Permission 1/9/25</th>\n",
       "      <th>Date of PFS</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150894551</td>\n",
       "      <td>1154368</td>\n",
       "      <td>NATHAN</td>\n",
       "      <td>RAY</td>\n",
       "      <td>135 ANGELL RD</td>\n",
       "      <td>CUMBERLAND</td>\n",
       "      <td>RI</td>\n",
       "      <td>2864.0</td>\n",
       "      <td>FAMILYSTORE.IO LLC</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>Update PFS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150498569</td>\n",
       "      <td>1032720</td>\n",
       "      <td>WALTER</td>\n",
       "      <td>ARAUJO</td>\n",
       "      <td>23 FAIRWAY DR</td>\n",
       "      <td>ACUSHNET</td>\n",
       "      <td>MA</td>\n",
       "      <td>2743.0</td>\n",
       "      <td>ARAUJO LANDSCAPING INC.</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150498569</td>\n",
       "      <td>1039104</td>\n",
       "      <td>MARINA</td>\n",
       "      <td>ARAUJO</td>\n",
       "      <td>23 FAIRWAY DR</td>\n",
       "      <td>ACUSHNET</td>\n",
       "      <td>MA</td>\n",
       "      <td>2743.0</td>\n",
       "      <td>ARAUJO LANDSCAPING INC.</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150304683</td>\n",
       "      <td>421</td>\n",
       "      <td>NANCY</td>\n",
       "      <td>DASILVA</td>\n",
       "      <td>2265 WHEELER ST</td>\n",
       "      <td>NORTH DIGHTON</td>\n",
       "      <td>MA</td>\n",
       "      <td>2764.0</td>\n",
       "      <td>2120 PLEASANT STREET REALTY TRUST</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150304683</td>\n",
       "      <td>1027703</td>\n",
       "      <td>BRIAN</td>\n",
       "      <td>DASILVA</td>\n",
       "      <td>2265 WHEELER ST</td>\n",
       "      <td>NORTH DIGHTON</td>\n",
       "      <td>MA</td>\n",
       "      <td>2764.0</td>\n",
       "      <td>2120 PLEASANT STREET REALTY TRUST</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>151062743</td>\n",
       "      <td>1105528</td>\n",
       "      <td>STEPHEN</td>\n",
       "      <td>MURPHY</td>\n",
       "      <td>62 WEST ST</td>\n",
       "      <td>CARVER</td>\n",
       "      <td>MA</td>\n",
       "      <td>2330.0</td>\n",
       "      <td>TWOMAC, INC.</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>400261381666</td>\n",
       "      <td>1067999</td>\n",
       "      <td>JAMES</td>\n",
       "      <td>HUTZLER</td>\n",
       "      <td>53 WATER WAY</td>\n",
       "      <td>BARRINGTON</td>\n",
       "      <td>RI</td>\n",
       "      <td>2806.0</td>\n",
       "      <td>YANKEE LEASING CORPORATION</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>500187481374</td>\n",
       "      <td>1068050</td>\n",
       "      <td>HERMAN</td>\n",
       "      <td>KROBATH</td>\n",
       "      <td>55 BENJAMIN DAY DR</td>\n",
       "      <td>WRENTHAM</td>\n",
       "      <td>MA</td>\n",
       "      <td>2093.0</td>\n",
       "      <td>NEW ENGLAND METALFORM INC</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>2023-05-24</td>\n",
       "      <td>Update PFS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>100277881823</td>\n",
       "      <td>1031226</td>\n",
       "      <td>PETER</td>\n",
       "      <td>BARTEL</td>\n",
       "      <td>260 BURT ST</td>\n",
       "      <td>TAUNTON</td>\n",
       "      <td>MA</td>\n",
       "      <td>2780.0</td>\n",
       "      <td>PETER D BARTEL D D S FAMILY &amp; DDS</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>Update PFS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>150358052</td>\n",
       "      <td>1057148</td>\n",
       "      <td>MICHAEL</td>\n",
       "      <td>GALLAGHER</td>\n",
       "      <td>277 OAK ST</td>\n",
       "      <td>RAYNHAM</td>\n",
       "      <td>MA</td>\n",
       "      <td>2767.0</td>\n",
       "      <td>ED GALLAGHER &amp; SON PLASTERING, INC.</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          acctnbr  persnbr firstname   lastname               text1  \\\n",
       "0       150894551  1154368    NATHAN        RAY       135 ANGELL RD   \n",
       "1       150498569  1032720    WALTER     ARAUJO       23 FAIRWAY DR   \n",
       "2       150498569  1039104    MARINA     ARAUJO       23 FAIRWAY DR   \n",
       "3       150304683      421     NANCY    DASILVA     2265 WHEELER ST   \n",
       "4       150304683  1027703     BRIAN    DASILVA     2265 WHEELER ST   \n",
       "..            ...      ...       ...        ...                 ...   \n",
       "293     151062743  1105528   STEPHEN     MURPHY          62 WEST ST   \n",
       "294  400261381666  1067999     JAMES    HUTZLER        53 WATER WAY   \n",
       "295  500187481374  1068050    HERMAN    KROBATH  55 BENJAMIN DAY DR   \n",
       "296  100277881823  1031226     PETER     BARTEL         260 BURT ST   \n",
       "297     150358052  1057148   MICHAEL  GALLAGHER          277 OAK ST   \n",
       "\n",
       "          cityname statecd   zipcd                            ownername  \\\n",
       "0       CUMBERLAND      RI  2864.0                   FAMILYSTORE.IO LLC   \n",
       "1         ACUSHNET      MA  2743.0              ARAUJO LANDSCAPING INC.   \n",
       "2         ACUSHNET      MA  2743.0              ARAUJO LANDSCAPING INC.   \n",
       "3    NORTH DIGHTON      MA  2764.0    2120 PLEASANT STREET REALTY TRUST   \n",
       "4    NORTH DIGHTON      MA  2764.0    2120 PLEASANT STREET REALTY TRUST   \n",
       "..             ...     ...     ...                                  ...   \n",
       "293         CARVER      MA  2330.0                         TWOMAC, INC.   \n",
       "294     BARRINGTON      RI  2806.0           YANKEE LEASING CORPORATION   \n",
       "295       WRENTHAM      MA  2093.0            NEW ENGLAND METALFORM INC   \n",
       "296        TAUNTON      MA  2780.0    PETER D BARTEL D D S FAMILY & DDS   \n",
       "297        RAYNHAM      MA  2767.0  ED GALLAGHER & SON PLASTERING, INC.   \n",
       "\n",
       "    Permission 7/8/24 Permission 1/9/25 Date of PFS       Notes  \n",
       "0                   Y                 Y  2023-04-07  Update PFS  \n",
       "1                   Y                 N         NaT         NaN  \n",
       "2                   Y                 N         NaT         NaN  \n",
       "3                   N                 Y  2025-01-06         NaN  \n",
       "4                   N                 Y  2025-01-06         NaN  \n",
       "..                ...               ...         ...         ...  \n",
       "293                 Y                 N         NaT         NaN  \n",
       "294                 Y                 Y  2024-04-12         NaN  \n",
       "295                 Y                 Y  2023-05-24  Update PFS  \n",
       "296                 N                 Y  2019-10-25  Update PFS  \n",
       "297                 Y                 N         NaT         NaN  \n",
       "\n",
       "[298 rows x 13 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 298 entries, 0 to 297\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   acctnbr            298 non-null    int64         \n",
      " 1   persnbr            298 non-null    int64         \n",
      " 2   firstname          298 non-null    object        \n",
      " 3   lastname           298 non-null    object        \n",
      " 4   text1              297 non-null    object        \n",
      " 5   cityname           297 non-null    object        \n",
      " 6   statecd            297 non-null    object        \n",
      " 7   zipcd              297 non-null    float64       \n",
      " 8   ownername          298 non-null    object        \n",
      " 9   Permission 7/8/24  279 non-null    object        \n",
      " 10  Permission 1/9/25  298 non-null    object        \n",
      " 11  Date of PFS        235 non-null    datetime64[ns]\n",
      " 12  Notes              137 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(9)\n",
      "memory usage: 30.4+ KB\n"
     ]
    }
   ],
   "source": [
    "colin_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "colin_slice = colin_df.loc[:,['persnbr','Permission 1/9/25']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acctnbr</th>\n",
       "      <th>persnbr</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>text1</th>\n",
       "      <th>cityname</th>\n",
       "      <th>statecd</th>\n",
       "      <th>zipcd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103705</td>\n",
       "      <td>1123487.0</td>\n",
       "      <td>LAWRENCE</td>\n",
       "      <td>PARENTEAU</td>\n",
       "      <td>2528 PUTNAM PIKE</td>\n",
       "      <td>CHEPACHET</td>\n",
       "      <td>RI</td>\n",
       "      <td>02814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100135</td>\n",
       "      <td>1120917.0</td>\n",
       "      <td>RONALD</td>\n",
       "      <td>HOULE</td>\n",
       "      <td>21 LARK INDUSTRIAL PKWY</td>\n",
       "      <td>GREENVILLE</td>\n",
       "      <td>RI</td>\n",
       "      <td>02828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102807</td>\n",
       "      <td>1067980.0</td>\n",
       "      <td>CARLOS</td>\n",
       "      <td>DASILVA</td>\n",
       "      <td>17 CLARK RD</td>\n",
       "      <td>SMITHFIELD</td>\n",
       "      <td>RI</td>\n",
       "      <td>02917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102625</td>\n",
       "      <td>1124298.0</td>\n",
       "      <td>STEPHEN</td>\n",
       "      <td>EGAN</td>\n",
       "      <td>800 WELLINGTON AVE</td>\n",
       "      <td>CRANSTON</td>\n",
       "      <td>RI</td>\n",
       "      <td>02910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102625</td>\n",
       "      <td>1124299.0</td>\n",
       "      <td>PAUL</td>\n",
       "      <td>SQUIZZERO</td>\n",
       "      <td>818 WELLINGTON AVE</td>\n",
       "      <td>CRANSTON</td>\n",
       "      <td>RI</td>\n",
       "      <td>02910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>151113455</td>\n",
       "      <td>1068009.0</td>\n",
       "      <td>JAMIE</td>\n",
       "      <td>STEBENNE</td>\n",
       "      <td>125 HUMMOCKS AVE</td>\n",
       "      <td>PORTSMOUTH</td>\n",
       "      <td>RI</td>\n",
       "      <td>02871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>151129577</td>\n",
       "      <td>1028181.0</td>\n",
       "      <td>DARRIN</td>\n",
       "      <td>DEGRAZIA</td>\n",
       "      <td>33 ROCKY GUTTER ST</td>\n",
       "      <td>MIDDLEBORO</td>\n",
       "      <td>MA</td>\n",
       "      <td>02346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>151129577</td>\n",
       "      <td>1029249.0</td>\n",
       "      <td>CHARLES</td>\n",
       "      <td>DEGRAZIA</td>\n",
       "      <td>1 CARMELLA DR</td>\n",
       "      <td>LAKEVILLE</td>\n",
       "      <td>MA</td>\n",
       "      <td>02347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>151135144</td>\n",
       "      <td>327.0</td>\n",
       "      <td>DONALD</td>\n",
       "      <td>SMYTH</td>\n",
       "      <td>724 OAKHILL AVE</td>\n",
       "      <td>ATTLEBORO</td>\n",
       "      <td>MA</td>\n",
       "      <td>02703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>151125301</td>\n",
       "      <td>1063515.0</td>\n",
       "      <td>ALLEN</td>\n",
       "      <td>BEAUPRE</td>\n",
       "      <td>1 SETH CHACE LANE</td>\n",
       "      <td>ASSONET</td>\n",
       "      <td>MA</td>\n",
       "      <td>02702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       acctnbr    persnbr firstname   lastname                    text1  \\\n",
       "0       103705  1123487.0  LAWRENCE  PARENTEAU         2528 PUTNAM PIKE   \n",
       "1       100135  1120917.0    RONALD      HOULE  21 LARK INDUSTRIAL PKWY   \n",
       "2       102807  1067980.0    CARLOS    DASILVA              17 CLARK RD   \n",
       "3       102625  1124298.0   STEPHEN       EGAN       800 WELLINGTON AVE   \n",
       "4       102625  1124299.0      PAUL  SQUIZZERO       818 WELLINGTON AVE   \n",
       "..         ...        ...       ...        ...                      ...   \n",
       "296  151113455  1068009.0     JAMIE   STEBENNE         125 HUMMOCKS AVE   \n",
       "297  151129577  1028181.0    DARRIN   DEGRAZIA       33 ROCKY GUTTER ST   \n",
       "298  151129577  1029249.0   CHARLES   DEGRAZIA            1 CARMELLA DR   \n",
       "299  151135144      327.0    DONALD      SMYTH          724 OAKHILL AVE   \n",
       "300  151125301  1063515.0     ALLEN    BEAUPRE        1 SETH CHACE LANE   \n",
       "\n",
       "       cityname statecd  zipcd  \n",
       "0     CHEPACHET      RI  02814  \n",
       "1    GREENVILLE      RI  02828  \n",
       "2    SMITHFIELD      RI  02917  \n",
       "3      CRANSTON      RI  02910  \n",
       "4      CRANSTON      RI  02910  \n",
       "..          ...     ...    ...  \n",
       "296  PORTSMOUTH      RI  02871  \n",
       "297  MIDDLEBORO      MA  02346  \n",
       "298   LAKEVILLE      MA  02347  \n",
       "299   ATTLEBORO      MA  02703  \n",
       "300     ASSONET      MA  02702  \n",
       "\n",
       "[301 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xactus_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>persnbr</th>\n",
       "      <th>Permission 1/9/25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1154368</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1032720</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1039104</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>421</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1027703</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>1105528</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>1067999</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1068050</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1031226</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1057148</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     persnbr Permission 1/9/25\n",
       "0    1154368                 Y\n",
       "1    1032720                 N\n",
       "2    1039104                 N\n",
       "3        421                 Y\n",
       "4    1027703                 Y\n",
       "..       ...               ...\n",
       "293  1105528                 N\n",
       "294  1067999                 Y\n",
       "295  1068050                 Y\n",
       "296  1031226                 Y\n",
       "297  1057148                 N\n",
       "\n",
       "[298 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colin_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xactus_extract = xactus_extract.drop_duplicates(subset='persnbr', keep='first')\n",
    "colin_slice = colin_slice.drop_duplicates(subset='persnbr', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert xactus_extract['persnbr'].is_unique, \"Duplicates found\"\n",
    "assert colin_slice['persnbr'].is_unique, \"Duplicates found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(xactus_extract, colin_slice, how='outer', on='persnbr', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_merge\n",
       "both          284\n",
       "left_only       3\n",
       "right_only      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acctnbr</th>\n",
       "      <th>persnbr</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>text1</th>\n",
       "      <th>cityname</th>\n",
       "      <th>statecd</th>\n",
       "      <th>zipcd</th>\n",
       "      <th>Permission 1/9/25</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>150731373.0</td>\n",
       "      <td>1028738.0</td>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>WARD</td>\n",
       "      <td>60 RIDGEWOOD RD</td>\n",
       "      <td>ATTLEBORO</td>\n",
       "      <td>MA</td>\n",
       "      <td>02703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>150327916.0</td>\n",
       "      <td>1064237.0</td>\n",
       "      <td>CHRISTIAN</td>\n",
       "      <td>FARLAND</td>\n",
       "      <td>21 VENTURA DR</td>\n",
       "      <td>NORTH DARTMOUTH</td>\n",
       "      <td>MA</td>\n",
       "      <td>02747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>151127018.0</td>\n",
       "      <td>1090309.0</td>\n",
       "      <td>NICHOLAS</td>\n",
       "      <td>ARAUJO</td>\n",
       "      <td>67 OLD SCHOOLHOUSE ROAD</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>MA</td>\n",
       "      <td>02770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         acctnbr    persnbr  firstname lastname                    text1  \\\n",
       "24   150731373.0  1028738.0    WILLIAM     WARD          60 RIDGEWOOD RD   \n",
       "133  150327916.0  1064237.0  CHRISTIAN  FARLAND            21 VENTURA DR   \n",
       "197  151127018.0  1090309.0   NICHOLAS   ARAUJO  67 OLD SCHOOLHOUSE ROAD   \n",
       "\n",
       "            cityname statecd  zipcd Permission 1/9/25     _merge  \n",
       "24         ATTLEBORO      MA  02703               NaN  left_only  \n",
       "133  NORTH DARTMOUTH      MA  02747               NaN  left_only  \n",
       "197        ROCHESTER      MA  02770               NaN  left_only  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[merged_df['_merge'] == 'left_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Alerts\\Production\\Xactus\\xactus_extract.xlsx'\n",
    "xactus_extract.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85050 entries, 0 to 85049\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   acctnbr          85050 non-null  int64         \n",
      " 1   effdate          85050 non-null  datetime64[ns]\n",
      " 2   mjaccttypcd      85050 non-null  object        \n",
      " 3   product          85050 non-null  object        \n",
      " 4   currmiaccttypcd  85050 non-null  object        \n",
      " 5   bookbalance      85050 non-null  object        \n",
      " 6   loanofficer      24358 non-null  object        \n",
      " 7   ownername        85050 non-null  object        \n",
      " 8   curracctstatcd   85050 non-null  object        \n",
      " 9   contractdate     85049 non-null  datetime64[ns]\n",
      " 10  notebal          85050 non-null  object        \n",
      "dtypes: datetime64[ns](2), int64(1), object(8)\n",
      "memory usage: 7.1+ MB\n"
     ]
    }
   ],
   "source": [
    "acctcommon.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ownername_df = acctcommon[['acctnbr','ownername','loanofficer']].copy()\n",
    "merged_xactus_extract = pd.merge(merged_df, ownername_df, how='left', on='acctnbr')\n",
    "# file_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Alerts\\Production\\Xactus\\xactus_extract.xlsx'\n",
    "# merged_xactus_extract.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acctnbr</th>\n",
       "      <th>persnbr</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>text1</th>\n",
       "      <th>cityname</th>\n",
       "      <th>statecd</th>\n",
       "      <th>zipcd</th>\n",
       "      <th>Permission 1/9/25</th>\n",
       "      <th>_merge</th>\n",
       "      <th>ownername</th>\n",
       "      <th>loanofficer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>150731373.0</td>\n",
       "      <td>1028738.0</td>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>WARD</td>\n",
       "      <td>60 RIDGEWOOD RD</td>\n",
       "      <td>ATTLEBORO</td>\n",
       "      <td>MA</td>\n",
       "      <td>02703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>W B CONSTRUCTION &amp; DEVELOPMENT INC</td>\n",
       "      <td>THOMAS D. KELLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>150327916.0</td>\n",
       "      <td>1064237.0</td>\n",
       "      <td>CHRISTIAN</td>\n",
       "      <td>FARLAND</td>\n",
       "      <td>21 VENTURA DR</td>\n",
       "      <td>NORTH DARTMOUTH</td>\n",
       "      <td>MA</td>\n",
       "      <td>02747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>FARLAND CORPORATION INC</td>\n",
       "      <td>JEFFREY P. PAGLIUCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>151127018.0</td>\n",
       "      <td>1090309.0</td>\n",
       "      <td>NICHOLAS</td>\n",
       "      <td>ARAUJO</td>\n",
       "      <td>67 OLD SCHOOLHOUSE ROAD</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>MA</td>\n",
       "      <td>02770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>STALLION PLUMBING, HEATING &amp; COOLING, INC</td>\n",
       "      <td>ANDREW RODRIGUES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         acctnbr    persnbr  firstname lastname                    text1  \\\n",
       "24   150731373.0  1028738.0    WILLIAM     WARD          60 RIDGEWOOD RD   \n",
       "133  150327916.0  1064237.0  CHRISTIAN  FARLAND            21 VENTURA DR   \n",
       "197  151127018.0  1090309.0   NICHOLAS   ARAUJO  67 OLD SCHOOLHOUSE ROAD   \n",
       "\n",
       "            cityname statecd  zipcd Permission 1/9/25     _merge  \\\n",
       "24         ATTLEBORO      MA  02703               NaN  left_only   \n",
       "133  NORTH DARTMOUTH      MA  02747               NaN  left_only   \n",
       "197        ROCHESTER      MA  02770               NaN  left_only   \n",
       "\n",
       "                                     ownername          loanofficer  \n",
       "24          W B CONSTRUCTION & DEVELOPMENT INC      THOMAS D. KELLY  \n",
       "133                    FARLAND CORPORATION INC  JEFFREY P. PAGLIUCA  \n",
       "197  STALLION PLUMBING, HEATING & COOLING, INC     ANDREW RODRIGUES  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_xactus_extract[merged_xactus_extract['_merge'] == 'left_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_xactus_extract['Permission 1/9/25'] = np.where(merged_xactus_extract['persnbr'] == 1028738.0, 'Y', merged_xactus_extract['Permission 1/9/25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acctnbr</th>\n",
       "      <th>persnbr</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>text1</th>\n",
       "      <th>cityname</th>\n",
       "      <th>statecd</th>\n",
       "      <th>zipcd</th>\n",
       "      <th>Permission 1/9/25</th>\n",
       "      <th>_merge</th>\n",
       "      <th>ownername</th>\n",
       "      <th>loanofficer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>150731373.0</td>\n",
       "      <td>1028738.0</td>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>WARD</td>\n",
       "      <td>60 RIDGEWOOD RD</td>\n",
       "      <td>ATTLEBORO</td>\n",
       "      <td>MA</td>\n",
       "      <td>02703</td>\n",
       "      <td>Y</td>\n",
       "      <td>left_only</td>\n",
       "      <td>W B CONSTRUCTION &amp; DEVELOPMENT INC</td>\n",
       "      <td>THOMAS D. KELLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>150327916.0</td>\n",
       "      <td>1064237.0</td>\n",
       "      <td>CHRISTIAN</td>\n",
       "      <td>FARLAND</td>\n",
       "      <td>21 VENTURA DR</td>\n",
       "      <td>NORTH DARTMOUTH</td>\n",
       "      <td>MA</td>\n",
       "      <td>02747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>FARLAND CORPORATION INC</td>\n",
       "      <td>JEFFREY P. PAGLIUCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>151127018.0</td>\n",
       "      <td>1090309.0</td>\n",
       "      <td>NICHOLAS</td>\n",
       "      <td>ARAUJO</td>\n",
       "      <td>67 OLD SCHOOLHOUSE ROAD</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>MA</td>\n",
       "      <td>02770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "      <td>STALLION PLUMBING, HEATING &amp; COOLING, INC</td>\n",
       "      <td>ANDREW RODRIGUES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         acctnbr    persnbr  firstname lastname                    text1  \\\n",
       "24   150731373.0  1028738.0    WILLIAM     WARD          60 RIDGEWOOD RD   \n",
       "133  150327916.0  1064237.0  CHRISTIAN  FARLAND            21 VENTURA DR   \n",
       "197  151127018.0  1090309.0   NICHOLAS   ARAUJO  67 OLD SCHOOLHOUSE ROAD   \n",
       "\n",
       "            cityname statecd  zipcd Permission 1/9/25     _merge  \\\n",
       "24         ATTLEBORO      MA  02703                 Y  left_only   \n",
       "133  NORTH DARTMOUTH      MA  02747               NaN  left_only   \n",
       "197        ROCHESTER      MA  02770               NaN  left_only   \n",
       "\n",
       "                                     ownername          loanofficer  \n",
       "24          W B CONSTRUCTION & DEVELOPMENT INC      THOMAS D. KELLY  \n",
       "133                    FARLAND CORPORATION INC  JEFFREY P. PAGLIUCA  \n",
       "197  STALLION PLUMBING, HEATING & COOLING, INC     ANDREW RODRIGUES  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_xactus_extract[merged_xactus_extract['_merge'] == 'left_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_xactus_extract['Permission 1/9/25'] = np.where(merged_xactus_extract['persnbr'] == 1064237.0, 'Y', merged_xactus_extract['Permission 1/9/25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_xactus_extract['Permission 1/9/25'] = np.where(merged_xactus_extract['persnbr'] == 1090309.0, 'Y', merged_xactus_extract['Permission 1/9/25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acctnbr</th>\n",
       "      <th>persnbr</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>text1</th>\n",
       "      <th>cityname</th>\n",
       "      <th>statecd</th>\n",
       "      <th>zipcd</th>\n",
       "      <th>Permission 1/9/25</th>\n",
       "      <th>_merge</th>\n",
       "      <th>ownername</th>\n",
       "      <th>loanofficer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1136688.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>right_only</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     acctnbr    persnbr firstname lastname text1 cityname statecd zipcd  \\\n",
       "251      NaN  1136688.0       NaN      NaN   NaN      NaN     NaN   NaN   \n",
       "\n",
       "    Permission 1/9/25      _merge ownername loanofficer  \n",
       "251                 Y  right_only       NaN         NaN  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_xactus_extract[merged_xactus_extract['_merge'] == 'right_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_xactus_extract =merged_xactus_extract[~(merged_xactus_extract['_merge'] == 'right_only')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['THOMAS D. KELLY', 'SBLC LOAN OFFICER', 'KEVIN M. MCCARTHY',\n",
       "       'EBL PROGRAM ADMIN', 'MARK A. BORKMAN', 'ALISSA E. HALL',\n",
       "       'ANDREW J. OMER', 'WILLITTS S. MENDONCA', 'AN T. LE',\n",
       "       'JOSHUA A. CAMARA', 'JEFFREY M. VIALL', 'ROGER A. CABRAL',\n",
       "       'BRANDON CANNATA', 'JOAN M. MEDEIROS', 'DAMON T. ARPIN',\n",
       "       'JEFFREY P. PAGLIUCA', 'ANDREW RODRIGUES'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_xactus_extract['loanofficer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_extract = merged_xactus_extract[(merged_xactus_extract['Permission 1/9/25'] == 'Y') | (merged_xactus_extract['loanofficer'] == 'EBL PROGRAM ADMIN')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 276 entries, 0 to 287\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   acctnbr            276 non-null    float64 \n",
      " 1   persnbr            276 non-null    float64 \n",
      " 2   firstname          276 non-null    object  \n",
      " 3   lastname           276 non-null    object  \n",
      " 4   text1              275 non-null    object  \n",
      " 5   cityname           275 non-null    object  \n",
      " 6   statecd            275 non-null    object  \n",
      " 7   zipcd              275 non-null    object  \n",
      " 8   Permission 1/9/25  276 non-null    object  \n",
      " 9   _merge             276 non-null    category\n",
      " 10  ownername          276 non-null    object  \n",
      " 11  loanofficer        276 non-null    object  \n",
      "dtypes: category(1), float64(2), object(9)\n",
      "memory usage: 26.3+ KB\n"
     ]
    }
   ],
   "source": [
    "cleaned_extract.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers_permission_df = cleaned_extract.loc[:, ['persnbr','firstname','lastname']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers_permission_df['Permission'] = 'Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'Z:\\Chad Projects\\Alerts\\Production\\Xactus\\Permission_db\\pfs_permission.csv'\n",
    "pers_permission_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_extract['Reference Number'] = None\n",
    "cleaned_extract['SSN'] = None\n",
    "cleaned_extract['Address Number'] = None\n",
    "cleaned_extract['Pre-Directional'] = None\n",
    "cleaned_extract['Post-Directional'] = None\n",
    "cleaned_extract['Street Type'] = None\n",
    "cleaned_extract['Maternal Name'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 276 entries, 0 to 287\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   acctnbr            276 non-null    float64 \n",
      " 1   persnbr            276 non-null    float64 \n",
      " 2   firstname          276 non-null    object  \n",
      " 3   lastname           276 non-null    object  \n",
      " 4   text1              275 non-null    object  \n",
      " 5   cityname           275 non-null    object  \n",
      " 6   statecd            275 non-null    object  \n",
      " 7   zipcd              275 non-null    object  \n",
      " 8   Permission 1/9/25  276 non-null    object  \n",
      " 9   _merge             276 non-null    category\n",
      " 10  ownername          276 non-null    object  \n",
      " 11  loanofficer        276 non-null    object  \n",
      " 12  Reference Number   0 non-null      object  \n",
      " 13  SSN                0 non-null      object  \n",
      " 14  Address Number     0 non-null      object  \n",
      " 15  Pre-Directional    0 non-null      object  \n",
      " 16  Post-Directional   0 non-null      object  \n",
      " 17  Street Type        0 non-null      object  \n",
      " 18  Maternal Name      0 non-null      object  \n",
      "dtypes: category(1), float64(2), object(16)\n",
      "memory usage: 41.4+ KB\n"
     ]
    }
   ],
   "source": [
    "cleaned_extract.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_extract = cleaned_extract.loc[:, ['firstname','lastname','Reference Number','SSN','Address Number','Pre-Directional','text1','Post-Directional','Street Type','cityname','statecd','zipcd','Maternal Name']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>Reference Number</th>\n",
       "      <th>SSN</th>\n",
       "      <th>Address Number</th>\n",
       "      <th>Pre-Directional</th>\n",
       "      <th>text1</th>\n",
       "      <th>Post-Directional</th>\n",
       "      <th>Street Type</th>\n",
       "      <th>cityname</th>\n",
       "      <th>statecd</th>\n",
       "      <th>zipcd</th>\n",
       "      <th>Maternal Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DONALD</td>\n",
       "      <td>SMYTH</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>724 OAKHILL AVE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ATTLEBORO</td>\n",
       "      <td>MA</td>\n",
       "      <td>02703</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NANCY</td>\n",
       "      <td>DASILVA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2265 WHEELER ST</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NORTH DIGHTON</td>\n",
       "      <td>MA</td>\n",
       "      <td>02764</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MICHAEL</td>\n",
       "      <td>BRIGGS</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>660 PAINE RD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NORTH ATTLEBORO</td>\n",
       "      <td>MA</td>\n",
       "      <td>02760</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAMELA</td>\n",
       "      <td>DUMAS</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>26 MILL ST</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>BERKLEY</td>\n",
       "      <td>MA</td>\n",
       "      <td>02779</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TIMOTHY</td>\n",
       "      <td>DUBUC</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>102 MORGAN DR</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>TAUNTON</td>\n",
       "      <td>MA</td>\n",
       "      <td>02780</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>CARLOS</td>\n",
       "      <td>COSTA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>6 TORRINGTON RD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>FAIRHAVEN</td>\n",
       "      <td>MA</td>\n",
       "      <td>02719</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>JOSHUA</td>\n",
       "      <td>ABREU</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>18 ISTHMUS RD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>FOSTER</td>\n",
       "      <td>RI</td>\n",
       "      <td>02825</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>JULIE</td>\n",
       "      <td>EISENHAUER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>36 RIDGE RD</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>FOXBOROUGH</td>\n",
       "      <td>MA</td>\n",
       "      <td>02035</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>OWEN</td>\n",
       "      <td>DOYLE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>91 W LAWN AVE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>PAWTUCKET</td>\n",
       "      <td>RI</td>\n",
       "      <td>02860</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>TRAVIS</td>\n",
       "      <td>GERVASIO</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9 KILEY WAY</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>COVENTRY</td>\n",
       "      <td>RI</td>\n",
       "      <td>02816</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    firstname    lastname Reference Number   SSN Address Number  \\\n",
       "0      DONALD       SMYTH             None  None           None   \n",
       "1       NANCY     DASILVA             None  None           None   \n",
       "2     MICHAEL      BRIGGS             None  None           None   \n",
       "3      PAMELA       DUMAS             None  None           None   \n",
       "4     TIMOTHY       DUBUC             None  None           None   \n",
       "..        ...         ...              ...   ...            ...   \n",
       "283    CARLOS       COSTA             None  None           None   \n",
       "284    JOSHUA       ABREU             None  None           None   \n",
       "285     JULIE  EISENHAUER             None  None           None   \n",
       "286      OWEN       DOYLE             None  None           None   \n",
       "287    TRAVIS    GERVASIO             None  None           None   \n",
       "\n",
       "    Pre-Directional            text1 Post-Directional Street Type  \\\n",
       "0              None  724 OAKHILL AVE             None        None   \n",
       "1              None  2265 WHEELER ST             None        None   \n",
       "2              None     660 PAINE RD             None        None   \n",
       "3              None       26 MILL ST             None        None   \n",
       "4              None    102 MORGAN DR             None        None   \n",
       "..              ...              ...              ...         ...   \n",
       "283            None  6 TORRINGTON RD             None        None   \n",
       "284            None    18 ISTHMUS RD             None        None   \n",
       "285            None      36 RIDGE RD             None        None   \n",
       "286            None    91 W LAWN AVE             None        None   \n",
       "287            None      9 KILEY WAY             None        None   \n",
       "\n",
       "            cityname statecd  zipcd Maternal Name  \n",
       "0          ATTLEBORO      MA  02703          None  \n",
       "1      NORTH DIGHTON      MA  02764          None  \n",
       "2    NORTH ATTLEBORO      MA  02760          None  \n",
       "3            BERKLEY      MA  02779          None  \n",
       "4            TAUNTON      MA  02780          None  \n",
       "..               ...     ...    ...           ...  \n",
       "283        FAIRHAVEN      MA  02719          None  \n",
       "284           FOSTER      RI  02825          None  \n",
       "285       FOXBOROUGH      MA  02035          None  \n",
       "286        PAWTUCKET      RI  02860          None  \n",
       "287         COVENTRY      RI  02816          None  \n",
       "\n",
       "[276 rows x 13 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_extract_with_persnbr = cleaned_extract.loc[:, ['firstname','lastname','Reference Number','SSN','Address Number','Pre-Directional','text1','Post-Directional','Street Type','cityname','statecd','zipcd','Maternal Name','persnbr']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'Z:\\Chad Projects\\Alerts\\Production\\Xactus\\Extract_Xactus\\final_extract_with_persnbr.csv'\n",
    "final_extract_with_persnbr.to_csv(file_path, index=False)\n",
    "\n",
    "file_path = r'Z:\\Chad Projects\\Alerts\\Production\\Xactus\\Extract_Xactus\\final_extract.csv'\n",
    "final_extract.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete, for now. Will streamline this process for future use. Still a bit manual."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
