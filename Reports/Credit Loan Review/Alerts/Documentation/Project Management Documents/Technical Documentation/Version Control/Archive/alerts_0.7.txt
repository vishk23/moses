#################################
# List all non-standard packages to be imported by your 
# script here (only missing packages will be installed)
from ayx import Package
#Package.installPackages(['pandas','numpy'])


#################################
""" 
Title: Commercial Portfolio Alerts System
Developed by: Chad Doorley

The Commercial Portfolio Alerts System monitors early warning patterns
on a subset of the portfolio.

"""

from ayx import Alteryx
import pandas as pd
import numpy as np
import os
import json
from sqlalchemy import create_engine

class DatabaseHandler:
    """
    This class abstracts the connection to the database and allows a clean
    interface for the developer to use.
    
    """
    def __init__(self, tns_admin_path, credentials_path_db1, credentials_path_db2):
        """
        Args:
            tns_admin_path (str): Oracle driver path
            credentials_path_db1 (str): Database 1 credentials path
            credentials_path_db1 (str): Databsae 2 credentials path
        """
        os.environ['TNS_ADMIN'] = tns_admin_path
        
        with open(credentials_path_db1) as config_file:
            config1 = json.load(config_file)
            
        self.username1 = config1['username']
        self.password1 = config1['password']
        self.dsn1 = config1['dsn']
        
        with open(credentials_path_db2) as config_file:
            config2 = json.load(config_file)
            
        self.username2 = config2['username']
        self.password2 = config2['password']
        self.dsn2 = config2['dsn']
        
        self.connection_string1 = f'oracle+cx_oracle://{self.username1}:{self.password1}@{self.dsn1}'
        self.connection_string2 = f'oracle+cx_oracle://{self.username2}:{self.password2}@{self.dsn2}'
        
        self.engine1 = create_engine(self.connection_string1, max_identifier_length=128)
        self.engine2 = create_engine(self.connection_string2, max_identifier_length=128)
        
    def query(self, sql_query, engine=1):
        """
        This allows abstraction of the connection and the class
        so the developer can query a single table as a dataframe
        
        Args:
            sql_query (str): The query to SQL database is passed as a string
            engine (int): This selects the database. There are two engines:
                1 -> R1625
                2 -> COCC DataMart
                
        Returns:
            df: The SQL query is returned as a pandas DataFrame
            
        Usage:
            df = db_handler.query("SELECT * FROM DB.TABLE", engine=1)
            
            In this example, db_handler = DatabaseHandler(args)
        """
        if engine == 1:
            selected_engine = self.engine1
        elif engine == 2:
            selected_engine = self.engine2
        else:
            raise ValueError("Engine must be 1 or 2")
            
        with selected_engine.connect() as connection:
            df = pd.read_sql(sql_query, connection)
        return df

# Database Connection Configuration
tns_admin_path = r'C:\Oracle2\instantclient_21_13\network\admin'
credentials_path_db1 = r'\\10.161.85.66\Home\Share\Alteryx_Admin\Configuration\Connection\db_config_main.json'
credentials_path_db2 = r'\\10.161.85.66\Home\Share\Alteryx_Admin\Configuration\Connection\db_config_datamart.json'
db_handler = DatabaseHandler(tns_admin_path, credentials_path_db1, credentials_path_db2)


#################################
help(DatabaseHandler)


#################################
# This section handles all SQL overhead at the beginning
# and caches the data for processing

import time

start_time = time.time()

with db_handler.engine1.connect() as connection:
    acctcommon = pd.read_sql("SELECT * FROM OSIBANK.WH_ACCTCOMMON", connection)
    acctloan = pd.read_sql("SELECT * FROM OSIBANK.WH_ACCTLOAN", connection)
    loans = pd.read_sql("SELECT * FROM OSIBANK.WH_LOANS", connection)
    househldacct = pd.read_sql("SELECT * FROM OSIEXTN.HOUSEHLDACCT", connection)
    allroles = pd.read_sql("SELECT * FROM OSIBANK.WH_ALLROLES", connection)
    persaddruse = pd.read_sql("SELECT * FROM OSIBANK.PERSADDRUSE", connection)
    wh_addr = pd.read_sql("SELECT * FROM OSIBANK.WH_ADDR", connection)
    pers = pd.read_sql("SELECT * FROM OSIBANK.PERS", connection)
    acctstatistichist = pd.read_sql("SELECT * FROM OSIBANK.ACCTSTATISTICHIST", connection)
    # For development only
    lookup_df = pd.read_sql("SELECT * FROM sys.all_tab_columns col", connection)
    
print(f"Query took {time.time() - start_time} seconds.")


#################################
# Core ETL

def filter_and_merge_loan_tables(acctcommon, acctloan, loans):
    """
    
    """
    
    # Active/NPFM products
    df = acctcommon[acctcommon['curracctstatcd'].isin(['ACT','NPFM'])]

    # CML loans
    df = df[df['mjaccttypcd'].isin(['CML'])]

    # Merging and dropping blank fields
    df = pd.merge(df, acctloan, on='acctnbr', how='left', suffixes=('_df', '_acctloan'))
    df = pd.merge(df, loans, on='acctnbr', how='left', suffixes=('_df', '_loans'))
    df = df.dropna(axis=1, how='all')
    
    return df

loan_data = filter_and_merge_loan_tables(acctcommon, acctloan, loans)

def cleanse_loan_data(df):
    # Data Cleansing
    df['totalpctsold'] = df['totalpctsold'].fillna(0)
    df['availbalamt'] = df['availbalamt'].fillna(0)
    df['credlimitclatresamt'] = df['credlimitclatresamt'].fillna(0)
    return df

loan_data = cleanse_loan_data(loan_data)

def append_total_exposure_field(df):
    """ Single Obligor Exposure Calculation
    
    I'll figure out docstring later
    
    """
    # Tax Exempt bonds always have $0 Book Balance so need to take NOTEBAL
    df['bookbalance'] = np.where(df['currmiaccttypcd'].isin(['CM45']), df['notebal'], df['bookbalance'])
    df['Net Balance'] = df['bookbalance'] - df['cobal']
    df['Net Available'] = df['availbalamt'] * (1 - df['totalpctsold'])
    df['Net Collateral Reserve'] = df['credlimitclatresamt'] * (1 - df['totalpctsold'])
    df['Total Exposure'] = df['Net Balance'] + df['Net Available'] + df['Net Collateral Reserve']
    return df

loan_data = append_total_exposure_field(loan_data)

def append_household_number(df, househldacct):
    df = pd.merge(df, househldacct, on='acctnbr', how='left', suffixes=('_df', '_househldacct'))
    return df

loan_data = append_household_number(loan_data, househldacct)

def household_total_exposure(df):
    household_grouping_df = df.groupby('householdnbr')['Total Exposure'].sum().reset_index()
    household_grouping_df = pd.DataFrame(household_grouping_df)
    return household_grouping_df

household_grouping_df = household_total_exposure(loan_data)

def append_household_exposure(df, household_grouping_df):
    df = pd.merge(df, household_grouping_df, on='householdnbr', how='left', suffixes=('_df','_hhgroup'))
    return df

loan_data = append_household_exposure(loan_data, household_grouping_df)

def filter_to_target_products(df):
    # Lines of Credit
    df = df[df['currmiaccttypcd'].isin(["CM06","CM11","CM30","CM52","CM57","CM62","CM71","CM76"])]
    # Credit Limit Amount <= $500M & Household Exposure <= $1MM
    df = df[(df['creditlimitamt'] <= 500000) & (df['Total Exposure_hhgroup'] <= 1000000)]
    return df

loan_data = filter_to_target_products(loan_data)


#################################
# Personal Guarantors extracted
def personal_guarantors(allroles, persaddruse, wh_addr, pers):
    allroles = allroles[allroles['acctrolecd'] == 'GUAR']
    allroles = allroles[allroles['persnbr'].notnull()]
    persaddruse = persaddruse[persaddruse['addrusecd'] == "PRI"]
    # Merge
    df = pd.merge(allroles, persaddruse, on='persnbr',how='left', suffixes=('_allroles','_persaddruse'))
    df = pd.merge(df, wh_addr, on='addrnbr',how='left', suffixes=('_df','_addr'))
    df = pd.merge(df, pers, on='persnbr', how='left', suffixes=('_df','_pers'))
    df = df[['acctnbr','persnbr','firstname','lastname','text1','cityname','statecd','zipcd']]
    return df

pg_section = personal_guarantors(allroles, persaddruse, wh_addr, pers)


#################################
def merge_guar_with_loan_data(df, pg_section):
    df = pd.merge(df, pg_section, on='acctnbr', how='inner', suffixes=('_df','_pg'))
    return df

target_loans_with_guar = merge_guar_with_loan_data(loan_data, pg_section)


#################################
len(target_loans_with_guar)


#################################
# target_loans_with_guar.info(verbose=True)


#################################
# xactus_extract = target_loans_with_guar[['acctnbr','persnbr_pg','firstname','lastname','text1','cityname','statecd','zipcd']]
# file_path = r'Y:\GlobalWave\CLO Intern Deliverables\070824PFS_Check_v2.xlsx'
# colin_list = pd.read_excel(file_path, engine='openpyxl')
# colin_list = colin_list.astype({"Person Number": float})
# merged_df = pd.merge(xactus_extract, colin_list, how='left', left_on='persnbr_pg', right_on='Person Number', suffixes=('_xactus','_colin'), indicator=True)


#################################
# merged_df.groupby('_merge')['persnbr_pg'].count()


#################################
# # Output Guarantor Data
# file_name = r'\\10.161.85.66\Home\Share\Line of Business_Shared Services\Commercial Credit\CML_Executive_Leadership_Projects\Alerts\Xactus\Data\guarantor_data.xlsx'
# merged_df.to_excel(file_name, index=False)


#################################
### Pending external action on the Xactus SFTP setup & information regarding permission to run soft pull credit scores
### Will continue developing the other tests


#################################
# target_loans_with_guar.info(verbose=True, null_counts=True)


#################################
# # Initializing Database for Xactus
# file_path = r'\\10.161.85.66\Home\Share\Line of Business_Shared Services\Commercial Credit\CML_Executive_Leadership_Projects\Alerts\Xactus\Database\temporary.db'
# engine = create_engine(f'sqlite:///{file_path}')

# with engine.connect() as connection:
#     connection.execute("""
#     CREATE TABLE IF NOT EXISTS guarantors (
#         acctnbr INTEGER,
#         persnbr INTEGER,
#         firstname TEXT,
#         lastname TEXT,
#         creditscore INTEGER,
#         effdate DATETIME
#     );
#     """)
    
# with engine.connect() as connection:
#     data = pd.read_sql("SELECT * FROM guarantors", connection)


#################################
def acctstatistichist_cleaning(df):
    """ Adds a new field to turn monthcd & yearnbr into a full date
    
    Args:
        df: The COCC ACCTSTATISTICHIST table is the only parameter
    
    Returns:
        df
    """
    df['monthcd'] = df['monthcd'].str.zfill(2)
    df['monthcd'] = df['monthcd'].astype(str)
    df['yearnbr'] = df['yearnbr'].astype(str)
    df['month_date'] = df['yearnbr'] + "-" + df['monthcd'] + "-01"
    return df

acctstatistic_output = acctstatistichist_cleaning(acctstatistichist)


#################################



#################################



#################################
