{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Weekly Loan Report\n",
    "# Developed by CD\n",
    "# v2.0.2-prod\n",
    "\n",
    "# %%\n",
    "import os\n",
    "from io import StringIO\n",
    "from datetime import datetime, timedelta, date\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import time\n",
    "from cryptography.fernet import Fernet\n",
    "from dotenv import load_dotenv\n",
    "import win32com.client as win32\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# %%\n",
    "def retrieve_data():\n",
    "    \"\"\"\n",
    "    Retrieve data from COCC database\n",
    "    \"\"\"\n",
    "    class DatabaseHandler:\n",
    "        \"\"\"\n",
    "        This class abstracts the connection to the database and allows a clean\n",
    "        interface for the developer to use.\n",
    "\n",
    "        \"\"\"\n",
    "        def __init__(self, tns_admin_path):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                tns_admin_path (str): Oracle driver path\n",
    "                credentials_path_db1 (str): Database 1 credentials path\n",
    "                credentials_path_db1 (str): Databsae 2 credentials path\n",
    "            \"\"\"\n",
    "            os.environ['TNS_ADMIN'] = tns_admin_path\n",
    "            \n",
    "            # Load private key\n",
    "            key_key_path = r'C:\\Users\\w322800\\Documents\\coding3\\env_admin\\key.key'\n",
    "            with open(key_key_path, \"rb\") as key_file:\n",
    "                key = key_file.read()\n",
    "\n",
    "            cipher = Fernet(key)\n",
    "            \n",
    "            # Load encrypted data\n",
    "            encoded_env_path = r'C:\\Users\\w322800\\Documents\\coding3\\env_admin\\.env.enc'\n",
    "            with open(encoded_env_path, \"rb\") as encrypted_file:\n",
    "                encrypted_data = encrypted_file.read()\n",
    "\n",
    "            decrypted_data = cipher.decrypt(encrypted_data).decode()\n",
    "\n",
    "            env_file = StringIO(decrypted_data)\n",
    "            load_dotenv(stream=env_file)\n",
    "\n",
    "            self.username1 = os.getenv('main_username')\n",
    "            self.password1 = os.getenv('main_password')\n",
    "            self.dsn1 = os.getenv('main_dsn')\n",
    "\n",
    "            self.username2 = os.getenv('datamart_username')\n",
    "            self.password2 = os.getenv('datamart_password')\n",
    "            self.dsn2 = os.getenv('datamart_dsn')\n",
    "\n",
    "            self.connection_string1 = f'oracle+oracledb://{self.username1}:{self.password1}@{self.dsn1}'\n",
    "            self.connection_string2 = f'oracle+oracledb://{self.username2}:{self.password2}@{self.dsn2}'\n",
    "\n",
    "            self.engine1 = create_engine(self.connection_string1, max_identifier_length=128, echo=False, future=True)\n",
    "            self.engine1.dialect.hide_parameters = True\n",
    "            self.engine2 = create_engine(self.connection_string2, max_identifier_length=128, echo=False, future=True)\n",
    "            self.engine1.dialect.hide_parameters = True\n",
    "\n",
    "        def query(self, sql_query, engine=1):\n",
    "            \"\"\"\n",
    "            This allows abstraction of the connection and the class\n",
    "            so the developer can query a single table as a dataframe\n",
    "\n",
    "            Args:\n",
    "                sql_query (str): The query to SQL database is passed as a string\n",
    "                engine (int): This selects the database. There are two engines:\n",
    "                    1 -> R1625\n",
    "                    2 -> COCC DataMart\n",
    "\n",
    "            Returns:\n",
    "                df: The SQL query is returned as a pandas DataFrame\n",
    "\n",
    "            Usage:\n",
    "                df = db_handler.query(\"SELECT * FROM DB.TABLE\", engine=1)\n",
    "\n",
    "                In this example, db_handler = DatabaseHandler(args)\n",
    "            \"\"\"\n",
    "            if engine == 1:\n",
    "                selected_engine = self.engine1\n",
    "            elif engine == 2:\n",
    "                selected_engine = self.engine2\n",
    "            else:\n",
    "                raise ValueError(\"Engine must be 1 or 2\")\n",
    "\n",
    "            with selected_engine.connect() as connection:\n",
    "                df = pd.read_sql(sql_query, connection)\n",
    "            return df\n",
    "\n",
    "    # Database Connection Configuration\n",
    "    tns_admin_path = r'C:\\Users\\w322800\\Documents\\coding3\\env_admin\\tns_admin'\n",
    "    db_handler = DatabaseHandler(tns_admin_path)\n",
    "\n",
    "    #Last business day\n",
    "    with db_handler.engine2.connect() as connection:\n",
    "#         For development only\n",
    "        wh_acctcommon = text(\"\"\"\n",
    "        SELECT \n",
    "            a.ACCTNBR,\n",
    "            a.LOANOFFICER,\n",
    "            a.OWNERSORTNAME,\n",
    "            a.PRODUCT,\n",
    "            a.CURRACCTSTATCD,\n",
    "            a.NOTEBAL,\n",
    "            a.BOOKBALANCE,\n",
    "            a.NOTEINTRATE,\n",
    "            a.DATEMAT,\n",
    "            a.TAXRPTFORORGNBR,\n",
    "            a.TAXRPTFORPERSNBR,\n",
    "            a.CONTRACTDATE,\n",
    "            a.MJACCTTYPCD,\n",
    "            a.CURRMIACCTTYPCD\n",
    "        FROM \n",
    "            COCCDM.WH_ACCTCOMMON_TEMP a\n",
    "        \"\"\")\n",
    "        start_time = time.time()\n",
    "        wh_acctcommon = pd.read_sql(wh_acctcommon, connection)\n",
    "        print(f\"acctcommon took {time.time() - start_time} seconds.\")\n",
    "\n",
    "        # COCCDM -> WH_LOANS_TEMP\n",
    "        wh_loans = text(\"\"\"\n",
    "        SELECT\n",
    "            a.ACCTNBR,\n",
    "            a.ORIGDATE,\n",
    "            a.ORIGBAL,\n",
    "            a.FDICCATDESC,\n",
    "            a.RUNDATE,\n",
    "            a.AVAILBALAMT\n",
    "        FROM\n",
    "            COCCDM.WH_LOANS_TEMP a\n",
    "        \"\"\")\n",
    "        start_time = time.time()\n",
    "        wh_loans = pd.read_sql(wh_loans, connection)\n",
    "        print(f\"wh_loans took {time.time() - start_time} seconds.\")\n",
    "\n",
    "        # COCCDM -> WH_ACCTLOAN_TEMP\n",
    "        wh_acctloan = text(\"\"\"\n",
    "        SELECT\n",
    "            a.ACCTNBR,\n",
    "            a.MININTRATE,\n",
    "            a.FDICCATCD,\n",
    "            a.PROPNBR,\n",
    "            a.TOTALPCTSOLD,\n",
    "            a.RISKRATINGCD,\n",
    "            a.COBAL,\n",
    "            a.CREDLIMITCLATRESAMT\n",
    "        FROM\n",
    "            COCCDM.WH_ACCTLOAN_TEMP a\n",
    "        \"\"\")\n",
    "        start_time = time.time()\n",
    "        wh_acctloan = pd.read_sql(wh_acctloan, connection)\n",
    "        print(f\"wh_acctloan took {time.time() - start_time} seconds.\")\n",
    "\n",
    "        # COCCDM -> WH_ORG\n",
    "        wh_org = text(\"\"\"\n",
    "        SELECT\n",
    "            a.ORGNBR,\n",
    "            a.NAICSCD,\n",
    "            a.NAICSCDDESC\n",
    "        FROM\n",
    "            COCCDM.WH_ORG a\n",
    "        \"\"\")\n",
    "        start_time = time.time()\n",
    "        wh_org = pd.read_sql(wh_org, connection)\n",
    "        print(f\"wh_org took {time.time() - start_time} seconds.\")\n",
    "\n",
    "        # # COCCDM -> WH_PERS\n",
    "        # wh_pers = text(\"\"\"\n",
    "        # SELECT\n",
    "        #     a.PERSNBR,\n",
    "        #     a.NAICSCD,\n",
    "        #     a.NAICSDESC\n",
    "        # FROM\n",
    "        #     COCCDM.WH_PERS a\n",
    "        # \"\"\")\n",
    "        # start_time = time.time()\n",
    "        # wh_pers = pd.read_sql(wh_pers, connection)\n",
    "        # print(f\"wh_pers took {time.time() - start_time} seconds.\")\n",
    "        \n",
    "\n",
    "        # COCCDM -> WH_PROP\n",
    "        wh_prop = text(\"\"\"\n",
    "        SELECT\n",
    "            a.ACCTNBR,\n",
    "            a.PROPNBR,\n",
    "            a.APRSVALUEAMT,\n",
    "            a.APRSDATE,\n",
    "            a.PROPADDR1,\n",
    "            a.PROPADDR2,\n",
    "            a.PROPADDR3,\n",
    "            a.PROPCITY,\n",
    "            a.PROPSTATE,\n",
    "            a.PROPZIP,\n",
    "            a.PROPTYPECD\n",
    "        FROM\n",
    "            COCCDM.WH_PROP a\n",
    "        \"\"\")\n",
    "        start_time = time.time()\n",
    "        wh_prop = pd.read_sql(wh_prop, connection)\n",
    "        print(f\"wh_prop took {time.time() - start_time} seconds.\")\n",
    "\n",
    "        # COCCDM -> WH_PROP2\n",
    "        wh_prop2 = text(\"\"\"\n",
    "        SELECT\n",
    "            a.ACCTNBR,\n",
    "            a.PROPNBR,\n",
    "            a.PROPDESC,\n",
    "            a.PROPTYPDESC\n",
    "        FROM\n",
    "            COCCDM.WH_PROP2 a\n",
    "        \"\"\")\n",
    "        start_time = time.time()\n",
    "        wh_prop2 = pd.read_sql(wh_prop2, connection)\n",
    "        print(f\"wh_prop2 took {time.time() - start_time} seconds.\")\n",
    "\n",
    "        # # COCCDM -> ORGADDRUSE\n",
    "        # orgaddruse = text(\"\"\"\n",
    "        # SELECT\n",
    "        #     a.ORGNBR,\n",
    "        #     a.ADDRUSECD,\n",
    "        #     a.ADDRNBR\n",
    "        # FROM\n",
    "        #     COCCDM.ORGADDRUSE a\n",
    "        # \"\"\")\n",
    "        # start_time = time.time()\n",
    "        # orgaddruse = pd.read_sql(orgaddruse, connection)\n",
    "        # print(f\"orgaddruse took {time.time() - start_time} seconds.\")\n",
    "\n",
    "        # # COCCDM -> PERSADDRUSE\n",
    "        # persaddruse = text(\"\"\"\n",
    "        # SELECT\n",
    "        #     a.PERSNBR,\n",
    "        #     a.ADDRUSECD,\n",
    "        #     a.ADDRNBR\n",
    "        # FROM\n",
    "        #     COCCDM.PERSADDRUSE a\n",
    "        # \"\"\")\n",
    "        # start_time = time.time()\n",
    "        # persaddruse = pd.read_sql(persaddruse, connection)\n",
    "        # print(f\"persaddruse took {time.time() - start_time} seconds.\")\n",
    "        \n",
    "        # # COCCDM -> WH_ADDR\n",
    "        # wh_addr = text(\"\"\"\n",
    "        # SELECT\n",
    "        #     a.ADDRNBR,\n",
    "        #     a.TEXT1,\n",
    "        #     a.TEXT2,\n",
    "        #     a.TEXT3,\n",
    "        #     a.CITYNAME,\n",
    "        #     a.STATECD,\n",
    "        #     a.ZIPCD\n",
    "        # FROM\n",
    "        #     COCCDM.WH_ADDR a\n",
    "        # \"\"\")\n",
    "        # start_time = time.time()\n",
    "        # wh_addr = pd.read_sql(wh_addr, connection)\n",
    "        # print(f\"wh_addr took {time.time() - start_time} seconds.\")\n",
    "\n",
    "    #Last business day\n",
    "    with db_handler.engine1.connect() as connection:\n",
    "#         For development only\n",
    "        househldacct = text(\"\"\"\n",
    "        SELECT \n",
    "            a.ACCTNBR,\n",
    "            a.HOUSEHOLDNBR,\n",
    "            a.DATELASTMAINT\n",
    "        FROM \n",
    "            OSIEXTN.HOUSEHLDACCT a\n",
    "        \"\"\")\n",
    "        start_time = time.time()\n",
    "        househldacct = pd.read_sql(househldacct, connection)\n",
    "        print(f\"househldacct took {time.time() - start_time} seconds.\")\n",
    "\n",
    "\n",
    "    data = {\n",
    "        'wh_acctcommon': wh_acctcommon,\n",
    "        'wh_loans': wh_loans,\n",
    "        'wh_acctloan': wh_acctloan,\n",
    "        'wh_org': wh_org,\n",
    "        # 'wh_pers': wh_pers,\n",
    "        'wh_prop': wh_prop,\n",
    "        'wh_prop2': wh_prop2,\n",
    "        # 'orgaddruse': orgaddruse,\n",
    "        # 'persaddruse': persaddruse,\n",
    "        # 'wh_addr': wh_addr,\n",
    "        'househldacct': househldacct,\n",
    "    }\n",
    "    return data\n",
    "\n",
    "# %%\n",
    "# data = retrieve_data()\n",
    "\n",
    "# %%\n",
    "# wh_acctcommon = data['wh_acctcommon'].copy()\n",
    "# wh_loans = data['wh_loans'].copy()\n",
    "# wh_acctloan = data['wh_acctloan'].copy()\n",
    "# wh_org = data['wh_org'].copy()\n",
    "# wh_pers = data['wh_pers'].copy()\n",
    "# wh_prop = data['wh_prop'].copy()\n",
    "# wh_prop2 = data['wh_prop2'].copy()\n",
    "# orgaddruse = data['orgaddruse'].copy()\n",
    "# persaddruse = data['persaddruse'].copy()\n",
    "# wh_addr = data['wh_addr'].copy()\n",
    "\n",
    "# %%\n",
    "def filter_acctcommon(df):\n",
    "    \"\"\"\n",
    "    Filter acctcommon table\n",
    "\n",
    "    Args:\n",
    "        df: acctcommon table from COCC\n",
    "\n",
    "    Returns:\n",
    "        result_df: dataframe after filters are applied\n",
    "    \n",
    "    Operations:\n",
    "    [MJACCTTYPCD] IN (\"CML\", \"CNS\", \"MTG\", \"MLN\") \n",
    "    AND \n",
    "    [CURRMIACCTTYPCD] != \"CI07\"\n",
    "    If [MJACCTTYPCD] IN \"CNS\", [CURRMIACCTTYPCD] IN (\"IL02\", \"IL11\", \"IL12\", \"IL13\", \"IL14\") \n",
    "    AND \n",
    "    !IsNull([TAXRPTFORORGNBR])\n",
    "    \"\"\"\n",
    "    df = df[df['mjaccttypcd'].isin(['CML', 'MTG', 'MLN'])]\n",
    "    df = df[df['currmiaccttypcd'] != 'CI07']\n",
    "    return df\n",
    "\n",
    "# %%\n",
    "def filter_wh_loans(df):\n",
    "    \"\"\"\n",
    "    Filter wh_loans\n",
    "\n",
    "    Args:\n",
    "        df: WH_LOANS_TEMP from COCCDM db table\n",
    "    \n",
    "    Returns:\n",
    "        result_df: filtered dataframe of wh_loans\n",
    "\n",
    "    Operations:\n",
    "    - Create a day difference between \n",
    "    \"\"\"\n",
    "    df['day diff'] = (df['rundate'] - df['origdate']).dt.days + 1\n",
    "    result_df = df[df['day diff'] <= 45]\n",
    "    return result_df\n",
    "    \n",
    "def drop_household_duplicates(househldacct):\n",
    "    househldacct = househldacct.sort_values(by='datelastmaint', ascending=False).drop_duplicates(subset='acctnbr', keep='first').copy()\n",
    "    return househldacct\n",
    "\n",
    "def drop_org_duplicates(wh_org):\n",
    "    wh_org = wh_org.drop_duplicates(subset='orgnbr', keep='first').copy()\n",
    "    return wh_org\n",
    "\n",
    "# %%\n",
    "# filtered_wh_loans = filter_wh_loans(wh_loans)\n",
    "\n",
    "# %%\n",
    "def consolidate_prop_data(wh_prop, wh_prop2):\n",
    "    \"\"\"\n",
    "    Consolidate property data between the two property tables in COCC\n",
    "\n",
    "    Args:\n",
    "        wh_prop\n",
    "        wh_prop2\n",
    "\n",
    "    Returns:\n",
    "        consolidated_prop_data\n",
    "\n",
    "    Operations:\n",
    "    - merge the tables\n",
    "    - rename columns\n",
    "    - keep only the property with the highest appraised value\n",
    "    - fill null values in aprsvalueamt field\n",
    "\n",
    "    \"\"\"\n",
    "    consolidated_prop_data = pd.merge(wh_prop, wh_prop2, how='inner', on='propnbr')\n",
    "    consolidated_prop_data['acctnbr'] = consolidated_prop_data['acctnbr_x'].combine_first(consolidated_prop_data['acctnbr_y'])\n",
    "    consolidated_prop_data = consolidated_prop_data.drop(columns=['acctnbr_x','acctnbr_y'])\n",
    "    consolidated_prop_data['aprsvalueamt'] = consolidated_prop_data['aprsvalueamt'].fillna(0)\n",
    "    consolidated_prop_data = (consolidated_prop_data.sort_values('aprsvalueamt', ascending=False).groupby('acctnbr', as_index=False).first())\n",
    "    consolidated_prop_data = consolidated_prop_data.reset_index(drop=True)\n",
    "    return consolidated_prop_data\n",
    "\n",
    "# %%\n",
    "# consolidated_prop_data = consolidate_prop_data(wh_prop, wh_prop2)\n",
    "\n",
    "# %%\n",
    "def merge_data(filtered_acctcommon, filtered_wh_loans, wh_acctloan, consolidated_prop_data, wh_org, househldacct):\n",
    "    \"\"\"\n",
    "    Merging dataframes together\n",
    "    \n",
    "    Args:\n",
    "        dfs: all dataframes\n",
    "    \n",
    "    Returns:\n",
    "        merged_df: merged data\n",
    "    \"\"\"\n",
    "\n",
    "    # QA tests\n",
    "    assert filtered_acctcommon['acctnbr'].is_unique, \"Duplicates found\"\n",
    "    assert househldacct['acctnbr'].is_unique, \"Duplicates found\"\n",
    "    assert wh_acctloan['acctnbr'].is_unique, \"Duplicates found\"\n",
    "    assert consolidated_prop_data['acctnbr'].is_unique, \"Duplicates found\"\n",
    "    assert wh_org['orgnbr'].is_unique, \"Duplicates found\"\n",
    "\n",
    "    merged_df = pd.merge(filtered_acctcommon, filtered_wh_loans, on='acctnbr', how='inner')\n",
    "    merged_df = pd.merge(merged_df, wh_acctloan, on='acctnbr', how='left')\n",
    "    merged_df = pd.merge(merged_df, consolidated_prop_data, on='acctnbr', how='left')\n",
    "    merged_df = merged_df.drop(columns=['propnbr_y'])\n",
    "    merged_df = merged_df.rename(columns={'propnbr_x':'propnbr'})\n",
    "    merged_df = pd.merge(merged_df, wh_org, left_on='taxrptfororgnbr', right_on='orgnbr', how='left').sort_values(by='origdate', ascending=False)\n",
    "    merged_df = pd.merge(merged_df, househldacct, how='left', on='acctnbr')\n",
    "    return merged_df\n",
    "\n",
    "def column_to_index(column):\n",
    "    \"\"\"\n",
    "    Convert Excel column letters to column index for formatting\n",
    "    \"\"\"\n",
    "    index = 0\n",
    "    for i, char in enumerate(reversed(column.upper())):\n",
    "        index += (ord(char) - 64) * (26 ** i)\n",
    "    return index\n",
    "\n",
    "# %%\n",
    "# merged_df = merge_data(filtered_acctcommon, filtered_wh_loans, wh_acctloan, consolidated_prop_data, wh_org)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# Potential Outstanding\n",
    "def filter_and_merge_loan_tables(acctcommon, acctloan, loans):\n",
    "    \"\"\"\n",
    "    This filters on CML Loans & merges tables to consolidate loan data.\n",
    "    Data cleansing on numeric fields is performed.\n",
    "    \n",
    "    Args:\n",
    "        acctcommon: WH_ACCTCOMMON\n",
    "        acctloan: WH_ACCTLOAN\n",
    "        loans: WH_LOANS\n",
    "        \n",
    "    Returns:\n",
    "        df: Consolidated loan data as a dataframe\n",
    "        \n",
    "    Operations:\n",
    "        - mjaccttypcd (Major) == 'CML'\n",
    "        - left merge of df (acctcommon) & acctloan on 'acctnbr'\n",
    "        - left merge of df & loans on 'acctnbr'\n",
    "        - drop all fields that are completely null/empty\n",
    "        - Replace null/na values with 0 for numeric fields:\n",
    "            - total pct sold\n",
    "            - avail bal amt\n",
    "            - credit limit collateral reserve amt\n",
    "        - loans with risk rating 4 or 5 are excluded\n",
    "    \"\"\"\n",
    "\n",
    "    # CML loans\n",
    "    df = acctcommon[acctcommon['mjaccttypcd'].isin(['CML'])]\n",
    "    df = df[df['curracctstatcd'].isin(['ACT','NPFM'])]\n",
    "\n",
    "    # Merging and dropping blank fields\n",
    "    df = pd.merge(df, acctloan, on='acctnbr', how='left', suffixes=('_df', '_acctloan'))\n",
    "    df = pd.merge(df, loans, on='acctnbr', how='left', suffixes=('_df', '_loans'))\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    \n",
    "    # Data Cleansing\n",
    "    df['totalpctsold'] = df['totalpctsold'].fillna(0)\n",
    "    df['availbalamt'] = df['availbalamt'].fillna(0)\n",
    "    df['credlimitclatresamt'] = df['credlimitclatresamt'].fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def append_total_exposure_field(df):\n",
    "    \"\"\" \n",
    "    Single Obligor Exposure Calculation\n",
    "    \n",
    "    Args:\n",
    "        df: loan_data is loaded in\n",
    "    \n",
    "    Returns:\n",
    "        df: loan_data is returned with new fields appended\n",
    "        \n",
    "    Operations:\n",
    "        bookbalance -> if currmiaccttypcd == 'CM45', use notebal, else bookbalance\n",
    "            - Tax Exempt bonds always have $0 as book balance so adjustment is made\n",
    "        net balance == bookbalance - cobal\n",
    "            - BCSB balance - Charged off amount (COBAL)\n",
    "        net available == available balance amount * (1 - total pct sold)\n",
    "        net collateral reserve == collateral reserve * (1 - total pct sold)\n",
    "        total exposure == net balance + net available + net collateral reserve\n",
    "    \"\"\"\n",
    "    # QA test\n",
    "    list_of_numeric = ['bookbalance','notebal','availbalamt','totalpctsold']\n",
    "    for col in list_of_numeric:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    # Tax Exempt bonds always have $0 Book Balance so need to take NOTEBAL\n",
    "    df['bookbalance'] = np.where(df['currmiaccttypcd'].isin(['CM45']), df['notebal'], df['bookbalance'])\n",
    "    df['Net Balance'] = df['bookbalance'] - df['cobal']\n",
    "    df['Net Available'] = df['availbalamt'] * (1 - df['totalpctsold'])\n",
    "    df['Net Collateral Reserve'] = df['credlimitclatresamt'] * (1 - df['totalpctsold'])\n",
    "    df['Total Exposure'] = df['Net Balance'] + df['Net Available'] + df['Net Collateral Reserve']\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "def get_most_recent_file(folder_path):\n",
    "    today_str = datetime.now().strftime('%Y%m%d')\n",
    "    today_date = datetime.strptime(today_str, '%Y%m%d')\n",
    "\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    csv_files = [f for f in files if f.startswith(\"r360_\") and f.endswith(\".csv\")]\n",
    "\n",
    "    valid_files = {}\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            date_str = file.split(\"_\")[1].split(\".csv\")[0]\n",
    "            file_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "            if file_date <= today_date:\n",
    "                valid_files[file_date] = file\n",
    "        except (IndexError, ValueError):\n",
    "            continue\n",
    "\n",
    "    if not valid_files:\n",
    "        print(\"No history\")\n",
    "        return None\n",
    "    else:\n",
    "        most_recent_date = max(valid_files.keys())\n",
    "        most_recent_file = valid_files[most_recent_date]\n",
    "\n",
    "        return os.path.join(folder_path, most_recent_file)\n",
    "    \n",
    "def append_grouping_keys(loan_data, househldacct, pkey):\n",
    "    assert househldacct['acctnbr'].is_unique, \"Duplicates found\"\n",
    "    assert pkey['acctnbr'].is_unique, \"Duplicates found\"\n",
    "\n",
    "    loan_data = pd.merge(loan_data, househldacct, on='acctnbr', how='left')\n",
    "    loan_data = pd.merge(loan_data, pkey, on='acctnbr', how='left')\n",
    "    return loan_data\n",
    "\n",
    "def retrieve_historical_keys(history_path):\n",
    "    if history_path is None:\n",
    "        return None\n",
    "    else:\n",
    "        history = pd.read_csv(history_path)\n",
    "        return history\n",
    "    \n",
    "def append_historical_keys(data, history=None):\n",
    "    if history is None:\n",
    "        return data\n",
    "    else:\n",
    "        data = pd.DataFrame.from_dict(data, orient='index').copy()\n",
    "        data = data.reset_index().copy()\n",
    "        data = data.rename(columns={'index':'acctnbr'})\n",
    "        history_subset = history[['acctnbr','portfolio_key']]\n",
    "        assert history_subset['acctnbr'].is_unique, \"Duplicates found\"\n",
    "        data = pd.merge(data, history_subset, on='acctnbr', how='left')\n",
    "        data = data.set_index('acctnbr')\n",
    "        data = data.to_dict(orient='index').copy()\n",
    "        return data\n",
    "    \n",
    "\n",
    "\n",
    "# %%\n",
    "def calculate_total_exposure(df):\n",
    "    hh_exposure = df.groupby('householdnbr', as_index=False)['Total Exposure'].sum()\n",
    "    hh_exposure = hh_exposure.rename(columns={'Total Exposure':'total_exposure_hh'}).copy()\n",
    "    pkey_exposure = df.groupby('portfolio_key', as_index=False)['Total Exposure'].sum()\n",
    "    pkey_exposure = pkey_exposure.rename(columns={'Total Exposure':'total_exposure_pkey'}).copy()\n",
    "    hh_exposure = pd.DataFrame(hh_exposure)\n",
    "    pkey_exposure = pd.DataFrame(pkey_exposure)\n",
    "\n",
    "    df = pd.merge(df, hh_exposure, on='householdnbr', how='left')\n",
    "    df = pd.merge(df, pkey_exposure, on='portfolio_key', how='left')\n",
    "    return df\n",
    "\n",
    "# %%\n",
    "def append_exposure(df, keys_df):\n",
    "    assert df['acctnbr'].is_unique, \"Duplicates found\"\n",
    "    assert keys_df['acctnbr'].is_unique, \"Duplicates found\"\n",
    "\n",
    "    df = pd.merge(df, keys_df, how='left', on='acctnbr')\n",
    "    return df\n",
    "\n",
    "# %%\n",
    "# NEW LOAN section\n",
    "def split_data(df):\n",
    "    \"\"\"\n",
    "    Goal is to split the data between CML & MTG for this section, add subtitles, and necessary blank fields\n",
    "    \"\"\"\n",
    "    df['Notes'] = None\n",
    "    df['Next Rev Date'] = None\n",
    "    df['Appr in CT File'] = None\n",
    "    df['Exceptions on List'] = None\n",
    "\n",
    "    cml = df.loc[df['mjaccttypcd'] == 'CML', [\n",
    "        'Notes',\n",
    "        'Next Rev Date',\n",
    "        'Appr in CT File',\n",
    "        'Exceptions on List',\n",
    "        'householdnbr',\n",
    "        'contractdate',\n",
    "        'product',\n",
    "        'loanofficer',\n",
    "        'ownersortname',\n",
    "        'acctnbr',\n",
    "        'origbal',\n",
    "        'notebal',\n",
    "        'availbalamt',\n",
    "        'total_exposure_hh',\n",
    "        'total_exposure_pkey',\n",
    "        'riskratingcd',\n",
    "        'fdiccatcd',\n",
    "        'fdiccatdesc',\n",
    "        'naicscd',\n",
    "        'naicscddesc',\n",
    "        'proptypecd',\n",
    "        'proptypdesc',\n",
    "        'noteintrate',\n",
    "        'propnbr',\n",
    "        'propdesc'\n",
    "    ]].copy()\n",
    "\n",
    "    cml = cml.sort_values(by='contractdate', ascending=False)\n",
    "\n",
    "    mtg = df.loc[df['mjaccttypcd'] == 'MTG', [\n",
    "        'Notes',\n",
    "        'Next Rev Date',\n",
    "        'Appr in CT File',\n",
    "        'Exceptions on List',\n",
    "        'householdnbr',\n",
    "        'contractdate',\n",
    "        'product',\n",
    "        'loanofficer',\n",
    "        'ownersortname',\n",
    "        'acctnbr',\n",
    "        'origbal',\n",
    "        'notebal',\n",
    "        'availbalamt',\n",
    "        'total_exposure_hh',\n",
    "        'total_exposure_pkey',\n",
    "        'riskratingcd',\n",
    "        'fdiccatcd',\n",
    "        'fdiccatdesc',\n",
    "        'naicscd',\n",
    "        'naicscddesc',\n",
    "        'proptypecd',\n",
    "        'proptypdesc',\n",
    "        'noteintrate',\n",
    "        'propnbr',\n",
    "        'propdesc'\n",
    "    ]].copy()\n",
    "\n",
    "    mtg = mtg.sort_values(by='contractdate', ascending=False)\n",
    "\n",
    "    def create_subtitle_row(df, subtitle):\n",
    "        \"\"\"\n",
    "        Create a new row with a subtitle to break sections apart\n",
    "\n",
    "        Args:\n",
    "            df: either cml or mtg\n",
    "            subtitle (str): section title\n",
    "        \n",
    "        Returns:\n",
    "            df with additional row for subtitle\n",
    "        \"\"\"\n",
    "        new_row = pd.DataFrame(columns=df.columns)\n",
    "        new_row.loc[1, 'product'] = subtitle\n",
    "        new_row = new_row.fillna('')\n",
    "        df = pd.concat([new_row, df]).copy()\n",
    "        return df\n",
    "    \n",
    "    cml = create_subtitle_row(cml, 'Commercial Loans')\n",
    "    mtg = create_subtitle_row(mtg, 'Residential Loans')\n",
    "\n",
    "    blank_row = pd.DataFrame(columns=cml.columns)\n",
    "    blank_row = blank_row.fillna('')\n",
    "    \n",
    "    df = pd.concat([cml, blank_row])\n",
    "    df = pd.concat([df, mtg])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# CRA section\n",
    "def cra_section(df):\n",
    "    \"\"\"\n",
    "    CRA Sheet creation\n",
    "    \"\"\"\n",
    "    df['#'] = None\n",
    "    df['Committed'] = None\n",
    "    df['Round'] = None\n",
    "    df['Gross Sales'] = None\n",
    "    df['MSA'] = None\n",
    "    df['State'] = None\n",
    "    df['County'] = None\n",
    "    df['Census'] = None\n",
    "    df['SBP'] = None\n",
    "    df['Reason'] = None\n",
    "    df['Comments'] = None\n",
    "\n",
    "    df = df.loc[~(df['currmiaccttypcd'].isin(['CM15','CM16']))].copy()\n",
    "    df = df.loc[df['mjaccttypcd'] != 'MTG'].copy()\n",
    "\n",
    "    df = df.loc[df['mjaccttypcd'] == 'CML', [\n",
    "        '#',\n",
    "        'contractdate',\n",
    "        'ownersortname',\n",
    "        'acctnbr',\n",
    "        'Committed',\n",
    "        'Round',\n",
    "        'Gross Sales',\n",
    "        'propaddr1',\n",
    "        'propcity',\n",
    "        'propstate',\n",
    "        'propzip',\n",
    "        'Comments',\n",
    "        'fdiccatcd',\n",
    "        'MSA',\n",
    "        'State',\n",
    "        'County',\n",
    "        'Census',\n",
    "        'product',\n",
    "        'SBP',\n",
    "        'Reason',\n",
    "        'noteintrate',\n",
    "        'loanofficer',\n",
    "        'origdate',\n",
    "        'proptypdesc',\n",
    "        'riskratingcd',\n",
    "        'origbal'\n",
    "    ]].copy()\n",
    "\n",
    "    df = df.sort_values(by='contractdate', ascending=False)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acctcommon took 71.28466534614563 seconds.\n",
      "wh_loans took 34.88888478279114 seconds.\n",
      "wh_acctloan took 35.05140995979309 seconds.\n",
      "wh_org took 6.912823438644409 seconds.\n",
      "wh_prop took 34.51502799987793 seconds.\n",
      "wh_prop2 took 35.74451184272766 seconds.\n",
      "househldacct took 89.80053496360779 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "# %%\n",
    "# def main():\n",
    "data = retrieve_data()\n",
    "\n",
    "wh_acctcommon = data['wh_acctcommon'].copy()\n",
    "wh_loans = data['wh_loans'].copy()\n",
    "wh_acctloan = data['wh_acctloan'].copy()\n",
    "wh_org = data['wh_org'].copy()\n",
    "wh_prop = data['wh_prop'].copy()\n",
    "wh_prop2 = data['wh_prop2'].copy()\n",
    "househldacct = data['househldacct'].copy()\n",
    "\n",
    "filtered_acctcommon = filter_acctcommon(wh_acctcommon)\n",
    "filtered_wh_loans = filter_wh_loans(wh_loans)\n",
    "consolidated_prop_data = consolidate_prop_data(wh_prop, wh_prop2)\n",
    "\n",
    "househldacct = drop_household_duplicates(househldacct)\n",
    "wh_org = drop_org_duplicates(wh_org)\n",
    "merged_df = merge_data(filtered_acctcommon, filtered_wh_loans, wh_acctloan, consolidated_prop_data, wh_org, househldacct)\n",
    "loan_data = filter_and_merge_loan_tables(wh_acctcommon, wh_acctloan, wh_loans)\n",
    "loan_data = append_total_exposure_field(loan_data)\n",
    "historical_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\R360\\Production\\Output'\n",
    "historical_path = get_most_recent_file(historical_path)\n",
    "\n",
    "pkey = retrieve_historical_keys(historical_path)\n",
    "pkey = pkey.loc[:,['acctnbr','portfolio_key']].copy()\n",
    "loan_data = append_grouping_keys(loan_data, househldacct, pkey)\n",
    "loan_data = calculate_total_exposure(loan_data)\n",
    "loan_data_keys = loan_data.loc[:,['acctnbr','total_exposure_hh','total_exposure_pkey']].copy()\n",
    "\n",
    "\n",
    "merged_df = append_exposure(merged_df, loan_data_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99 entries, 0 to 98\n",
      "Data columns (total 60 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   acctnbr              99 non-null     int64         \n",
      " 1   loanofficer          99 non-null     object        \n",
      " 2   ownersortname        99 non-null     object        \n",
      " 3   product              99 non-null     object        \n",
      " 4   curracctstatcd       99 non-null     object        \n",
      " 5   notebal              99 non-null     float64       \n",
      " 6   bookbalance          99 non-null     float64       \n",
      " 7   noteintrate          99 non-null     float64       \n",
      " 8   datemat              99 non-null     datetime64[ns]\n",
      " 9   taxrptfororgnbr      45 non-null     float64       \n",
      " 10  taxrptforpersnbr     54 non-null     float64       \n",
      " 11  contractdate         99 non-null     datetime64[ns]\n",
      " 12  mjaccttypcd          99 non-null     object        \n",
      " 13  currmiaccttypcd      99 non-null     object        \n",
      " 14  origdate             99 non-null     datetime64[ns]\n",
      " 15  origbal              95 non-null     float64       \n",
      " 16  fdiccatdesc          99 non-null     object        \n",
      " 17  rundate              99 non-null     datetime64[ns]\n",
      " 18  availbalamt          33 non-null     float64       \n",
      " 19  day diff             99 non-null     float64       \n",
      " 20  minintrate           99 non-null     float64       \n",
      " 21  fdiccatcd            99 non-null     object        \n",
      " 22  propnbr              96 non-null     float64       \n",
      " 23  totalpctsold         99 non-null     float64       \n",
      " 24  riskratingcd         45 non-null     object        \n",
      " 25  cobal                99 non-null     float64       \n",
      " 26  credlimitclatresamt  99 non-null     float64       \n",
      " 27  aprsvalueamt         96 non-null     float64       \n",
      " 28  aprsdate             68 non-null     datetime64[ns]\n",
      " 29  propaddr1            65 non-null     object        \n",
      " 30  propaddr2            0 non-null      object        \n",
      " 31  propaddr3            0 non-null      object        \n",
      " 32  propcity             65 non-null     object        \n",
      " 33  propstate            65 non-null     object        \n",
      " 34  propzip              65 non-null     object        \n",
      " 35  proptypecd           96 non-null     object        \n",
      " 36  propdesc             96 non-null     object        \n",
      " 37  proptypdesc          96 non-null     object        \n",
      " 38  orgnbr               45 non-null     float64       \n",
      " 39  naicscd              41 non-null     object        \n",
      " 40  naicscddesc          41 non-null     object        \n",
      " 41  householdnbr         59 non-null     float64       \n",
      " 42  datelastmaint        59 non-null     datetime64[ns]\n",
      " 43  total_exposure_hh    38 non-null     float64       \n",
      " 44  total_exposure_pkey  40 non-null     float64       \n",
      " 45  Notes                0 non-null      object        \n",
      " 46  Next Rev Date        0 non-null      object        \n",
      " 47  Appr in CT File      0 non-null      object        \n",
      " 48  Exceptions on List   0 non-null      object        \n",
      " 49  #                    0 non-null      object        \n",
      " 50  Committed            0 non-null      object        \n",
      " 51  Round                0 non-null      object        \n",
      " 52  Gross Sales          0 non-null      object        \n",
      " 53  MSA                  0 non-null      object        \n",
      " 54  State                0 non-null      object        \n",
      " 55  County               0 non-null      object        \n",
      " 56  Census               0 non-null      object        \n",
      " 57  SBP                  0 non-null      object        \n",
      " 58  Reason               0 non-null      object        \n",
      " 59  Comments             0 non-null      object        \n",
      "dtypes: datetime64[ns](6), float64(18), int64(1), object(35)\n",
      "memory usage: 46.5+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved with autofit at \\\\10.161.85.66\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Weekly Reports\\NewLoanReport_LR_Credit\\Production\\Output\n",
      "Excel process complete\n",
      "Email sent!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_loan_page = split_data(merged_df)\n",
    "\n",
    "cra_section = cra_section(merged_df)\n",
    "\n",
    "# Output to excel\n",
    "current_date = datetime.now().strftime('%Y%m%d')\n",
    "file_path = r'\\\\10.161.85.66\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Weekly Reports\\NewLoanReport_LR_Credit\\Production\\Output'\n",
    "file_name = f'Loan_Report_45_day_lookback_{current_date}.xlsx'\n",
    "full_path = os.path.join(file_path, file_name)\n",
    "with pd.ExcelWriter(full_path, mode='w', engine='openpyxl') as writer:\n",
    "    new_loan_page.to_excel(writer, sheet_name='NEW LOAN', index=False)\n",
    "    cra_section.to_excel(writer, sheet_name='CRA', index=False)\n",
    "\n",
    "try:\n",
    "    excel = win32.Dispatch(\"Excel.Application\")\n",
    "    excel.Visible = False\n",
    "    workbook = excel.Workbooks.Open(full_path)\n",
    "    \n",
    "    ## NEW LOAN\n",
    "    sheet = workbook.Worksheets(\"NEW LOAN\")\n",
    "\n",
    "    sheet.Columns.AutoFit()\n",
    "\n",
    "    # Bold top row\n",
    "    top_row = sheet.Rows(1)\n",
    "    top_row.Font.Bold = True\n",
    "\n",
    "    # Add bottom border to header row\n",
    "    bottom_border = top_row.Borders(9)\n",
    "    bottom_border.LineStyle = 1\n",
    "    bottom_border.Weight = 2\n",
    "\n",
    "    date_columns = [\"F\"]\n",
    "\n",
    "    for col in date_columns:\n",
    "        col_index = column_to_index(col)\n",
    "        sheet.Columns(col_index).NumberFormat = \"mm/dd/yyyy\"\n",
    "\n",
    "    dollar_columns = [\"K\",\"L\",\"M\",\"N\",\"O\"]\n",
    "    \n",
    "    for col in dollar_columns:\n",
    "        col_index = column_to_index(col)\n",
    "        sheet.Columns(col_index).NumberFormat = \"$###,##0.00\"\n",
    "\n",
    "    percentage_columns = [\"W\"]\n",
    "    \n",
    "    for col in percentage_columns:\n",
    "        col_index = column_to_index(col)\n",
    "        sheet.Columns(col_index).NumberFormat = \"0.00%\"\n",
    "    \n",
    "\n",
    "    # Freeze top row\n",
    "    sheet.Application.ActiveWindow.SplitRow = 1\n",
    "    sheet.Application.ActiveWindow.FreezePanes = True\n",
    "\n",
    "    ## CRA\n",
    "    sheet = workbook.Worksheets(\"CRA\")\n",
    "\n",
    "    sheet.Columns.AutoFit()\n",
    "\n",
    "    # Bold top row\n",
    "    top_row = sheet.Rows(1)\n",
    "    top_row.Font.Bold = True\n",
    "\n",
    "    # Add bottom border to header row\n",
    "    bottom_border = top_row.Borders(9)\n",
    "    bottom_border.LineStyle = 1\n",
    "    bottom_border.Weight = 2\n",
    "\n",
    "    date_columns = [\"B\",\"W\"]\n",
    "\n",
    "    for col in date_columns:\n",
    "        col_index = column_to_index(col)\n",
    "        sheet.Columns(col_index).NumberFormat = \"mm/dd/yyyy\"\n",
    "\n",
    "    dollar_columns = [\"Z\"]\n",
    "    \n",
    "    for col in dollar_columns:\n",
    "        col_index = column_to_index(col)\n",
    "        sheet.Columns(col_index).NumberFormat = \"$###,##0.00\"\n",
    "\n",
    "\n",
    "    percentage_columns = [\"U\"]\n",
    "    \n",
    "    for col in percentage_columns:\n",
    "        col_index = column_to_index(col)\n",
    "        sheet.Columns(col_index).NumberFormat = \"0.00%\"\n",
    "    \n",
    "\n",
    "    # Freeze top row\n",
    "    sheet.Application.ActiveWindow.SplitRow = 1\n",
    "    sheet.Application.ActiveWindow.FreezePanes = True\n",
    "\n",
    "\n",
    "    workbook.Save()\n",
    "    workbook.Close()\n",
    "\n",
    "    print(f\"Excel file saved with autofit at {file_path}\")\n",
    "finally:\n",
    "    try:\n",
    "        if 'workbook' in locals() and workbook is not None:\n",
    "            workbook.Close(SaveChanges=False)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if 'excel' in locals():\n",
    "            excel.Quit()\n",
    "    except:\n",
    "        pass\n",
    "    print(\"Excel process complete\")\n",
    "\n",
    "# Email\n",
    "recipients = [\n",
    "    # \"chad.doorley@bcsbmail.com\"\n",
    "    \"paul.kocak@bcsbmail.com\",\n",
    "    \"linda.clark@bcsbmail.com\"\n",
    "]\n",
    "bcc_recipients = [\n",
    "    \"chad.doorley@bcsbmail.com\"\n",
    "]\n",
    "outlook = win32.Dispatch(\"Outlook.Application\")\n",
    "message = outlook.CreateItem(0)\n",
    "# message.Display()\n",
    "message.To = \";\".join(recipients)\n",
    "message.BCC = \";\".join(bcc_recipients)\n",
    "message.Subject = f\"Weekly Loan Report - {datetime.now().strftime('%m/%d/%Y')}\"\n",
    "message.Body = \"Hi all, \\n\\nAttached is the Weekly Loan Report with a 45 day lookback. Fixed percentage formatting. Please let me know if you have any questions.\"\n",
    "message.Attachments.Add(str(full_path))\n",
    "message.Send()\n",
    "print(\"Email sent!\")\n",
    "\n",
    "\n",
    "# # %%\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
