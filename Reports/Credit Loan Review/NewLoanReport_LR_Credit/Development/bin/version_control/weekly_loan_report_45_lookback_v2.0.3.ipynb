{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Weekly Loan Report\n",
    "# Developed by CD\n",
    "# v2.0.3-dev\n",
    "\n",
    "from io import StringIO\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta, date\n",
    "from sqlalchemy.ext.asyncio import create_async_engine\n",
    "from sqlalchemy import text\n",
    "from typing import List\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "from cryptography.fernet import Fernet\n",
    "from dotenv import load_dotenv\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import sys\n",
    "import win32com.client as win32\n",
    "nest_asyncio.apply()\n",
    "\n",
    "if sys.platform == \"win32\":\n",
    "    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "\n",
    "\n",
    "def retrieve_data():\n",
    "    \"\"\"\n",
    "    Retrieve data from COCC database\n",
    "    \"\"\"\n",
    "    class DatabaseHandler:\n",
    "        \"\"\"\n",
    "        This class abstracts the connection to the database and allows a clean\n",
    "        interface for the developer to use.\n",
    "\n",
    "        This connector can handle async queries\n",
    "\n",
    "        \"\"\"\n",
    "        def __init__(self, tns_admin_path):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "                tns_admin_path (str): Oracle driver path\n",
    "                credentials_path_db1 (str): Database 1 credentials path\n",
    "                credentials_path_db1 (str): Databsae 2 credentials path\n",
    "            \"\"\"\n",
    "            os.environ['TNS_ADMIN'] = tns_admin_path\n",
    "            \n",
    "            # Load private key\n",
    "            key_key_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Utility\\env_admin\\key.key'\n",
    "            with open(key_key_path, \"rb\") as key_file:\n",
    "                key = key_file.read()\n",
    "\n",
    "            cipher = Fernet(key)\n",
    "            \n",
    "            # Load encrypted data\n",
    "            encoded_env_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Utility\\env_admin\\.env.enc'\n",
    "            with open(encoded_env_path, \"rb\") as encrypted_file:\n",
    "                encrypted_data = encrypted_file.read()\n",
    "\n",
    "            decrypted_data = cipher.decrypt(encrypted_data).decode()\n",
    "\n",
    "            env_file = StringIO(decrypted_data)\n",
    "            load_dotenv(stream=env_file)\n",
    "\n",
    "            self.username1 = os.getenv('main_username')\n",
    "            self.password1 = os.getenv('main_password')\n",
    "            self.dsn1 = os.getenv('main_dsn')\n",
    "\n",
    "            self.username2 = os.getenv('datamart_username')\n",
    "            self.password2 = os.getenv('datamart_password')\n",
    "            self.dsn2 = os.getenv('datamart_dsn')\n",
    "\n",
    "            self.connection_string1 = f'oracle+oracledb://{self.username1}:{self.password1}@{self.dsn1}'\n",
    "            self.connection_string2 = f'oracle+oracledb://{self.username2}:{self.password2}@{self.dsn2}'\n",
    "\n",
    "            self.engine1 = create_async_engine(self.connection_string1, max_identifier_length=128, echo=False, future=True)\n",
    "            self.engine1.dialect.hide_parameters = True\n",
    "            self.engine2 = create_async_engine(self.connection_string2, max_identifier_length=128, echo=False, future=True)\n",
    "            self.engine1.dialect.hide_parameters = True\n",
    "\n",
    "\n",
    "        async def query(self, sql_query, engine=1):\n",
    "            \"\"\"\n",
    "            This allows abstraction of the connection and the class\n",
    "            so the developer can query a single table as a dataframe\n",
    "\n",
    "            Args:\n",
    "                sql_query (str): The query to SQL database is passed as a string\n",
    "                engine (int): This selects the database. There are two engines:\n",
    "                    1 -> R1625\n",
    "                    2 -> COCC DataMart\n",
    "\n",
    "            Returns:\n",
    "                df: The SQL query is returned as a pandas DataFrame\n",
    "\n",
    "            Usage:\n",
    "                df = db_handler.query(\"SELECT * FROM DB.TABLE\", engine=1)\n",
    "\n",
    "                In this example, db_handler = DatabaseHandler(args)\n",
    "            \"\"\"\n",
    "            if engine == 1:\n",
    "                selected_engine = self.engine1\n",
    "            elif engine == 2:\n",
    "                selected_engine = self.engine2\n",
    "            else:\n",
    "                raise ValueError(\"Engine must be 1 or 2\")\n",
    "\n",
    "            async with selected_engine.connect() as connection:\n",
    "                result = await connection.execute(sql_query)\n",
    "                rows = result.fetchall()\n",
    "                if not rows:\n",
    "                    return pd.DataFrame()\n",
    "                df = pd.DataFrame(rows, columns=result.keys())\n",
    "            return df\n",
    "\n",
    "        async def close(self):\n",
    "            if self.engine1:\n",
    "                await self.engine1.dispose()\n",
    "            if self.engine2:\n",
    "                await self.engine2.dispose()\n",
    "\n",
    "\n",
    "    # Database Connection Configuration\n",
    "    tns_admin_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Utility\\env_admin\\tns_admin'\n",
    "    db_handler = DatabaseHandler(tns_admin_path)\n",
    "\n",
    "    async def fetch_data(queries):\n",
    "        try:\n",
    "            tasks = {query['key']: asyncio.create_task(db_handler.query(query['sql'], query['engine'])) for query in queries}\n",
    "            results = await asyncio.gather(*tasks.values())\n",
    "            return {key: df for key, df in zip(tasks.keys(), results)}\n",
    "        except Exception as e:\n",
    "            print(f\"Error\")\n",
    "            raise\n",
    "        finally:\n",
    "            await db_handler.close()\n",
    "\n",
    "    def run_sql_queries():\n",
    "        # lookup table\n",
    "        # Engine 1\n",
    "        lookup_df = text(\"\"\"\n",
    "        SELECT \n",
    "            *\n",
    "        FROM \n",
    "            sys.all_tab_columns col\n",
    "        \"\"\")\n",
    "\n",
    "        # acctcommon\n",
    "        # engine 2\n",
    "        wh_acctcommon = text(\"\"\"\n",
    "        SELECT \n",
    "            a.ACCTNBR,\n",
    "            a.LOANOFFICER,\n",
    "            a.OWNERSORTNAME,\n",
    "            a.PRODUCT,\n",
    "            a.CURRACCTSTATCD,\n",
    "            a.NOTEBAL,\n",
    "            a.BOOKBALANCE,\n",
    "            a.NOTEINTRATE,\n",
    "            a.DATEMAT,\n",
    "            a.TAXRPTFORORGNBR,\n",
    "            a.TAXRPTFORPERSNBR,\n",
    "            a.CONTRACTDATE,\n",
    "            a.MJACCTTYPCD,\n",
    "            a.CURRMIACCTTYPCD,\n",
    "            a.NAMEADDR1,\n",
    "            a.NAMEADDR2,\n",
    "            a.NAMEADDR3,\n",
    "            a.PRIMARYOWNERCITY,\n",
    "            a.PRIMARYOWNERSTATE,\n",
    "            a.PRIMARYOWNERZIPCD,\n",
    "            a.NOTEOPENAMT\n",
    "        FROM \n",
    "            COCCDM.WH_ACCTCOMMON_TEMP a\n",
    "        \"\"\")\n",
    "\n",
    "        wh_loans = text(\"\"\"\n",
    "        SELECT\n",
    "            a.ACCTNBR,\n",
    "            a.ORIGDATE,\n",
    "            a.ORIGBAL,\n",
    "            a.FDICCATDESC,\n",
    "            a.RUNDATE,\n",
    "            a.AVAILBALAMT\n",
    "        FROM\n",
    "            COCCDM.WH_LOANS_TEMP a\n",
    "        \"\"\")\n",
    "\n",
    "        wh_acctloan = text(\"\"\"\n",
    "        SELECT\n",
    "            a.ACCTNBR,\n",
    "            a.MININTRATE,\n",
    "            a.FDICCATCD,\n",
    "            a.PROPNBR,\n",
    "            a.TOTALPCTSOLD,\n",
    "            a.RISKRATINGCD,\n",
    "            a.COBAL,\n",
    "            a.CREDLIMITCLATRESAMT\n",
    "        FROM\n",
    "            COCCDM.WH_ACCTLOAN_TEMP a\n",
    "        \"\"\")\n",
    "\n",
    "        wh_org = text(\"\"\"\n",
    "        SELECT\n",
    "            a.ORGNBR,\n",
    "            a.NAICSCD,\n",
    "            a.NAICSCDDESC\n",
    "        FROM\n",
    "            COCCDM.WH_ORG a\n",
    "        \"\"\")\n",
    "\n",
    "        wh_prop = text(\"\"\"\n",
    "        SELECT\n",
    "            a.ACCTNBR,\n",
    "            a.PROPNBR,\n",
    "            a.APRSVALUEAMT,\n",
    "            a.APRSDATE,\n",
    "            a.PROPADDR1,\n",
    "            a.PROPADDR2,\n",
    "            a.PROPADDR3,\n",
    "            a.PROPCITY,\n",
    "            a.PROPSTATE,\n",
    "            a.PROPZIP,\n",
    "            a.PROPTYPECD\n",
    "        FROM\n",
    "            COCCDM.WH_PROP a\n",
    "        \"\"\")\n",
    "\n",
    "        wh_prop2 = text(\"\"\"\n",
    "        SELECT\n",
    "            a.ACCTNBR,\n",
    "            a.PROPNBR,\n",
    "            a.PROPDESC,\n",
    "            a.PROPTYPDESC\n",
    "        FROM\n",
    "            COCCDM.WH_PROP2 a\n",
    "        \"\"\")\n",
    "\n",
    "        househldacct = text(\"\"\"\n",
    "        SELECT \n",
    "            a.ACCTNBR,\n",
    "            a.HOUSEHOLDNBR,\n",
    "            a.DATELASTMAINT\n",
    "        FROM \n",
    "            OSIEXTN.HOUSEHLDACCT a\n",
    "        \"\"\")\n",
    "\n",
    "        queries = [\n",
    "            {'key':'wh_acctcommon', 'sql':wh_acctcommon, 'engine':2},\n",
    "            {'key':'wh_loans', 'sql':wh_loans, 'engine':2},\n",
    "            {'key':'wh_acctloan', 'sql':wh_acctloan, 'engine':2},\n",
    "            {'key':'wh_org', 'sql':wh_org, 'engine':2},\n",
    "            {'key':'wh_prop', 'sql':wh_prop, 'engine':2},\n",
    "            {'key':'wh_prop2', 'sql':wh_prop2, 'engine':2},\n",
    "            {'key':'househldacct', 'sql':househldacct, 'engine':1},\n",
    "        ]\n",
    "\n",
    "        async def run_queries():\n",
    "            return await fetch_data(queries)\n",
    "        \n",
    "        loop = asyncio.get_event_loop()\n",
    "        if loop.is_running():\n",
    "            return loop.run_until_complete(run_queries())\n",
    "        else:\n",
    "            return asyncio.run(run_queries())\n",
    "        \n",
    "    data = run_sql_queries()\n",
    "    \n",
    "    return data\n",
    "\n",
    "# %%\n",
    "# data = retrieve_data()\n",
    "\n",
    "# %%\n",
    "# wh_acctcommon = data['wh_acctcommon'].copy()\n",
    "# wh_loans = data['wh_loans'].copy()\n",
    "# wh_acctloan = data['wh_acctloan'].copy()\n",
    "# wh_org = data['wh_org'].copy()\n",
    "# wh_pers = data['wh_pers'].copy()\n",
    "# wh_prop = data['wh_prop'].copy()\n",
    "# wh_prop2 = data['wh_prop2'].copy()\n",
    "# orgaddruse = data['orgaddruse'].copy()\n",
    "# persaddruse = data['persaddruse'].copy()\n",
    "# wh_addr = data['wh_addr'].copy()\n",
    "\n",
    "# %%\n",
    "def filter_acctcommon(df):\n",
    "    \"\"\"\n",
    "    Filter acctcommon table\n",
    "\n",
    "    Args:\n",
    "        df: acctcommon table from COCC\n",
    "\n",
    "    Returns:\n",
    "        result_df: dataframe after filters are applied\n",
    "    \n",
    "    Operations:\n",
    "    [MJACCTTYPCD] IN (\"CML\", \"CNS\", \"MTG\", \"MLN\") \n",
    "    AND \n",
    "    [CURRMIACCTTYPCD] != \"CI07\"\n",
    "    If [MJACCTTYPCD] IN \"CNS\", [CURRMIACCTTYPCD] IN (\"IL02\", \"IL11\", \"IL12\", \"IL13\", \"IL14\") \n",
    "    AND \n",
    "    !IsNull([TAXRPTFORORGNBR])\n",
    "    - Concatenate address fields into one primary_address field\n",
    "    \"\"\"\n",
    "    df = df[df['mjaccttypcd'].isin(['CML', 'MTG', 'MLN'])]\n",
    "    df = df[df['currmiaccttypcd'] != 'CI07']\n",
    "    df['primary_address'] = df[['nameaddr1','nameaddr2','nameaddr3']].apply(lambda x: ''.join(filter(None, x)), axis=1)\n",
    "    df = df.drop(columns=['nameaddr1','nameaddr2','nameaddr3'])\n",
    "    return df\n",
    "\n",
    "# %%\n",
    "def filter_wh_loans(df):\n",
    "    \"\"\"\n",
    "    Filter wh_loans\n",
    "\n",
    "    Args:\n",
    "        df: WH_LOANS_TEMP from COCCDM db table\n",
    "    \n",
    "    Returns:\n",
    "        result_df: filtered dataframe of wh_loans\n",
    "\n",
    "    Operations:\n",
    "    - Create a day difference between \n",
    "    \"\"\"\n",
    "    df['day diff'] = (df['rundate'] - df['origdate']).dt.days + 1\n",
    "    result_df = df[df['day diff'] <= 45]\n",
    "    return result_df\n",
    "    \n",
    "def drop_household_duplicates(househldacct):\n",
    "    househldacct = househldacct.sort_values(by='datelastmaint', ascending=False).drop_duplicates(subset='acctnbr', keep='first').copy()\n",
    "    return househldacct\n",
    "\n",
    "def drop_org_duplicates(wh_org):\n",
    "    wh_org = wh_org.drop_duplicates(subset='orgnbr', keep='first').copy()\n",
    "    return wh_org\n",
    "\n",
    "# %%\n",
    "# filtered_wh_loans = filter_wh_loans(wh_loans)\n",
    "\n",
    "# %%\n",
    "def consolidate_prop_data(wh_prop, wh_prop2):\n",
    "    \"\"\"\n",
    "    Consolidate property data between the two property tables in COCC\n",
    "\n",
    "    Args:\n",
    "        wh_prop\n",
    "        wh_prop2\n",
    "\n",
    "    Returns:\n",
    "        consolidated_prop_data\n",
    "\n",
    "    Operations:\n",
    "    - merge the tables\n",
    "    - rename columns\n",
    "    - keep only the property with the highest appraised value\n",
    "    - fill null values in aprsvalueamt field\n",
    "\n",
    "    \"\"\"\n",
    "    consolidated_prop_data = pd.merge(wh_prop, wh_prop2, how='inner', on='propnbr')\n",
    "    consolidated_prop_data['acctnbr'] = consolidated_prop_data['acctnbr_x'].combine_first(consolidated_prop_data['acctnbr_y'])\n",
    "    consolidated_prop_data = consolidated_prop_data.drop(columns=['acctnbr_x','acctnbr_y'])\n",
    "    consolidated_prop_data['aprsvalueamt'] = consolidated_prop_data['aprsvalueamt'].fillna(0)\n",
    "    consolidated_prop_data = (consolidated_prop_data.sort_values('aprsvalueamt', ascending=False).groupby('acctnbr', as_index=False).first())\n",
    "    consolidated_prop_data = consolidated_prop_data.reset_index(drop=True)\n",
    "    return consolidated_prop_data\n",
    "\n",
    "# %%\n",
    "# consolidated_prop_data = consolidate_prop_data(wh_prop, wh_prop2)\n",
    "\n",
    "# %%\n",
    "def merge_data(filtered_acctcommon, filtered_wh_loans, wh_acctloan, consolidated_prop_data, wh_org, househldacct):\n",
    "    \"\"\"\n",
    "    Merging dataframes together\n",
    "    \n",
    "    Args:\n",
    "        dfs: all dataframes\n",
    "    \n",
    "    Returns:\n",
    "        merged_df: merged data\n",
    "    \"\"\"\n",
    "\n",
    "    # QA tests\n",
    "    assert filtered_acctcommon['acctnbr'].is_unique, \"Duplicates found\"\n",
    "    assert househldacct['acctnbr'].is_unique, \"Duplicates found\"\n",
    "    assert wh_acctloan['acctnbr'].is_unique, \"Duplicates found\"\n",
    "    assert consolidated_prop_data['acctnbr'].is_unique, \"Duplicates found\"\n",
    "    assert wh_org['orgnbr'].is_unique, \"Duplicates found\"\n",
    "\n",
    "    merged_df = pd.merge(filtered_acctcommon, filtered_wh_loans, on='acctnbr', how='inner')\n",
    "    merged_df = pd.merge(merged_df, wh_acctloan, on='acctnbr', how='left')\n",
    "    merged_df = pd.merge(merged_df, consolidated_prop_data, on='acctnbr', how='left')\n",
    "    merged_df = merged_df.drop(columns=['propnbr_y'])\n",
    "    merged_df = merged_df.rename(columns={'propnbr_x':'propnbr'})\n",
    "    merged_df = pd.merge(merged_df, wh_org, left_on='taxrptfororgnbr', right_on='orgnbr', how='left').sort_values(by='origdate', ascending=False)\n",
    "    merged_df = pd.merge(merged_df, househldacct, how='left', on='acctnbr')\n",
    "    return merged_df\n",
    "\n",
    "def column_to_index(column):\n",
    "    \"\"\"\n",
    "    Convert Excel column letters to column index for formatting\n",
    "    \"\"\"\n",
    "    index = 0\n",
    "    for i, char in enumerate(reversed(column.upper())):\n",
    "        index += (ord(char) - 64) * (26 ** i)\n",
    "    return index\n",
    "\n",
    "# %%\n",
    "# merged_df = merge_data(filtered_acctcommon, filtered_wh_loans, wh_acctloan, consolidated_prop_data, wh_org)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# Potential Outstanding\n",
    "def filter_and_merge_loan_tables(acctcommon, acctloan, loans):\n",
    "    \"\"\"\n",
    "    This filters on CML Loans & merges tables to consolidate loan data.\n",
    "    Data cleansing on numeric fields is performed.\n",
    "    \n",
    "    Args:\n",
    "        acctcommon: WH_ACCTCOMMON\n",
    "        acctloan: WH_ACCTLOAN\n",
    "        loans: WH_LOANS\n",
    "        \n",
    "    Returns:\n",
    "        df: Consolidated loan data as a dataframe\n",
    "        \n",
    "    Operations:\n",
    "        - mjaccttypcd (Major) == 'CML'\n",
    "        - left merge of df (acctcommon) & acctloan on 'acctnbr'\n",
    "        - left merge of df & loans on 'acctnbr'\n",
    "        - drop all fields that are completely null/empty\n",
    "        - Replace null/na values with 0 for numeric fields:\n",
    "            - total pct sold\n",
    "            - avail bal amt\n",
    "            - credit limit collateral reserve amt\n",
    "        - loans with risk rating 4 or 5 are excluded\n",
    "    \"\"\"\n",
    "    # CML loans\n",
    "    df = acctcommon[acctcommon['mjaccttypcd'].isin(['CML'])]\n",
    "    df = df[df['curracctstatcd'].isin(['ACT','NPFM'])]\n",
    "\n",
    "    # Merging and dropping blank fields\n",
    "    df = pd.merge(df, acctloan, on='acctnbr', how='left', suffixes=('_df', '_acctloan'))\n",
    "    df = pd.merge(df, loans, on='acctnbr', how='left', suffixes=('_df', '_loans'))\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    \n",
    "    # Data Cleansing\n",
    "    df['totalpctsold'] = df['totalpctsold'].fillna(0)\n",
    "    df['availbalamt'] = df['availbalamt'].fillna(0)\n",
    "    df['credlimitclatresamt'] = df['credlimitclatresamt'].fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def append_total_exposure_field(df):\n",
    "    \"\"\" \n",
    "    Single Obligor Exposure Calculation\n",
    "    \n",
    "    Args:\n",
    "        df: loan_data is loaded in\n",
    "    \n",
    "    Returns:\n",
    "        df: loan_data is returned with new fields appended\n",
    "        \n",
    "    Operations:\n",
    "        bookbalance -> if currmiaccttypcd == 'CM45', use notebal, else bookbalance\n",
    "            - Tax Exempt bonds always have $0 as book balance so adjustment is made\n",
    "        net balance == bookbalance - cobal\n",
    "            - BCSB balance - Charged off amount (COBAL)\n",
    "        net available == available balance amount * (1 - total pct sold)\n",
    "        net collateral reserve == collateral reserve * (1 - total pct sold)\n",
    "        total exposure == net balance + net available + net collateral reserve\n",
    "    \"\"\"\n",
    "    # QA test\n",
    "    list_of_numeric = ['bookbalance','notebal','availbalamt','totalpctsold','noteopenamt','noteintrate','cobal','credlimitclatresamt']\n",
    "    for col in list_of_numeric:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "    def convert_to_float(value):\n",
    "        try:\n",
    "            return float(value)\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    for col in list_of_numeric:\n",
    "        df[col] = df[col].apply(convert_to_float)\n",
    "    \n",
    "    # Tax Exempt bonds always have $0 Book Balance so need to take NOTEBAL\n",
    "    df['bookbalance'] = np.where(df['currmiaccttypcd'].isin(['CM45']), df['notebal'], df['bookbalance'])\n",
    "    df['Net Balance'] = df['bookbalance'] - df['cobal']\n",
    "    df['Net Available'] = df['availbalamt'] * (1 - df['totalpctsold'])\n",
    "    df['Net Collateral Reserve'] = df['credlimitclatresamt'] * (1 - df['totalpctsold'])\n",
    "    df['Total Exposure'] = df['Net Balance'] + df['Net Available'] + df['Net Collateral Reserve']\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "def get_most_recent_file(folder_path):\n",
    "    today_str = datetime.now().strftime('%Y%m%d')\n",
    "    today_date = datetime.strptime(today_str, '%Y%m%d')\n",
    "\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    csv_files = [f for f in files if f.startswith(\"r360_\") and f.endswith(\".csv\")]\n",
    "\n",
    "    valid_files = {}\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            date_str = file.split(\"_\")[1].split(\".csv\")[0]\n",
    "            file_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "            if file_date <= today_date:\n",
    "                valid_files[file_date] = file\n",
    "        except (IndexError, ValueError):\n",
    "            continue\n",
    "\n",
    "    if not valid_files:\n",
    "        print(\"No history\")\n",
    "        return None\n",
    "    else:\n",
    "        most_recent_date = max(valid_files.keys())\n",
    "        most_recent_file = valid_files[most_recent_date]\n",
    "\n",
    "        return os.path.join(folder_path, most_recent_file)\n",
    "    \n",
    "def append_grouping_keys(loan_data, househldacct, pkey):\n",
    "    assert househldacct['acctnbr'].is_unique, \"Duplicates found\"\n",
    "    assert pkey['acctnbr'].is_unique, \"Duplicates found\"\n",
    "\n",
    "    loan_data = pd.merge(loan_data, househldacct, on='acctnbr', how='left')\n",
    "    loan_data = pd.merge(loan_data, pkey, on='acctnbr', how='left')\n",
    "    return loan_data\n",
    "\n",
    "def retrieve_historical_keys(history_path):\n",
    "    if history_path is None:\n",
    "        return None\n",
    "    else:\n",
    "        history = pd.read_csv(history_path)\n",
    "        return history\n",
    "    \n",
    "# def append_historical_keys(data, history=None):\n",
    "#     if history is None:\n",
    "#         return data\n",
    "#     else:\n",
    "#         history_subset = history[['acctnbr','portfolio_key']]\n",
    "#         assert history_subset['acctnbr'].is_unique, \"Duplicates found\"\n",
    "#         data = pd.merge(data, history_subset, on='acctnbr', how='left')\n",
    "#         data = data.set_index('acctnbr')\n",
    "#         data = data.to_dict(orient='index').copy()\n",
    "#         return data\n",
    "    \n",
    "\n",
    "\n",
    "# %%\n",
    "def calculate_total_exposure(df):\n",
    "    hh_exposure = df.groupby('householdnbr', as_index=False)['Total Exposure'].sum()\n",
    "    hh_exposure = hh_exposure.rename(columns={'Total Exposure':'total_exposure_hh'}).copy()\n",
    "    pkey_exposure = df.groupby('portfolio_key', as_index=False)['Total Exposure'].sum()\n",
    "    pkey_exposure = pkey_exposure.rename(columns={'Total Exposure':'total_exposure_pkey'}).copy()\n",
    "    hh_exposure = pd.DataFrame(hh_exposure)\n",
    "    pkey_exposure = pd.DataFrame(pkey_exposure)\n",
    "\n",
    "    df = pd.merge(df, hh_exposure, on='householdnbr', how='left')\n",
    "    df = pd.merge(df, pkey_exposure, on='portfolio_key', how='left')\n",
    "    return df\n",
    "\n",
    "# %%\n",
    "def append_exposure(df, keys_df):\n",
    "    # QA test\n",
    "    list_of_numeric = ['bookbalance','notebal','availbalamt','totalpctsold','noteopenamt','noteintrate','cobal','credlimitclatresamt']\n",
    "    for col in list_of_numeric:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "    def convert_to_float(value):\n",
    "        try:\n",
    "            return float(value)\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    for col in list_of_numeric:\n",
    "        df[col] = df[col].apply(convert_to_float)\n",
    "\n",
    "    assert df['acctnbr'].is_unique, \"Duplicates found\"\n",
    "    assert keys_df['acctnbr'].is_unique, \"Duplicates found\"\n",
    "\n",
    "    df = pd.merge(df, keys_df, how='left', on='acctnbr')\n",
    "    return df\n",
    "\n",
    "# %%\n",
    "# NEW LOAN section\n",
    "def split_data(df):\n",
    "    \"\"\"\n",
    "    Goal is to split the data between CML & MTG for this section, add subtitles, and necessary blank fields\n",
    "    \"\"\"\n",
    "    df['Notes'] = None\n",
    "    df['Next Rev Date'] = None\n",
    "    df['Appr in CT File'] = None\n",
    "    df['Exceptions on List'] = None\n",
    "\n",
    "    cml = df.loc[df['mjaccttypcd'] == 'CML', [\n",
    "        'Notes',\n",
    "        'Next Rev Date',\n",
    "        'Appr in CT File',\n",
    "        'Exceptions on List',\n",
    "        'householdnbr',\n",
    "        'contractdate',\n",
    "        'product',\n",
    "        'loanofficer',\n",
    "        'ownersortname',\n",
    "        'acctnbr',\n",
    "        'origbal',\n",
    "        'notebal',\n",
    "        'availbalamt',\n",
    "        'total_exposure_hh',\n",
    "        'total_exposure_pkey',\n",
    "        'riskratingcd',\n",
    "        'fdiccatcd',\n",
    "        'fdiccatdesc',\n",
    "        'naicscd',\n",
    "        'naicscddesc',\n",
    "        'proptypecd',\n",
    "        'proptypdesc',\n",
    "        'noteintrate',\n",
    "        'propnbr',\n",
    "        'propdesc',\n",
    "        'noteopenamt'\n",
    "    ]].copy()\n",
    "\n",
    "    cml = cml.sort_values(by='contractdate', ascending=False)\n",
    "\n",
    "    mtg = df.loc[df['mjaccttypcd'] == 'MTG', [\n",
    "        'Notes',\n",
    "        'Next Rev Date',\n",
    "        'Appr in CT File',\n",
    "        'Exceptions on List',\n",
    "        'householdnbr',\n",
    "        'contractdate',\n",
    "        'product',\n",
    "        'loanofficer',\n",
    "        'ownersortname',\n",
    "        'acctnbr',\n",
    "        'origbal',\n",
    "        'notebal',\n",
    "        'availbalamt',\n",
    "        'total_exposure_hh',\n",
    "        'total_exposure_pkey',\n",
    "        'riskratingcd',\n",
    "        'fdiccatcd',\n",
    "        'fdiccatdesc',\n",
    "        'naicscd',\n",
    "        'naicscddesc',\n",
    "        'proptypecd',\n",
    "        'proptypdesc',\n",
    "        'noteintrate',\n",
    "        'propnbr',\n",
    "        'propdesc',\n",
    "        'noteopenamt'\n",
    "    ]].copy()\n",
    "\n",
    "    mtg = mtg.sort_values(by='contractdate', ascending=False)\n",
    "\n",
    "    def create_subtitle_row(df, subtitle):\n",
    "        \"\"\"\n",
    "        Create a new row with a subtitle to break sections apart\n",
    "\n",
    "        Args:\n",
    "            df: either cml or mtg\n",
    "            subtitle (str): section title\n",
    "        \n",
    "        Returns:\n",
    "            df with additional row for subtitle\n",
    "        \"\"\"\n",
    "        new_row = pd.DataFrame(columns=df.columns)\n",
    "        new_row.loc[1, 'product'] = subtitle\n",
    "        new_row = new_row.fillna('')\n",
    "        df = pd.concat([new_row, df]).copy()\n",
    "        return df\n",
    "    \n",
    "    cml = create_subtitle_row(cml, 'Commercial Loans')\n",
    "    mtg = create_subtitle_row(mtg, 'Residential Loans')\n",
    "\n",
    "    blank_row = pd.DataFrame(columns=cml.columns)\n",
    "    blank_row = blank_row.fillna('')\n",
    "    \n",
    "    df = pd.concat([cml, blank_row])\n",
    "    df = pd.concat([df, mtg])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# CRA section\n",
    "def cra_section(df):\n",
    "    \"\"\"\n",
    "    CRA Sheet creation\n",
    "    \"\"\"\n",
    "    df['#'] = None\n",
    "    # df['Committed'] = None\n",
    "    df['Round'] = None\n",
    "    df['Gross Sales'] = None\n",
    "    df['MSA'] = None\n",
    "    df['State'] = None\n",
    "    df['County'] = None\n",
    "    df['Census'] = None\n",
    "    df['SBP'] = None\n",
    "    df['Reason'] = None\n",
    "    df['Comments'] = None\n",
    "\n",
    "    df = df.loc[~(df['currmiaccttypcd'].isin(['CM15','CM16']))].copy()\n",
    "    df = df.loc[df['mjaccttypcd'] != 'MTG'].copy()\n",
    "\n",
    "    df = df.loc[df['mjaccttypcd'] == 'CML', [\n",
    "        '#',\n",
    "        'contractdate',\n",
    "        'ownersortname',\n",
    "        'acctnbr',\n",
    "        'noteopenamt',\n",
    "        'Round',\n",
    "        'Gross Sales',\n",
    "        'primary_address',\n",
    "        'primaryownercity',\n",
    "        'primaryownerstate',\n",
    "        'primaryownerzipcd',\n",
    "        'Comments',\n",
    "        'fdiccatcd',\n",
    "        'MSA',\n",
    "        'State',\n",
    "        'County',\n",
    "        'Census',\n",
    "        'product',\n",
    "        'SBP',\n",
    "        'Reason',\n",
    "        'noteintrate',\n",
    "        'loanofficer',\n",
    "        'origdate',\n",
    "        'proptypdesc',\n",
    "        'riskratingcd'\n",
    "    ]].copy()\n",
    "\n",
    "    df = df.sort_values(by='contractdate', ascending=False)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# %%\n",
    "# def main():\n",
    "data = retrieve_data()\n",
    "\n",
    "wh_acctcommon = data['wh_acctcommon'].copy()\n",
    "wh_loans = data['wh_loans'].copy()\n",
    "wh_acctloan = data['wh_acctloan'].copy()\n",
    "wh_org = data['wh_org'].copy()\n",
    "wh_prop = data['wh_prop'].copy()\n",
    "wh_prop2 = data['wh_prop2'].copy()\n",
    "househldacct = data['househldacct'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filtered_acctcommon = filter_acctcommon(wh_acctcommon)\n",
    "filtered_wh_loans = filter_wh_loans(wh_loans)\n",
    "consolidated_prop_data = consolidate_prop_data(wh_prop, wh_prop2)\n",
    "\n",
    "househldacct = drop_household_duplicates(househldacct)\n",
    "wh_org = drop_org_duplicates(wh_org)\n",
    "merged_df = merge_data(filtered_acctcommon, filtered_wh_loans, wh_acctloan, consolidated_prop_data, wh_org, househldacct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data = filter_and_merge_loan_tables(wh_acctcommon, wh_acctloan, wh_loans)\n",
    "loan_data = append_total_exposure_field(loan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3302 entries, 0 to 3301\n",
      "Data columns (total 38 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   acctnbr                 3302 non-null   int64         \n",
      " 1   loanofficer             3302 non-null   object        \n",
      " 2   ownersortname           3302 non-null   object        \n",
      " 3   product                 3302 non-null   object        \n",
      " 4   curracctstatcd          3302 non-null   object        \n",
      " 5   notebal                 3302 non-null   float64       \n",
      " 6   bookbalance             3302 non-null   float64       \n",
      " 7   noteintrate             3302 non-null   float64       \n",
      " 8   datemat                 3302 non-null   datetime64[ns]\n",
      " 9   taxrptfororgnbr         3165 non-null   float64       \n",
      " 10  taxrptforpersnbr        137 non-null    float64       \n",
      " 11  contractdate            3302 non-null   datetime64[ns]\n",
      " 12  mjaccttypcd             3302 non-null   object        \n",
      " 13  currmiaccttypcd         3302 non-null   object        \n",
      " 14  nameaddr1               3302 non-null   object        \n",
      " 15  nameaddr2               3302 non-null   object        \n",
      " 16  nameaddr3               3299 non-null   object        \n",
      " 17  primaryownercity        3284 non-null   object        \n",
      " 18  primaryownerstate       3284 non-null   object        \n",
      " 19  primaryownerzipcd       3284 non-null   object        \n",
      " 20  noteopenamt             3302 non-null   float64       \n",
      " 21  minintrate              3302 non-null   object        \n",
      " 22  fdiccatcd               2700 non-null   object        \n",
      " 23  propnbr                 2681 non-null   float64       \n",
      " 24  totalpctsold            3302 non-null   float64       \n",
      " 25  riskratingcd            2704 non-null   object        \n",
      " 26  cobal                   3302 non-null   float64       \n",
      " 27  credlimitclatresamt     3302 non-null   float64       \n",
      " 28  origdate                3111 non-null   datetime64[ns]\n",
      " 29  origbal                 2573 non-null   float64       \n",
      " 30  fdiccatdesc             2700 non-null   object        \n",
      " 31  rundate                 3302 non-null   datetime64[ns]\n",
      " 32  availbalamt             3302 non-null   float64       \n",
      " 33  day diff                3111 non-null   float64       \n",
      " 34  Net Balance             3302 non-null   float64       \n",
      " 35  Net Available           3302 non-null   float64       \n",
      " 36  Net Collateral Reserve  3302 non-null   float64       \n",
      " 37  Total Exposure          3302 non-null   float64       \n",
      "dtypes: datetime64[ns](4), float64(17), int64(1), object(16)\n",
      "memory usage: 980.4+ KB\n"
     ]
    }
   ],
   "source": [
    "loan_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\R360\\Production\\Output'\n",
    "historical_path = get_most_recent_file(historical_path)\n",
    "\n",
    "pkey = retrieve_historical_keys(historical_path)\n",
    "pkey = pkey.loc[:,['acctnbr','portfolio_key']].copy()\n",
    "loan_data = append_grouping_keys(loan_data, househldacct, pkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3302 entries, 0 to 3301\n",
      "Data columns (total 41 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   acctnbr                 3302 non-null   int64         \n",
      " 1   loanofficer             3302 non-null   object        \n",
      " 2   ownersortname           3302 non-null   object        \n",
      " 3   product                 3302 non-null   object        \n",
      " 4   curracctstatcd          3302 non-null   object        \n",
      " 5   notebal                 3302 non-null   float64       \n",
      " 6   bookbalance             3302 non-null   float64       \n",
      " 7   noteintrate             3302 non-null   float64       \n",
      " 8   datemat                 3302 non-null   datetime64[ns]\n",
      " 9   taxrptfororgnbr         3165 non-null   float64       \n",
      " 10  taxrptforpersnbr        137 non-null    float64       \n",
      " 11  contractdate            3302 non-null   datetime64[ns]\n",
      " 12  mjaccttypcd             3302 non-null   object        \n",
      " 13  currmiaccttypcd         3302 non-null   object        \n",
      " 14  nameaddr1               3302 non-null   object        \n",
      " 15  nameaddr2               3302 non-null   object        \n",
      " 16  nameaddr3               3299 non-null   object        \n",
      " 17  primaryownercity        3284 non-null   object        \n",
      " 18  primaryownerstate       3284 non-null   object        \n",
      " 19  primaryownerzipcd       3284 non-null   object        \n",
      " 20  noteopenamt             3302 non-null   float64       \n",
      " 21  minintrate              3302 non-null   object        \n",
      " 22  fdiccatcd               2700 non-null   object        \n",
      " 23  propnbr                 2681 non-null   float64       \n",
      " 24  totalpctsold            3302 non-null   float64       \n",
      " 25  riskratingcd            2704 non-null   object        \n",
      " 26  cobal                   3302 non-null   float64       \n",
      " 27  credlimitclatresamt     3302 non-null   float64       \n",
      " 28  origdate                3111 non-null   datetime64[ns]\n",
      " 29  origbal                 2573 non-null   float64       \n",
      " 30  fdiccatdesc             2700 non-null   object        \n",
      " 31  rundate                 3302 non-null   datetime64[ns]\n",
      " 32  availbalamt             3302 non-null   float64       \n",
      " 33  day diff                3111 non-null   float64       \n",
      " 34  Net Balance             3302 non-null   float64       \n",
      " 35  Net Available           3302 non-null   float64       \n",
      " 36  Net Collateral Reserve  3302 non-null   float64       \n",
      " 37  Total Exposure          3302 non-null   float64       \n",
      " 38  householdnbr            3095 non-null   float64       \n",
      " 39  datelastmaint           3095 non-null   datetime64[ns]\n",
      " 40  portfolio_key           3293 non-null   float64       \n",
      "dtypes: datetime64[ns](5), float64(19), int64(1), object(16)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "loan_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loan_data = calculate_total_exposure(loan_data)\n",
    "loan_data_keys = loan_data.loc[:,['acctnbr','total_exposure_hh','total_exposure_pkey']].copy()\n",
    "\n",
    "\n",
    "merged_df = append_exposure(merged_df, loan_data_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104 entries, 0 to 103\n",
      "Data columns (total 50 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   acctnbr              104 non-null    int64         \n",
      " 1   loanofficer          104 non-null    object        \n",
      " 2   ownersortname        104 non-null    object        \n",
      " 3   product              104 non-null    object        \n",
      " 4   curracctstatcd       104 non-null    object        \n",
      " 5   notebal              104 non-null    float64       \n",
      " 6   bookbalance          104 non-null    float64       \n",
      " 7   noteintrate          104 non-null    float64       \n",
      " 8   datemat              104 non-null    datetime64[ns]\n",
      " 9   taxrptfororgnbr      46 non-null     float64       \n",
      " 10  taxrptforpersnbr     58 non-null     float64       \n",
      " 11  contractdate         104 non-null    datetime64[ns]\n",
      " 12  mjaccttypcd          104 non-null    object        \n",
      " 13  currmiaccttypcd      104 non-null    object        \n",
      " 14  primaryownercity     104 non-null    object        \n",
      " 15  primaryownerstate    104 non-null    object        \n",
      " 16  primaryownerzipcd    104 non-null    object        \n",
      " 17  noteopenamt          104 non-null    float64       \n",
      " 18  primary_address      104 non-null    object        \n",
      " 19  origdate             104 non-null    datetime64[ns]\n",
      " 20  origbal              100 non-null    float64       \n",
      " 21  fdiccatdesc          104 non-null    object        \n",
      " 22  rundate              104 non-null    datetime64[ns]\n",
      " 23  availbalamt          104 non-null    float64       \n",
      " 24  day diff             104 non-null    float64       \n",
      " 25  minintrate           104 non-null    object        \n",
      " 26  fdiccatcd            104 non-null    object        \n",
      " 27  propnbr              101 non-null    float64       \n",
      " 28  totalpctsold         104 non-null    float64       \n",
      " 29  riskratingcd         46 non-null     object        \n",
      " 30  cobal                104 non-null    float64       \n",
      " 31  credlimitclatresamt  104 non-null    float64       \n",
      " 32  aprsvalueamt         101 non-null    object        \n",
      " 33  aprsdate             72 non-null     datetime64[ns]\n",
      " 34  propaddr1            69 non-null     object        \n",
      " 35  propaddr2            0 non-null      object        \n",
      " 36  propaddr3            0 non-null      object        \n",
      " 37  propcity             69 non-null     object        \n",
      " 38  propstate            69 non-null     object        \n",
      " 39  propzip              69 non-null     object        \n",
      " 40  proptypecd           101 non-null    object        \n",
      " 41  propdesc             101 non-null    object        \n",
      " 42  proptypdesc          101 non-null    object        \n",
      " 43  orgnbr               46 non-null     float64       \n",
      " 44  naicscd              42 non-null     object        \n",
      " 45  naicscddesc          42 non-null     object        \n",
      " 46  householdnbr         62 non-null     float64       \n",
      " 47  datelastmaint        62 non-null     datetime64[ns]\n",
      " 48  total_exposure_hh    40 non-null     float64       \n",
      " 49  total_exposure_pkey  40 non-null     float64       \n",
      "dtypes: datetime64[ns](6), float64(17), int64(1), object(26)\n",
      "memory usage: 40.8+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_loan_page = split_data(merged_df)\n",
    "cra_section = cra_section(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved with autofit at \\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Weekly Reports\\NewLoanReport_LR_Credit\\Production\\Output\n",
      "Excel process complete\n",
      "Email sent!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Output to excel\n",
    "current_date = datetime.now().strftime('%Y%m%d')\n",
    "file_path = r'\\\\00-da1\\Home\\Share\\Data & Analytics Initiatives\\Project Management\\Chad Projects\\Weekly Reports\\NewLoanReport_LR_Credit\\Production\\Output'\n",
    "file_name = f'Loan_Report_45_day_lookback_{current_date}.xlsx'\n",
    "full_path = os.path.join(file_path, file_name)\n",
    "with pd.ExcelWriter(full_path, mode='w', engine='openpyxl') as writer:\n",
    "    new_loan_page.to_excel(writer, sheet_name='NEW LOAN', index=False)\n",
    "    cra_section.to_excel(writer, sheet_name='CRA', index=False)\n",
    "\n",
    "try:\n",
    "    excel = win32.Dispatch(\"Excel.Application\")\n",
    "    excel.Visible = False\n",
    "    workbook = excel.Workbooks.Open(full_path)\n",
    "    \n",
    "    ## NEW LOAN\n",
    "    sheet = workbook.Worksheets(\"NEW LOAN\")\n",
    "\n",
    "    sheet.Columns.AutoFit()\n",
    "\n",
    "    # Bold top row\n",
    "    top_row = sheet.Rows(1)\n",
    "    top_row.Font.Bold = True\n",
    "\n",
    "    # Add bottom border to header row\n",
    "    bottom_border = top_row.Borders(9)\n",
    "    bottom_border.LineStyle = 1\n",
    "    bottom_border.Weight = 2\n",
    "\n",
    "    date_columns = [\"F\"]\n",
    "\n",
    "    for col in date_columns:\n",
    "        col_index = column_to_index(col)\n",
    "        sheet.Columns(col_index).NumberFormat = \"mm/dd/yyyy\"\n",
    "\n",
    "    dollar_columns = [\"K\",\"L\",\"M\",\"N\",\"O\",\"Z\"]\n",
    "    \n",
    "    for col in dollar_columns:\n",
    "        col_index = column_to_index(col)\n",
    "        sheet.Columns(col_index).NumberFormat = \"$###,##0.00\"\n",
    "\n",
    "    percentage_columns = [\"W\"]\n",
    "    \n",
    "    for col in percentage_columns:\n",
    "        col_index = column_to_index(col)\n",
    "        sheet.Columns(col_index).NumberFormat = \"0.00%\"\n",
    "    \n",
    "\n",
    "    # Freeze top row\n",
    "    sheet.Application.ActiveWindow.SplitRow = 1\n",
    "    sheet.Application.ActiveWindow.FreezePanes = True\n",
    "\n",
    "    ## CRA\n",
    "    sheet = workbook.Worksheets(\"CRA\")\n",
    "\n",
    "    sheet.Columns.AutoFit()\n",
    "\n",
    "    # Bold top row\n",
    "    top_row = sheet.Rows(1)\n",
    "    top_row.Font.Bold = True\n",
    "\n",
    "    # Add bottom border to header row\n",
    "    bottom_border = top_row.Borders(9)\n",
    "    bottom_border.LineStyle = 1\n",
    "    bottom_border.Weight = 2\n",
    "\n",
    "    date_columns = [\"B\",\"W\"]\n",
    "\n",
    "    for col in date_columns:\n",
    "        col_index = column_to_index(col)\n",
    "        sheet.Columns(col_index).NumberFormat = \"mm/dd/yyyy\"\n",
    "\n",
    "    dollar_columns = [\"E\"]\n",
    "    \n",
    "    for col in dollar_columns:\n",
    "        col_index = column_to_index(col)\n",
    "        sheet.Columns(col_index).NumberFormat = \"$###,##0.00\"\n",
    "\n",
    "\n",
    "    percentage_columns = [\"U\"]\n",
    "    \n",
    "    for col in percentage_columns:\n",
    "        col_index = column_to_index(col)\n",
    "        sheet.Columns(col_index).NumberFormat = \"0.00%\"\n",
    "    \n",
    "\n",
    "    # Freeze top row\n",
    "    sheet.Application.ActiveWindow.SplitRow = 1\n",
    "    sheet.Application.ActiveWindow.FreezePanes = True\n",
    "\n",
    "\n",
    "    workbook.Save()\n",
    "    workbook.Close()\n",
    "\n",
    "    print(f\"Excel file saved with autofit at {file_path}\")\n",
    "finally:\n",
    "    try:\n",
    "        if 'workbook' in locals() and workbook is not None:\n",
    "            workbook.Close(SaveChanges=False)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if 'excel' in locals():\n",
    "            excel.Quit()\n",
    "    except:\n",
    "        pass\n",
    "    print(\"Excel process complete\")\n",
    "\n",
    "# Email\n",
    "recipients = [\n",
    "    \"chad.doorley@bcsbmail.com\"\n",
    "    # \"paul.kocak@bcsbmail.com\",\n",
    "    # \"linda.clark@bcsbmail.com\"\n",
    "]\n",
    "bcc_recipients = [\n",
    "    \"chad.doorley@bcsbmail.com\"\n",
    "]\n",
    "outlook = win32.Dispatch(\"Outlook.Application\")\n",
    "message = outlook.CreateItem(0)\n",
    "# message.Display()\n",
    "message.To = \";\".join(recipients)\n",
    "message.BCC = \";\".join(bcc_recipients)\n",
    "message.Subject = f\"Weekly Loan Report - {datetime.now().strftime('%m/%d/%Y')}\"\n",
    "message.Body = \"Hi all, \\n\\nAttached is the Weekly Loan Report with a 45 day lookback. Please let me know if you have any questions.\"\n",
    "message.Attachments.Add(str(full_path))\n",
    "message.Send()\n",
    "print(\"Email sent!\")\n",
    "\n",
    "\n",
    "# # %%\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
