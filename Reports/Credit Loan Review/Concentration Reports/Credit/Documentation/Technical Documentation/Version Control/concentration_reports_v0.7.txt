#################################
# List all non-standard packages to be imported by your 
# script here (only missing packages will be installed)
from ayx import Package
#Package.installPackages(['pandas','numpy'])


#################################
"""
Concentration Reports
@ Chad Doorley
2024
"""

from ayx import Alteryx
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
from sqlalchemy import create_engine, text
import os
import time


#################################
def main():
    df = retrieve_data()
    df = global_etl(df)
    loans = etl_deposits(df)
    deposits = etl_deposits(df)
    all_products = etl_all_products(df)
    df = group_by_household(df)
    write_to_excel(df)


#################################
def retrieve_data():
    """
    This method is responsible for connecting to the SQL database and 
    retrieving data that will be transformed into a pandas DataFrame
    to generate the concentration reports
    
    Args:
        None
        
    Returns:
        df: Data from SQL database joined together into 1 table
        
    Operations:
        - Initialize class DatabaseHandler
        - Query database
        - Join data
    """
    
    class DatabaseHandler:
        """
        Attributes:
        """
        def __init__(self, tns_admin_path, credentials_path_db1, credentials_path_db2):
            """
            Args:
                tns_admin_path (str): Oracle driver path
                credentials_path_db1 (str): Database 1 credentials path
                credentials_path_db1 (str): Databsae 2 credentials path
            """
            os.environ['TNS_ADMIN'] = tns_admin_path

            with open(credentials_path_db1) as config_file:
                config1 = json.load(config_file)

            self.username1 = config1['username']
            self.password1 = config1['password']
            self.dsn1 = config1['dsn']

            with open(credentials_path_db2) as config_file:
                config2 = json.load(config_file)

            self.username2 = config2['username']
            self.password2 = config2['password']
            self.dsn2 = config2['dsn']

            self.connection_string1 = f'oracle+cx_oracle://{self.username1}:{self.password1}@{self.dsn1}'
            self.connection_string2 = f'oracle+cx_oracle://{self.username2}:{self.password2}@{self.dsn2}'

            self.engine1 = create_engine(self.connection_string1, max_identifier_length=128)
            self.engine2 = create_engine(self.connection_string2, max_identifier_length=128)

        def query(self, sql_query, engine=1):
            """
            This allows abstraction of the connection and the class
            so the developer can query a single table as a dataframe

            Args:
                sql_query (str): The query to SQL database is passed as a string
                engine (int): This selects the database. There are two engines:
                    1 -> R1625
                    2 -> COCC DataMart

            Returns:
                df: The SQL query is returned as a pandas DataFrame

            Usage:
                df = db_handler.query("SELECT * FROM DB.TABLE", engine=1)

                In this example, db_handler = DatabaseHandler(args)
            """
            if engine == 1:
                selected_engine = self.engine1
            elif engine == 2:
                selected_engine = self.engine2
            else:
                raise ValueError("Engine must be 1 or 2")

            with selected_engine.connect() as connection:
                df = pd.read_sql(sql_query, connection)
            return df
    
    # Database Connection Configuration
    tns_admin_path = r'C:\Oracle2\instantclient_21_13\network\admin'
    credentials_path_db1 = r'\\10.161.85.66\Home\Share\Alteryx_Admin\Configuration\Connection\db_config_main.json'
    credentials_path_db2 = r'\\10.161.85.66\Home\Share\Alteryx_Admin\Configuration\Connection\db_config_datamart.json'
    db_handler = DatabaseHandler(tns_admin_path, credentials_path_db1, credentials_path_db2)
    
    print("Starting SQL query ...")
    start_time = time.time()
    
    with db_handler.engine1.connect() as connection:
        # For development only
        lookup_df = text("""
        SELECT 
            *
        FROM 
            sys.all_tab_columns col
        """)
        start_time = time.time()
        lookup_df = pd.read_sql(lookup_df, connection)
        print(f"lookup_df took {time.time() - start_time} seconds.")
    
        acctcommon = text("""
        SELECT 
            a.ACCTNBR,
            a.OWNERNAME,
            a.PRODUCT,
            a.LOANOFFICER,
            a.ACCTOFFICER,
            a.EFFDATE, 
            a.MJACCTTYPCD, 
            a.CURRMIACCTTYPCD,
            a.NOTEBAL,
            a.BOOKBALANCE,
            a.NOTEINTRATE,
            a.CURRACCTSTATCD, 
            a.CONTRACTDATE,
            a.DATEMAT,
            a.TAXRPTFORORGNBR,
            a.TAXRPTFORPERSNBR
        FROM 
            OSIBANK.WH_ACCTCOMMON a
        """)
        acctcommon = pd.read_sql(acctcommon, connection)
        
        acctloan = text("""
        SELECT
            a.ACCTNBR,
            a.COBAL,
            a.TOTALPCTSOLD,
            a.FDICCATCD,
            a.RISKRATINGCD,
            a.CREDLIMITCLATRESAMT,
            a.TOTALPI,
            a.ESCROWDUE
        FROM
            OSIBANK.WH_ACCTLOAN a
        """)
        start_time = time.time()
        acctloan = pd.read_sql(acctloan, connection)
        print(f"ACCTLOAN took {time.time() - start_time} seconds.")

        wh_loans = text("""
        SELECT
            a.ACCTNBR,
            a.AVAILBALAMT,
            a.NEXTRATECHG
        FROM
            OSIBANK.WH_LOANS a
        """)
        start_time = time.time()
        wh_loans = pd.read_sql(wh_loans, connection)
        print(f"WH_LOANS took {time.time() - start_time:.2f} seconds")
        
    print(f"SQL query took {time.time() - start_time} seconds.")
    
    # Need to merge everything together here into 1 df
    # Make sure deposits come out okay.
    
    pass
    


#################################
def global_etl(df):
    pass


#################################
def etl_loans(df):
    pass


#################################
def etl_deposits(df):
    pass


#################################
def etl_all_products(df):
    pass


#################################
def group_relationships(df, portfolio_key='portfolio_key', balance_col='balance'):
    """
    Overview: Group and format relationships based on portfolio key and balance.
    
    Args:
        df (DataFrame): Input DataFrame to be processed.
        portfolio_key (str): Column name for portfolio key. Default is 'portfolio_key'.
        balance_col (str): Column name for balance. Default is 'balance'.
    
    Returns:
        DataFrame: Processed DataFrame with grouped relationships and summary rows.
    
    Operations:
        - Reset index and sort values.
        - Group by portfolio key and calculate totals.
        - Create result DataFrame with summary and empty rows.
    """
    df = df.reset_index(drop=True)
    df_sorted = df.sort_values([portfolio_key, balance_col], ascending=[True, False])
    grouped = df_sorted.groupby(portfolio_key)
    relationship_totals = grouped[balance_col].sum().sort_values(ascending=False)
    result = pd.DataFrame()

    for key in relationship_totals.index:
        relationship_records = grouped.get_group(key)
        result = pd.concat([result, relationship_records])

        summary_row = relationship_records.iloc[0].copy()
        for col in summary_row.index:
            if col == balance_col:
                summary_row[col] = relationship_records[balance_col].sum()
            elif col == portfolio_key:
                summary_row[col] = key
            else:
                summary_row[col] = 'Total' if col == df.columns[1] else ''
        
        result = pd.concat([result, pd.DataFrame([summary_row])])

        empty_row = pd.Series('', index=df.columns)
        empty_row[balance_col] = None
        result = pd.concat([result, pd.DataFrame([empty_row])])

    return result.reset_index(drop=True)


#################################
# Create sample data
np.random.seed(42)
num_records = 10

data = {
    'acctnbr': [f'{i:05d}' for i in range(1, num_records + 1)],
    'customer_name': [f'Customer {i}' for i in range(1, num_records + 1)],
    'officer': np.random.choice(['Smith', 'Johnson', 'Williams', 'Brown', 'Jones'], num_records),
    'contract_date': [datetime.now().date() - timedelta(days=np.random.randint(1, 365)) for _ in range(num_records)],
    'balance': np.random.uniform(1000, 100000, num_records).round(2),
    'interest_rate': np.random.uniform(0.01, 0.05, num_records).round(4),
    'household_number': np.random.choice([123456, 234567, 345678], num_records)
}

# Create the DataFrame
df = pd.DataFrame(data)


#################################
# temp_df = group_relationships(df, portfolio_key='household_number', balance_col='balance')


#################################
# with pd.option_context('display.max_rows',None):
#     temp_df = lookup_df[lookup_df['column_name'].str.contains('NEXTRATECH',case=False)]
#     print(temp_df)



#################################
